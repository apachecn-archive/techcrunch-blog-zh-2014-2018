# 脸书承认，它必须采取更多措施来阻止错误信息在其平台 TechCrunch 上传播

> 原文：<https://web.archive.org/web/https://techcrunch.com/2016/11/10/facebook-admits-it-must-do-more-to-stop-the-spread-of-misinformation-on-its-platform/>

在特朗普昨天赢得美国总统大选后，脸书对其新闻推送算法如何传播和放大错误信息的广泛批评做出了回应。

多名评论员迅速指责脸书在竞选中的作用，认为鉴于其平台目前作为主要媒体来源的角色，这家科技巨头非常不负责任，特别是通过让虚假故事激增——竞选期间，许多例子被视为在脸书新闻订阅中传播。

上周 [Buzzfeed](https://web.archive.org/web/20230130101824/https://www.buzzfeed.com/craigsilverman/how-macedonia-became-a-global-hub-for-pro-trump-misinfo) 报道了马其顿一个由网络用户组成的山寨产业，他们制造与川普和希拉里对决相关的假新闻，以便将它们注入脸书的新闻源，以此来推动病毒式的浏览量，并从利润丰厚的美国眼球中获得广告收入。

这项事业对参与其中的青少年来说显然非常成功，由于脸书的放大算法的力量，有些人显然每月能赚到 3000 美元和 5000 美元。

这对于玩算法游戏来说是一个相当大的经济激励。

正如 TC 的 [Sarah Perez 昨天](https://web.archive.org/web/20230130101824/https://techcrunch.com/2016/11/09/rigged/)所写的，社交网络已经成为“塑造我们对身边发生的事件的理解的超大玩家”。

在发给 TechCrunch 的一份声明中，我们向该公司提出了一系列问题(我们的问题见下文)，脸书产品管理副总裁亚当·莫塞里(Adam Mosseri)承认，该公司确实需要采取更多措施来解决这个问题——尽管他没有透露计划如何解决这个问题。

以下是他的声明全文:

> 我们非常重视关于脸书的错误信息。我们重视真实的交流，经常听到那些使用脸书的人说他们不想看到错误的信息。在 Newsfeed 中，我们使用基于社区反馈的各种信号来确定哪些帖子可能包含不准确的信息，并减少它们的分布。在趋势分析中，我们会查看各种信号，以帮助确保所显示的主题反映了真实世界的事件，并采取额外的措施来防止虚假或误导性的内容出现。尽管做出了这些努力，但我们知道还有很多事情需要我们去做，这就是为什么我们不断提高发现错误信息的能力是如此重要。我们致力于继续解决这个问题，并改善我们平台上的体验。

此前，脸书曾因解雇曾经负责策划其趋势新闻栏目的人工编辑而受到批评。它切换到的替换算法[很快被证明非常容易被骗过](https://web.archive.org/web/20230130101824/https://techcrunch.com/2016/08/29/facebooks-trending-topics-algorithm-mistake/)。

然而，该公司继续将自己定义为一个技术平台，故意回避对其算法分发的内容承担更广泛的编辑责任，而是倾向于应用一套狭隘而通用的社区标准和/或[试图找到工程解决方案](https://web.archive.org/web/20230130101824/https://techcrunch.com/2016/08/04/facebook-clickbait/)来过滤新闻。这是一个越来越不负责任的立场，因为脸书作为“新闻”来源和放大者的地位越来越强大。

[皮尤](https://web.archive.org/web/20230130101824/http://www.journalism.org/2016/05/26/news-use-across-social-media-platforms-2016/)今年早些时候的研究发现，大多数美国成年人(62%)现在通过社交媒体获取新闻。虽然脸书不是唯一的社交媒体机构，也不是唯一假新闻可以传播的地方(参见:Twitter)，但它是美国和其他许多市场上此类平台的主导者。

除了通过脸书的点击饥渴平台传播的真实假新闻，更广泛的问题是其偏好反馈新闻算法用来包围个人的过滤泡沫，因为他们努力给他们更多的点击——从而让用户在意见的同心圆中旋转，无法接触到其他观点。

这显然对同理心、多样性和一个有凝聚力的社会非常不利。

多年来，过滤泡沫一直是一个备受关注的问题，但在算法上剥离可用意见的光谱，同时沿着个人特定观点的轴线打开 [Overton 窗口](https://web.archive.org/web/20230130101824/https://en.wikipedia.org/wiki/Overton_window)的后果，可能在今年变得越来越明显，因为社会分裂似乎比最近记忆中的更大、更吵、更丑——至少在社交媒体上是这样。

我们知道媒介就是信息。在社交媒体上，我们知道信息本质上是个人的。因此，让算法来管理和控制通常高度情绪化的信息，让它看起来更像是一个非常大的科技巨头在方向盘上睡着了。

**我们向脸书提出的问题:**

*   有人批评脸书的新闻推送算法在美国大选期间放大假新闻，从而对错误信息竞选产生负面影响，并最终帮助推动对唐纳德·特朗普当选的支持，对此该如何回应？
*   脸书对 Buzzfeed 调查马其顿网站被用来生成大量假新闻并放入新闻源一事有具体回应吗？
*   脸书今后将采取哪些措施来防止假新闻在其平台上被放大和传播？
*   该公司是否对通过其平台传播假新闻承担任何责任？
*   脸书会改变立场，雇佣人类编辑和记者来阻止其新闻算法的琐碎游戏吗？
*   随着越来越多的人将它的平台作为主要新闻来源，脸书是否承认它有公民义务为它播放的内容承担编辑责任？
*   脸书对川普的当选有何评论？