<html>
<head>
<title>Thinking about the social cost of technology • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">思考技术的社会成本 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2017/09/30/thinking-about-the-social-cost-of-technology/?ncid=rss">https://web.archive.org/web/https://techcrunch.com/2017/09/30/thinking-about-the-social-cost-of-technology/?ncid=rss</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">每次我打电话给我妈妈聊天时，她通常会犹豫一下，然后提前道歉，提出她最新的技术难题。</p>
<p class="translated">她从电子邮件提供商那里收到一封电子邮件，警告她需要升级设备的操作系统，否则将无法访问该应用程序。或者她通过这样或那样的信息服务发送的信息从来没有收到或者几天后才收到。或者她会再次询问如何找到她之前通过电子邮件发送的特定照片，如何保存以及如何下载，以便她可以将其带到商店进行打印。</p>
<p class="translated">她曾经问我，为什么她的打印机现在突然只能打印小得难以辨认的文字。为什么文字处理软件会锁定双倍行距？我能告诉她为什么当她打字的时候光标会一直跳来跳去，因为她在文档中总是找不到自己的位置？</p>
<p class="translated">还有一次，她想知道为什么操作系统升级后视频通话不再有效。从那以后，她一直担心是否应该升级到最新的操作系统——如果这意味着其他应用程序可能会停止工作。</p>
<p class="translated">还有一次，她想知道为什么她一直使用的视频应用程序突然要求她登录一个帐户，她不认为她只是为了查看相同的内容。她以前不必这样做。</p>
<p class="translated">她遇到的其他问题甚至没有作为问题提出来。她只会说她忘记了某个账户的密码，所以这是没有希望的，因为这是不可能的。</p>
<p class="translated">大多数时候，很难远程解决这些问题，因为具体的问题或琐事并不是真正的问题。最重要的问题是技术本身越来越复杂，这要求人们理解不断扩大的互连组件和过程的分类。心甘情愿地融入这个系统，吸收它不讨人喜欢的词汇。</p>
<p class="translated">然后，当事情总是出错时，解构令人不快、难以理解的信件，让自己像个工程师一样，试图自己解决问题。</p>
<p class="translated">技术专家显然觉得有理由建立一个不断加深的用户困惑的迷雾，因为他们改变升级杠杆，以提升另一个档位来重新配置“下一个现实”，而他们的首席执行官则着眼于吸收更多消费者美元的奖励。</p>
<p class="translated">与此同时，像我妈妈这样的“用户”面临着另一个由不熟悉的碎片组成的神秘难题，他们试图将这些碎片拼回一起，并——他们希望——将工具恢复到一切再次改变之前的实用状态。</p>
<p class="translated">这些人将越来越感到被抛在后面，与社会脱节，在这个社会中，技术在日常生活中扮演着越来越重要的角色，而且通过控制我们看到和做的许多事情，在塑造日常社会中扮演着越来越重要但基本上看不见的角色。人工智能是真正规模的无声决策者。</p>
<p class="translated">看似不可知的复杂技术带来的沮丧和压力——更不用说试图让系统按照人们希望的方式工作而浪费的时间和精力了——往往不会在科技公司的圆滑演示中得到讨论，他们的激光笔固定在未来，他们的意图锁定在赢得下一场大游戏上。</p>
<p class="translated">人类生活越来越多地与越来越复杂、越来越难以理解的技术交织在一起，这一事实经常被认为是一件好事。消极因素通常不会被过多关注。在很大程度上，人们被期望向前移动，或者被技术移动。</p>
<p class="translated">这是进步的代价，简短的耸耸肩说道。用户应该使用该工具，并对不被该工具所迷惑负责。</p>
<p class="translated">但是，如果用户因为不知道如何使用而不能正确使用系统，该怎么办呢？他们有错吗？还是设计者未能恰当地阐明他们在如此大的规模下建造和推出了什么？以及未能以不疏远和排斥的方式将复杂性分层？</p>
<p class="translated">当工具变得如此吸引人们的注意力，如此能够推动个人按钮，成为公众意见的主流来源时，会发生什么？并且这样做时不显示其工作方式。虽然没有说清楚，但它实际上呈现的是一个经过过滤、由算法控制的视图。</p>
<p class="translated">没有报纸风格的刊头或电视新闻标题来表明脸书算法编辑器的存在。但是越来越多的人开始关注社交媒体来获取新闻。</p>
<p class="translated">这标志着一个重大的转变。</p>
<p>*</p>
<p class="translated">与此同时，越来越明显的是，就对现代消费技术工具的信任而言，我们生活在一个矛盾的时代。几乎是突然之间，科技的算法工具被指为大问题的源头，而不仅仅是大规模解决方案的源头。(有时甚至像<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/09/28/tech-giants-pressured-to-auto-flag-illegal-content-in-europe/" rel="noopener">一样既有问题又有解决方案</a>；看起来，困惑也能引发冲突。)</p>
<p class="translated">看看脸书首席执行官马克·扎克伯格脸上的<a target="_blank" href="https://web.archive.org/web/20221025222657/http://time.com/4952391/mark-zuckerberg-facebook-russia-meddling-congress/" rel="noopener">痛苦表情</a>，例如，当他直播上周该公司如何对待其平台上的政治广告时，他承认了不太真实的<em>过失</em>。</p>
<p class="translated">这是在<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/09/20/anticipating-the-dark-side/" rel="noopener">被揭露后</a>脸书的算法已经为广告创建了分类，目标是那些表示赞成烧死犹太人的人。</p>
<p class="translated">在美国选举机构开始<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/09/15/us-election-agency-seeks-views-on-rule-change-for-digital-ad-platforms/" rel="noopener">讨论改变在数字平台上展示政治广告的规则</a>之后——使信息披露要求符合电视和印刷媒体的规定。</p>
<p class="translated">也是在脸书对其平台上的政治广告支出进行内部调查后，发现俄罗斯特工花费了超过<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/09/06/facebook-russia-ads-election/" rel="noopener">10 万美元寻求在美国缝合社会分裂</a></p>
<p class="translated">扎克伯格的艰难决定(在他疲惫的脸上表现得尤为明显)是，<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/09/21/facebook-and-twitter-play-bigger-role-in-congressional-election-hacking-probe/" rel="noopener">公司</a>将向国会提交 3000 个俄罗斯购买的广告，该公司表示，这些广告可能在美国总统选举期间影响公众舆论。</p>
<p class="translated">但它会抵制公开这种具有社会分裂性的、通过算法投放的广告的呼吁。</p>
<p class="translated">因此，让公众更好地了解脸书的大规模广告平台实际上是为目标消费服务的，以及它实际上被用来分发的信息类型，并没有被列入扎克的政治优先任务清单。即使是现在。</p>
<p class="translated">大概是因为他已经看到了内容，它并不完全漂亮。</p>
<p class="translated">“假新闻”年复一年地在脸书的内容平台上自由传播。直到现在才成为脸书的一个主要政治和公共关系问题——它说它正试图用更多的技术工具来解决这个问题。</p>
<p class="translated">虽然你可能会认为越来越多的人在理解消费技术方面没有困难，因此像我妈妈这样的技术用户是越来越少的少数，但很难认为每个人都完全理解在闪亮的外表下运作的高度复杂、非常强大的技术巨头正在发生什么。</p>
<p class="translated">了解这些大型技术平台的用途和使用方式并不容易。当你考虑到他们掌握了多少权力时就不会了。</p>
<p class="translated">在脸书的案例中，我们可以抽象地知道，扎克的人工智能军队正在不断地将数十亿人的大数据输入机器学习模型，通过预测任何个人在特定时刻可能想要购买的东西来实现商业利润。</p>
<p class="translated">包括，如果你的注意力高于平均水平，通过<a target="_blank" href="https://web.archive.org/web/20221025222657/https://www.theguardian.com/technology/2017/may/01/facebook-advertising-data-insecure-teens" rel="noopener">追踪人们的情绪</a>。它也显示了<a target="_blank" href="https://web.archive.org/web/20221025222657/https://www.theguardian.com/technology/2014/jun/29/facebook-users-emotions-news-feeds" rel="noopener">试图控制人们感情的实验</a>。尽管这位脸书首席执行官更喜欢谈论脸书的“使命”是“建立一个全球社区”和“连接世界”，而不是作为一个跟踪和服务大众意见的工具。</p>
<p class="translated">然而，作为脸书用户的实验品，我们并不了解该平台的数据采集、信息三角测量和人员定位基础设施如何工作的完整工程细节。</p>
<p class="translated">通常只有通过外部调查才能发现负面影响。例如<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2016/10/28/facebook-ethnic-affinity/" rel="noopener"> ProPublica </a>在 2016 年报道称，脸书的工具可以被用来根据用户的“种族相似性”将他们包括或排除在特定的广告活动之外——这可能会允许广告活动违反禁止歧视性广告的住房和就业等领域的联邦法律。</p>
<p class="translated">这一外部曝光导致脸书<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2016/11/11/facebook-sort-of-disables-ethnic-affinity-targeting/" rel="noopener">关闭了</a>“种族亲和力”广告定位的某些类型的广告。它显然没有发现其广告定位基础设施本身的问题。显然，它将监管其商业决策的责任外包给了调查记者。</p>
<p class="translated">问题是，在商业有色玻璃的背后，公众在很大程度上无法理解消费技术的全部含义和影响，这些技术正在如此大规模地应用于社会、公民机构和数十亿消费者。</p>
<p class="translated">因此毫不奇怪的是，科技平台的分支——在脸书的情况下，允许自由访问点对点出版，以及将完全未经核实的信息锁定在任何人群和全球范围内——才真正开始在公众面前被揭开。</p>
<p class="translated">任何技术工具都可能是一把双刃剑。但是，如果你不完全了解设备的内部工作原理，就很难控制可能的负面后果。</p>
<p class="translated">内部人士显然不能自称如此无知。即使雪莉·桑德伯格为脸书建造了一个可以用来向反犹太人做广告的工具辩护，他们也只是没有想到这一点。</p>
<p class="translated">抱歉，但这还不够好，脸书。</p>
<p class="translated">你的工具，你的规则，你思考和消除负面后果的责任。尤其是当你宣称的目标是将你的平台覆盖到全世界的时候。</p>
<p class="translated">在脸书最终承认俄国的分裂性广告购买之前，<a target="_blank" href="https://web.archive.org/web/20221025222657/https://www.today.com/news/sheryl-sandberg-facebook-fake-news-we-don-t-think-it-t105703" rel="noopener">桑德伯格</a>和<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2016/11/10/zuck-denies-facebook-news-feed-bubble-impacted-the-election/" rel="noopener">扎克伯格</a>也试图淡化脸书影响政治观点的力量——同时经营着一项利润丰厚的业务，其收入几乎完全来自告诉广告商它可以影响观点。</p>
<p class="translated">只是现在，在美国大选后的一波公开批评之后，扎克告诉我们，他很遗憾地说，人们疯狂地认为他的 20 多亿用户平台工具可能被滥用。</p>
<p class="translated">如果他说这话时不是完全不真诚，那他真的是愚蠢得不可原谅。</p>
<p>*</p>
<p class="translated">在一个少数几个占主导地位的技术平台现在拥有塑造信息、进而塑造社会和公众舆论的巨大力量的世界里，其他算法结果当然也是存在的。在西方，脸书和谷歌是其中的佼佼者。在美国，亚马逊也在电子商务领域占据主导地位，同时也越来越多地超越这一领域——<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/09/27/amazon-just-launched-6-new-gadgets-and-none-was-over-150/" rel="noopener">特别是进入智能家居</a>，并寻求将其 Alexa voice-AI <a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/09/20/amazon-is-working-on-smart-glasses-to-house-alexa-ai-says-ft/" rel="noopener">始终放在听得见的地方</a>。</p>
<p class="translated">但与此同时，尽管大多数人在想要找到一些东西时仍会考虑使用谷歌，但该公司搜索排名算法的变化有能力将信息提升到大众视野，或将数据隐藏在大多数搜索者永远不会找到的文件夹下。</p>
<p class="translated">这当然早就知道了。但是多年来，谷歌一直将其算法描述为类似于公正的指数。事实上，他们是在为公司的商业利益服务。</p>
<p class="translated">我们看不到谷歌用来排序我们找到的信息的算法规则。但是基于这些搜索的结果，该公司有时被<a target="_blank" href="https://web.archive.org/web/20221025222657/https://beta.techcrunch.com/2017/06/27/google-fined-e2-42bn-for-eu-antitrust-violations-over-shopping-searches/" rel="noopener">指控</a>利用其在互联网搜索中的主导地位将自己的服务置于竞争对手之前。(例如，这是欧洲竞争监管机构的职责。)</p>
<p class="translated">今年 4 月，谷歌<a target="_blank" href="https://web.archive.org/web/20221025222657/https://www.blog.google/products/search/our-latest-quality-improvements-search/" rel="noopener">也宣布</a>它正在对其搜索算法进行修改，试图减少带有政治色彩的“假新闻”问题——显然也出现在互联网搜索中。(或者谷歌定义的“公然误导、低质量、令人不快或彻头彻尾的虚假信息”。)</p>
<p class="translated">令人不快的内容最近也威胁到了 Alphabet 的底线，此前广告客户从 YouTube 上撤下了与恐怖主义宣传和/或令人不快的仇恨言论放在一起的内容。因此，有一个明显的商业动机在推动谷歌搜索算法的调整，同时强大的技术平台也面临越来越大的政治压力，要求它们整顿自己的行为。</p>
<p class="translated">谷歌现在表示，很难开发工具来自动识别极端主义内容。其行动的催化剂似乎是对其自身收入的威胁——就像脸书突然面对大量愤怒的用户时改变主意一样。</p>
<p class="translated">问题是，当谷歌在搜索结果中降级假新闻时，一方面你可能会说‘太好了！它终于要为帮助和鼓励网上错误信息的传播承担责任了。另一方面，你可能会叫嚣犯规，正如自称“独立媒体”的网站 AlterNet 本周所做的那样——声称无论谷歌对其算法做了什么改变，其网站的流量自 6 月以来已经减少了 40%。</p>
<p class="translated">我不打算卷入一场关于 AlterNet 是否发布假新闻的辩论。但看起来谷歌确实正在这么做。</p>
<p class="translated">当被问及 AlterNet 对其算法改变导致网站流量减半的指控时，谷歌发言人告诉我们:“我们坚定地致力于向我们的用户提供有用和相关的搜索结果。为了做到这一点，我们不断改进我们的算法，使我们的网络结果更权威。一个网站在谷歌搜索上的排名是由数百个因素决定的，这些因素用来计算页面与给定查询的相关性，包括页面排名、网站上出现的特定词语、内容的新鲜度以及你所在的地区。</p>
<p class="translated">所以基本上是在判断 AlerNet 的内容是假新闻。而 AlterNet 回击称“新媒体垄断正在伤害进步和独立的新闻”。</p>
<p class="translated">显而易见的是，谷歌已经让它的算法负责评估像“信息质量”和权威性这样主观的东西——以及这种复杂决定带来的所有相关编辑风险。</p>
<p class="translated">但是，谷歌不是像传统媒体运营那样由人类逐个案例地做出决定，而是依靠算法来实现自动化，因此避免了具体的判断。</p>
<p class="translated">其结果是，它的技术工具正在大规模地对内容进行曝光或降级，而不承担这些编辑判断的责任。</p>
<p class="translated">在新代码上点击“执行”后，谷歌的工程师离开了房间——让我们人类用户筛选它推给我们的数据，试图决定我们正在展示的东西看起来是否公平、准确或合理。</p>
<p class="translated">我们又一次被赋予了处理大规模自动化决策后果的责任。</p>
<p class="translated">但是，期望人们评估复杂算法的内部工作，而不让他们也看到那些黑盒内部——同时还让他们服从那些相同算法的决定和结果——似乎不是一个非常可持续的情况。</p>
<p class="translated">当技术平台变得如此之大，以至于有垄断主流注意力的风险时，就不会了。</p>
<p class="translated">有些东西必须放弃。仅仅相信大规模应用的算法会产生良性影响，或者支撑巨大信息层级的规则永远不应被质疑，就像期望每个人，无论老少，都能准确理解你的应用程序如何完美地工作，并权衡他们是否真的需要你的最新更新，同时还假设他们会在你的工具无法与其他技术良好配合时设法解决所有问题一样明智。</p>
<p class="translated">我们刚刚开始意识到，当技术工具的创造者为了纯粹的商业利益而逃避更广泛的社会责任时，什么会被打破。</p>
<p class="translated">更多并不是对每个人都更好。这对个体企业来说可能更好，但以更广泛的社会成本为代价呢？</p>
<p class="translated">因此，也许我们应该更多地关注那些总是说他们不明白这个新技术是干什么用的，或者质疑他们为什么真的需要它，以及他们是否应该同意它告诉他们做什么的人。</p>
<p class="translated">也许我们都应该问更多关于技术用途的问题。</p>
			</div>

			</div>    
</body>
</html>