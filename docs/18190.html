<html>
<head>
<title>Nvidia launches colossal HGX-2 cloud server to power HPC and AI • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">英伟达推出庞大的HGX-2云服务器，为高性能计算和人工智能技术提供支持</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/05/30/nvidia-launches-colossal-hgx-2-cloud-server-to-power-hpc-and-ai/">https://web.archive.org/web/https://techcrunch.com/2018/05/30/nvidia-launches-colossal-hgx-2-cloud-server-to-power-hpc-and-ai/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">英伟达推出庞大的HGX-2云服务器，支持高性能计算和人工智能</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">Nvidia昨天发布了一个叫做HGX-2的怪物盒子，它是极客梦想的材料。这是一个据称非常强大的云服务器，它将高性能计算与人工智能需求结合在一个非常引人注目的包中。</p>
<p class="translated">你知道你想知道规格，所以让我们开始吧:它始于16x英伟达特斯拉V100 GPUs。对于低精度的人工智能来说，这是很好的2 petaFLOPS，中等精度的250 teraFLOPS和需要最高精度的125 teraFLOPS。它标配了1/2 TB的内存和12个Nvidia NVSwitches，能够以每秒300 GB的速度进行GPU之间的通信。与去年发布的HGX 1号相比，它们的容量增加了一倍。</p>
<p/><div id="attachment_1648219" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-1648219" decoding="async" loading="lazy" class="wp-image-1648219 size-large" src="../Images/e8a5c9b0c067113e47da4e923fc99af5.png" alt="" srcset="https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png 1234w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png?resize=150,57 150w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png?resize=300,114 300w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png?resize=768,291 768w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png?resize=680,258 680w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png?resize=1200,455 1200w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png?resize=50,19 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-33-04.png?w=680"/><p id="caption-attachment-1648219" class="wp-caption-text translated">图表:英伟达</p></div>
<p class="translated">英伟达特斯拉数据中心产品的集团产品营销经理Paresh Kharya表示，这种通信速度使他们能够将GPU本质上视为一个巨大的单个GPU。“这使得[开发人员]不仅可以获得巨大的计算能力，还可以在他们的程序中以单个内存块的形式访问半TB的GPU内存，”他解释道。</p>
<p/><div id="attachment_1648221" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-1648221" decoding="async" loading="lazy" class="wp-image-1648221 size-large" src="../Images/d085625f7ea3987f22f1e630340ccd7e.png" alt="" srcset="https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-34-25.png 645w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-34-25.png?resize=150,73 150w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-34-25.png?resize=300,147 300w, https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-34-25.png?resize=50,24 50w" sizes="(max-width: 645px) 100vw, 645px" data-original-src="https://web.archive.org/web/20230110180643im_/https://techcrunch.com/wp-content/uploads/2018/05/screenshot-2018-05-30-15-34-25.png?w=645"/><p id="caption-attachment-1648221" class="wp-caption-text translated">图形:英伟达</p></div>
<p class="translated">不幸的是，你买不到这样的盒子。事实上，Nvidia正在严格地将它们分发给经销商，经销商可能会将这些产品打包并出售给超大规模数据中心和云提供商。Kharya说，对于云经销商来说，这种方法的好处在于，当他们购买时，他们在一个盒子里就有了所有的精度。</p>
<p class="translated">“统一平台的优势在于，随着公司和云提供商构建基础设施，他们可以在单个统一架构上实现标准化，从而支持各种高性能工作负载。因此，无论是人工智能，还是高性能模拟，所有工作负载现在都可以在一个平台上实现，”Kharya解释道。</p>
<p class="translated">他指出，这在大规模数据中心尤其重要。“在超大规模公司或云提供商中，他们提供的主要优势是规模经济。如果他们能够在尽可能少的架构上实现标准化，他们就能真正最大限度地提高运营效率。HGX允许他们做的就是在这个单一的统一平台上实现标准化，”他补充道。</p>
<p class="translated">对于开发人员来说，他们可以编写利用底层技术的程序，并在单个机器上以他们需要的精确级别编程。</p>
<p class="translated">HGX-2驱动的服务器将于今年晚些时候从合作经销商处出售，包括联想、QCT、超微和威温。</p>
			</div>

			</div>    
</body>
</html>