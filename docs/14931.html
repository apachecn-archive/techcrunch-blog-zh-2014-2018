<html>
<head>
<title>PornHub uses computer vision to ID actors, acts in its videos | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PornHub 使用计算机视觉来识别演员，在其视频中表演</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2017/10/11/pornhub-uses-computer-vision-to-id-actors-acts-in-its-videos/">https://web.archive.org/web/https://techcrunch.com/2017/10/11/pornhub-uses-computer-vision-to-id-actors-acts-in-its-videos/</a></blockquote><div><header class="article__header ">
	<p class="article__title-wrapper">
						</p><h1 class="article__title translated">PornHub 使用计算机视觉来识别演员，在其视频中表演</h1>
		

			
	
			
	</header>

			<div class="article-content">
				<p id="speakable-summary" class="translated">他们说色情首先采用新技术，porn hub[<a target="_blank" href="https://web.archive.org/web/20230328013523/http://pornhub.com/" rel="noopener">NSFW</a>]，一个听起来像 NSFW 的网站，正在证明这句老话是对的。该网站每天接待 8000 万访客，发现其陈旧过时的手动标记视频的方法是不够的。</p>
<p class="translated">PHub 的团队雇佣了一个机器人，而不是雇人来检查成千上万的视频并手工标记它们。</p>
<p class="translated">PHub 副总裁科里·普莱斯(Corey Price)表示:“最终，我们希望为我们的粉丝提供他们喜欢的任何东西，我们的新模型将能够为他们提供更准确的结果，这有望让他们再次光临。”“这一切都是为了不断更新我们的平台，为我们的粉丝提供最新的技术，让他们在我们的平台上获得尽可能无缝的体验。导航和访问他们想要的东西越容易，他们就越开心。”</p>
<p class="translated">计算机视觉系统可以识别场景中的特定演员，甚至可以识别各种位置和……属性。虽然为家庭观众描述特征集显然非常困难，但该系统可以实时识别单个表演者——在这里的演示中，它甚至可以从侧面识别一个表演者——并且它还可以识别性行为。</p>
<p class="translated"><img decoding="async" class="alignright size-full wp-image-1553235" src="../Images/4c7a23ae69a62010a50f5638fd73a3bd.png" alt="" srcset="https://web.archive.org/web/20230328013523im_/https://techcrunch.com/wp-content/uploads/2017/10/screen-shot-2017-10-10-at-7-17-20-pm.png 934w, https://web.archive.org/web/20230328013523im_/https://techcrunch.com/wp-content/uploads/2017/10/screen-shot-2017-10-10-at-7-17-20-pm.png?resize=150,71 150w, https://web.archive.org/web/20230328013523im_/https://techcrunch.com/wp-content/uploads/2017/10/screen-shot-2017-10-10-at-7-17-20-pm.png?resize=300,143 300w, https://web.archive.org/web/20230328013523im_/https://techcrunch.com/wp-content/uploads/2017/10/screen-shot-2017-10-10-at-7-17-20-pm.png?resize=768,365 768w, https://web.archive.org/web/20230328013523im_/https://techcrunch.com/wp-content/uploads/2017/10/screen-shot-2017-10-10-at-7-17-20-pm.png?resize=680,323 680w, https://web.archive.org/web/20230328013523im_/https://techcrunch.com/wp-content/uploads/2017/10/screen-shot-2017-10-10-at-7-17-20-pm.png?resize=50,24 50w" sizes="(max-width: 934px) 100vw, 934px" data-original-src="https://web.archive.org/web/20230328013523im_/https://techcrunch.com/wp-content/uploads/2017/10/screen-shot-2017-10-10-at-7-17-20-pm.png"/></p>
<p class="translated">“到目前为止，我们已经在大约 50 万个特色视频中使用了该模型，其中包括用户提交的视频，我们计划在 2018 年初扫描整个库，”Price 说。“很快，这项技术还将用于检测各种性别位置/类别，并能够正确标记它们。”</p>
<p class="translated">面部检测并不是什么新鲜事，即使对移动设备来说也是如此，但该系统更进一步，根据各种属性对视频和图像进行分类。这意味着你可以通过名字或特征找到你的最爱，这一壮举曾经需要大量的数据输入。它的效果如何？</p>
<p class="translated">“非常精确，”普莱斯说。</p>
			</div>

			</div>    
</body>
</html>