# 人工智能数据垄断风险将被英国议员调查

> 原文：<https://web.archive.org/web/https://techcrunch.com/2017/07/19/ai-data-monopoly-risks-to-be-probed-by-uk-parliamentarians/>

英国议会上院要求对人工智能技术的社会经济和道德影响的调查做出贡献。

作为调查的一部分，上议院委员会将考虑以下问题:

*   围绕人工智能的当前兴奋程度有保证吗？
*   普通大众如何为人工智能的更广泛应用做好准备？
*   社会上谁从人工智能的发展和使用中获益最大？谁获益最少？
*   公众对人工智能的理解和参与应该得到改善吗？
*   哪些关键行业将从人工智能的发展和使用中受益？
*   如何解决一些大公司基于数据的垄断，以及与之相关的“赢家通吃”的经济学？
*   人工智能的发展和使用有哪些伦理含义？
*   在什么情况下，人工智能系统相对缺乏透明度(所谓的“黑盒”)是可以接受的？
*   在英国人工智能的发展和使用中，政府应该扮演什么角色？
*   人工智能是否应该被监管？

该委员会表示，它正在寻找“对当前和未来人工智能的发展和使用所提出的问题和问题的务实解决方案”。

人工智能特设委员会主席克莱门特-琼斯勋爵在一份声明中评论说:“这项调查正值人工智能越来越多地吸引行业、决策者和公众的注意力之际。该委员会希望通过这项调查了解人工智能的发展和使用给社会带来了哪些机会，以及可能存在哪些风险。

“我们希望采取务实的态度，并希望确保我们向政府和其他方面提出的建议切实可行。有一些与现在和未来都相关的重要问题需要解决，我们希望帮助提供这些问题的答案。为此，我们需要最广泛的个人和组织的帮助。”

“如果你对人工智能及其任何方面感兴趣，我们希望听到你的意见。如果你对公共政策感兴趣，我们想听听你的意见。如果你对我们要求提供证据的任何问题感兴趣，我们希望听到你的意见，”他补充说。

委员会对证据的要求可以在这里找到。书面意见可通过委员会网页上的[这一网络表格](https://web.archive.org/web/20230306043016/http://www.parliament.uk/business/committees/committees-a-z/lords-select/ai-committee/publications/written-submission-form/)提交。

查询的提交截止日期为 2017 年 9 月 6 日。

## 算法不负责任

最近一段时间，对人工智能社会影响的担忧一直在政治议程上上升，另一个英国议员委员会去年秋天警告政府需要采取积极措施，最大限度地减少人工智能系统中意外产生的偏见，并确保透明度，以便能够审计自主决策和审查系统，以确保人工智能技术按预期运行——并且不会产生不想要的或不可预测的行为。

我们在 TechCrunch 上标记的另一个问题[是有价值的公共资助数据集被渴望数据来支持和培育商业人工智能模型的科技巨头有效剥离的风险。](https://web.archive.org/web/20230306043016/https://techcrunch.com/2016/07/09/we-need-to-talk-about-ai-and-access-to-publicly-funded-data-sets/)

例如，自 2015 年以来，谷歌旗下的 DeepMind 一直在与英国国家医疗服务信托基金建立一系列数据共享合作关系，这为其提供了对数百万公民医疗信息的[访问](https://web.archive.org/web/20230306043016/https://techcrunch.com/2016/05/04/concerns-raised-over-broad-scope-of-deepmind-nhs-health-data-sharing-deal/)。其中一些伙伴关系[明确涉及 AI](https://web.archive.org/web/20230306043016/https://techcrunch.com/2016/07/05/deepmind-partners-with-nhs-eye-hospital-to-conduct-ai-research/)；在其他情况下，它已经开始构建临床任务管理应用程序，但将人工智能应用于相同的健康数据集是一个明确的近期目标。

最近还有消息称，DeepMind 并没有对 NHS 信托基金的应用开发和研究工作收费——相反，它的“价格”似乎是访问明显高度敏感的(公共资助的)数据集。

这令人担忧，因为显然只有少数公司有足够的财力有效地“购买”高度敏感的公共资助数据集的访问权——即通过提供五年的“免费”工作来换取访问权——使用这些数据开发新一代人工智能产品。一个小的创业公司不能指望和 Alphabet-Google 这样的巨头在同样的条件下竞争。

基于数据的垄断和“赢家通吃”经济学的风险应该是显而易见的。公众迫切需要就如何最好地监管这一新兴行业进行辩论，以便未来的财富和人工智能技术力量带来的任何好处能够得到广泛分配，而不是简单地锁定平台权力。

在另一个与 DeepMind Health 在英国的活动有关的转折中，该国的数据保护监管机构本月早些时候裁定[该公司与 NHS 信托的首次数据共享安排违反了英国隐私法。为了联合开发一个临床任务管理应用程序，以提供关于患者患肾病风险的警报，共享约 160 万份病历既没有征求也没有获得患者的同意。](https://web.archive.org/web/20230306043016/https://techcrunch.com/2017/07/03/uk-data-regulator-says-deepminds-initial-deal-with-the-nhs-broke-privacy-law/)

皇家免费 NHS 信托基金现在有三个月的时间来改变它与 DeepMind 的合作方式，以使这种安排符合英国数据保护法。

在这种情况下，有问题的应用程序不涉及 DeepMind 应用任何人工智能。然而，在 2016 年 1 月，该公司和同一家信托公司达成了更广泛的雄心，即[在五年内将人工智能应用于医疗数据集](https://web.archive.org/web/20230306043016/https://techcrunch.com/2016/06/08/nhs-memo-details-googledeepminds-five-year-plan-to-bring-ai-to-healthcare/)。因此，DeepMind Health 现在参与的 NHS 应用程序开发免费服务显然是为未来广泛的人工智能铺平了道路。

健康数据隐私组织 [medConfidential](https://web.archive.org/web/20230306043016/https://medconfidential.org/) 的协调员萨姆·史密斯对上议院的调查进行了评论，他是 DeepMind 如何获得 NHS 患者数据的早期批评者，他告诉我们:“这次调查很重要，特别是考虑到我们从 DeepMind 滥用 NHS 数据中看到的非法行为。人工智能略有不同，但规则仍然适用，这种公共领域的专家审查将推动辩论。”