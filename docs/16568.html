<html>
<head>
<title>The real consequences of fake porn and news • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">虚假色情和新闻的真实后果TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/02/08/the-real-consequences-of-fake-porn-and-news/?ncid=rss">https://web.archive.org/web/https://techcrunch.com/2018/02/08/the-real-consequences-of-fake-porn-and-news/?ncid=rss</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated"><span class="featured__span-first-words">一场禁止<a target="_blank" href="https://web.archive.org/web/20230130023902/https://motherboard.vice.com/en_us/article/gydydm/gal-gadot-fake-ai-porn" rel="noopener">非自愿色情</a>的运动</span>正在进行中，这种视频使用TensorFlow等机器学习库将不情愿的参与者的脸叠加到色情演员的身体上。昨天，正如TC的Taylor Hatmaker指出的，<a target="_blank" href="https://web.archive.org/web/20230130023902/https://techcrunch.com/2018/02/07/deepfakes-fake-porn-reddit-twitter-ban/" rel="noopener"> Reddit发布了禁止此类图片和视频的内容政策</a>，同时还关闭了一系列致力于此的子网站。Pornhub和其他社交媒体网站最近几周也发布了类似的政策。</p>
<p class="translated">然而，色情仅仅是一个无意识的虚假内容世界的先兆。本周早些时候，政治学家亨利·j·法雷尔(Henry J. Farrell)和《尼克森兰》(Nixonland)的作者里克·珀尔斯坦(Rick Perlstein)在《纽约时报》上写了一篇题为“<a target="_blank" href="https://web.archive.org/web/20230130023902/https://www.nytimes.com/2018/02/04/opinion/hacking-politics-future.html" rel="noopener">我们可驾驭的政治未来</a>”的专栏文章。在他们近乎反乌托邦的世界里，党派破坏者可以通过制作虚假视频，比如候选人与一名青少年发生性关系的视频，来破坏一名政客的候选人资格。预计，作者担心“假视频和音频可能变得如此令人信服，以至于无法与真实录音区分开来，导致音频和视频证据在法庭上不可接受。”</p>
<p class="translated">对于一个民主社会来说，真理的假设通常是对大多数内容的默认反应，我们很快就会生活在一个没有相反证据的一切都必须被认为是假的世界。这就好像我们突然搬到了一个专制国家，需要不断驳回我们每天看到的宣传。当谈到初创公司、科技公司、政党和政府共同面临的政策问题时，这一挑战就像它们来时一样棘手。</p>
<p class="translated">举一个Reddit可能迟早会遇到的情况:一个政客与一名青少年发生性关系的模糊视频被发布(出于某种原因，这是典型的例子)。该视频的真实性尚不清楚——没有明显的篡改迹象，但它可能是，事实上，甚至可能是假的。Reddit是做什么的？他们会为了“安全起见”而禁止可能成为世纪政治丑闻的事情吗？</p>
<p class="translated">不过，这只是挑战的第一层。为了看清所有细节的艰巨性，让我们挑选一个比政客或名人的虚假色情视频更复杂的例子。相反，想象一下，一个独裁政权的持不同政见者用他们的智能手机拍摄暴行的视频，比如该政权的安全部队大规模杀害抗议的平民。这个视频是真实的，是现场录制的，并匿名发布到互联网上。</p>
<p class="translated">在一个假货占主导地位的世界里，突然会有一个直接的问题，那就是这个视频到底是什么。完全有可能的是，一个持不同政见的团体会制作一个假视频来引起人们对他们困境的关注，并吸引媒体的注意。该政权公布了自己的视频，显示街道完全安全畅通。那些相信持不同政见者的人会相信他们，而那些相信政权的人会继续相信他们。原始视频的说服力就丧失了。</p>
<p class="translated">这让我们想到了在我的圈子里讨论的最明显的解决方案:为视频建立一个加密的、可验证的“监管链”(我感觉到“b”字以一个<em>块</em>开始，以一个<em>链结束)。</em>这个想法是，如果在这个即将到来的世界里，所有的内容都被认为是假的，那么让我们使用加密技术来创建元数据，以证明特定内容的出处。事实上，已经有一些初创公司瞄准了这个市场，比如<a target="_blank" href="https://web.archive.org/web/20230130023902/http://prover.io/" rel="noopener"> Prover.io </a>，它正在<a target="_blank" href="https://web.archive.org/web/20230130023902/https://medium.com/prover/can-blockchain-deal-with-authenticity-issues-1ecafb07c8f" rel="noopener">构建一个视频认证服务</a>来应对我在上面的例子中提出的挑战。</p>
<p class="translated">只有一个问题:身份，或者至少是设备验证，通常是这些链运行的先决条件。毕竟，我们正在努力证明监管链，监管链需要知道哪个设备或个人制作了视频。这些信息对独裁政权来说非常有价值，他们很想知道是哪个持不同政见者拍摄了那段视频，然后马上回击，而不是用相机。</p>
<p class="translated">也许视频创建者将有细粒度的访问控制来管理谁可以看到身份元数据，这样他们可以假设向纽约时报证明视频，但不会显示政权。也许区块链可以匿名，保护持不同政见者。但请记住，我们正在努力证明这是一个真实的视频，每一次混淆创作者身份的尝试都只是对其真实性的又一个打击。</p>
<p class="translated">另一个可能广泛使用的解决方案是认证软件，它可以扫描视频并确定它是否是伪造的。机器学习可能会做得非常好，但它可能不会对每个像素都正确。就像今天的照片分析师拥有确定特定图像是否经过PS处理的技术一样，我们的世界可能很快就会有算法工具来评估图像和视频，以供机器学习编辑。</p>
<p class="translated">我承认这项技术将会存在，但它真的重要吗？Politifact的<a target="_blank" href="https://web.archive.org/web/20230130023902/http://www.politifact.com/truth-o-meter/statements/" rel="noopener"> Truth-o-Meter </a>是一个公认的、相当客观的第三方验证服务，用于验证政治家使用(和滥用)的事实。很好的服务，但是他们不能阻止政客滥用事实和证据，也不能靠谎言当选。为什么我们会突然期望认证软件对人们的信仰有更大的影响？</p>
<p class="translated">最后，阻止这些虚假视频传播的政治选择也同样有限。这些视频背后的技术有很多合法用途，包括好莱坞特效，所以禁止它几乎没有意义。监管这些视频的使用似乎也是徒劳的，因为许多视频都是匿名制作的，而且可能跨越国界，因此无法强制执行。言论自由保护，至少在美国，可能会保护这些视频的创作。只要把“诽谤”换成“艺术”或“讽刺”，就有一个合理的理由允许至少一些这样的视频进入我们的话语。</p>
<p class="translated">也许更好的教育会让我们对这些视频免疫。也许某样东西是不是假，会比我们今天想的更明显。也许我们对媒体的信任会复苏，媒体会为我们仔细过滤垃圾内容。也许吧。</p>
<p class="translated">更有可能的是，在这个世界里，我们将不得不接受我们消费的每一个故事、图像和视频都被篡改过，可能完全是虚构的。我们，创业公司创始人和生态系统中的其他人，将不得不为民主建立新的工具，以继续按照我们的预期运行。假色情和假新闻的世界已经在我们面前，反击的工具甚至还没有准备好。</p>
			</div>

			</div>    
</body>
</html>