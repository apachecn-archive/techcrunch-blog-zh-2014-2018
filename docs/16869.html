<html>
<head>
<title>No one wants to build a "feel good" internet • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">没有人想建立一个“感觉良好”的互联网 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/03/03/no-one-wants-to-build-a-feel-good-internet/">https://web.archive.org/web/https://techcrunch.com/2018/03/03/no-one-wants-to-build-a-feel-good-internet/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">如果说如今几乎每家科技公司都面临着一个政策困境，那就是如何应对“内容节制”，这是一个近乎奥威尔式的审查术语。</p>
<p class="translated">一周多前，Buzzfeed 的查理·沃泽尔尖锐地提出了这个问题:“为什么一个普通的未经训练的人能做一些以创新为荣的价值数十亿美元的技术公司做不到的事情？除此之外，为什么在恶意的骗局和错误信息使多起国家悲剧政治化之后，还需要问这样一个问题？”</p>
<p class="translated">多年来，像脸书、Twitter、YouTube 和其他公司都避免<a href="https://web.archive.org/web/20221205162803/https://www.wired.com/2014/10/content-moderation/" target="_blank" rel="noopener">投入大量资源来实施审核</a>，更喜欢相对较小的审核团队和基本的众包标记工具来优先处理最糟糕的违规内容。</p>
<p class="translated">尽管在过去的几个月里，思想上发生了某种革命，因为面对公众的一再抗议，对内容节制的反对逐渐消退。</p>
<p class="translated"><a href="https://web.archive.org/web/20221205162803/https://www.facebook.com/notes/mark-zuckerberg/building-global-community/10154544292806634/" target="_blank" rel="noopener">马克·扎克伯格在全球社区</a>的致辞中问道:“在一个世界上任何人都可以影响我们的世界里，我们如何帮助人们建立一个安全的社区，防止伤害，在危机期间提供帮助，并在危机后进行重建？”与此同时，<a href="https://web.archive.org/web/20221205162803/https://twitter.com/jack/status/969234275420655616" target="_blank" rel="noopener">杰克·多西本周在推特上写道,</a>“我们承诺推特将帮助提高公共对话的集体健康、开放和文明程度，并让我们自己对进步公开负责。”</p>
<p class="translated">这两条信息都是对更好的社区和诚信的美好赞歌。只有一个问题:这两家公司都不想涉入审查政治，而这正是打造一个“感觉良好”的互联网所需要的。</p>
<p class="translated">就拿最近的例子来说。周五,《纽约时报》写道，脸书将允许男性赤裸上身的照片出现在平台上，但会屏蔽女性暴露背部皮肤的照片。“对于广告客户来说，与那些人类评论者争论什么是‘成人内容’可能会令人沮丧，”文章指出。年轻女性在线零售商“再见面包”表示，去年 12 月，该公司与脸书就一名年轻女性穿豹纹网眼衬衫的形象展开了激烈辩论。脸书说这张照片太挑逗了</p>
<p class="translated">或者把时间倒回到关于尼克·尤特的著名越战照片《凝固汽油弹女孩》的争议中<a href="https://web.archive.org/web/20221205162803/https://www.nytimes.com/2016/09/10/technology/facebook-vietnam-war-photo-nudity.html" target="_blank" rel="noopener">脸书的内容节制最初禁止了这张照片</a>，随后在公众对审查制度的强烈抗议下，该公司解除了禁令。是裸露吗？嗯，是的，有胸部暴露。暴力吗？然而，这是一张战争的照片。</p>
<p class="translated">无论你的政治观点如何，无论你倾向于或反对暗示性或暴力性的图像，现实是在这些案例中没有明显的“正确”答案。脸书和其他社交网络正在决定品味，但品味在不同的群体和不同的人之间差异很大。这就好像你把《阁楼》和《聚焦家庭杂志》的观众融合在了一起，并向他们提供了相同的编辑产品。</p>
<p class="translated">回想起来，沃泽尔问题的答案显而易见。没错，科技公司未能在内容适度方面投资，原因很明确:这是有意为之。关于工作有一句老话:如果你不想被要求做某件事，那就做得非常非常糟糕，这样就没有人会要求你再做一次。硅谷的科技公司非常非常不擅长内容适度，不是因为他们做不到，而是因为他们特别不想做。</p>
<p class="translated">不难理解为什么。压制言论不仅违背了美国宪法及其第一修正案，也违背了弥漫在硅谷公司中的自由主义精神，还违背了安全港法律框架，该框架从一开始就保护网站不对其内容负责。没有一家公司希望同时跨越这么多绊网。</p>
<p class="translated">我们也要清楚，有很多方法可以大规模地进行内容适度。如今，中国通过一系列技术<a href="https://web.archive.org/web/20221205162803/https://www.bloomberg.com/quicktake/great-firewall-of-china" target="_blank" rel="noopener">来做到这一点，这些技术通常被称为“防火长城”</a>，还有<a href="https://web.archive.org/web/20221205162803/https://www.cnn.com/2013/10/07/world/asia/china-internet-monitors/index.html" target="_blank" rel="noopener">一大批内容版主</a>，据估计人数超过 200 万。南韩，<a href="https://web.archive.org/web/20221205162803/https://freedomhouse.org/report/freedom-world/2017/south-korea" target="_blank" rel="noopener">一个被自由之家</a>评为自由的民主国家，有着<a href="https://web.archive.org/web/20221205162803/http://www.koreaherald.com/view.php?ud=20150730001129" target="_blank" rel="noopener">的<a href="https://web.archive.org/web/20221205162803/http://www.nytimes.com/2012/08/24/world/asia/south-korean-court-overturns-online-name-verification-law.html" target="_blank" rel="noopener">复杂历史</a>要求互联网上的评论</a>附加到用户的国民身份证号上，以防止“错误信息”的传播。</p>
<p class="translated">脸书、谷歌(以及推而广之的 YouTube)和 Twitter 都达到了一定的规模，如果他们真的想这样做的话，他们可以用这种方式进行内容审核。脸书可以在中西部雇用成千上万的人，并提供体面的报酬，灵活的工作，阅读帖子和核实图片。帖子可能需要用户的社会安全号码，以确保内容来自善意的人。</p>
<p class="translated">截至去年，YouTube 上的用户每分钟上传 400 小时的视频。维护实时内容审核需要 24，000 人全天候工作，成本为每天 860 万美元或每年 31 亿美元(假设每小时工资为 15 美元)。这当然是一个非常自由的估计:人工智能和众包标记至少可以提供某种程度的杠杆作用，几乎可以肯定的是，不是每个视频都需要仔细或实时审查。</p>
<p class="translated">是的，它很贵——YouTube 的财务状况没有被 Alphabet 披露，但分析师认为这项服务的收入高达 150 亿美元。是的，雇佣和培训成千上万的人是一项艰巨的任务，但是如果这些公司中的任何一家真的想做的话，互联网是可以变得对用户“安全”的。</p>
<p class="translated">但我们又回到了之前提出的挑战:YouTube 的品味是什么？什么是允许的，什么是不允许的？中国通过宣布某些在线讨论非法来解决这个问题。例如，中国数字时报广泛报道了政府发布的关于特别有争议话题的词汇黑名单。</p>
<p class="translated">这并不意味着规则缺乏细微差别。Gary King 和哈佛大学<a href="https://web.archive.org/web/20221205162803/https://gking.harvard.edu/publications/how-censorship-china-allows-government-criticism-silences-collective-expression" target="_blank" rel="noopener">的一组研究人员在一项出色的研究中得出结论，中国允许批评政府</a>，但明确禁止任何呼吁集体行动的对话——通常即使是支持政府的对话。对于内容版主来说，这是一条非常清晰的明线，更不用说犯错误是没问题的:如果一个帖子不小心被屏蔽了，中国政府真的不在乎。</p>
<p class="translated">令人欣慰的是，美国很少有言论规则，而今天的内容审核系统通常会迅速处理这些规则。剩下的是对一些人来说越界的模糊言论，而对另一些人来说不是，这就是为什么脸书和其他社交网络因屏蔽凝固汽油弹女孩或女性身体的背面而受到媒体的严厉批评。</p>
<p class="translated">脸书巧妙地解决了所有这些问题。它宣称<a href="https://web.archive.org/web/20221205162803/https://techcrunch.com/2018/01/11/facebook-time-well-spent/" target="_blank" rel="noopener">它希望 feed 显示更多来自家人和朋友的内容</a>，而不是那种过去有争议的病毒式内容。通过关注来自朋友的内容，订阅源可以显示更积极、更吸引人的内容，从而改善用户的精神状态。</p>
<p class="translated">我说这很巧妙，因为强调来自家人和朋友的内容实际上只是进一步隔离用户回音室的一种方法。社会学家长期以来一直在研究社交网络“同人”,即人们认识与自己相似的人的强烈倾向。一个朋友分享一篇文章不仅仅是更有意义，它也是你更有可能首先同意的内容。</p>
<p class="translated">我们是想生活在一个回音室里，还是想被负面的，有时是有害的内容轰炸？当我说建立一个感觉良好的互联网是不可能的时候，这最终就是我的意思。我们越想在我们的内容流中看到积极向上的故事，我们就越需要剔除 Twitter 和其他社交网络提供的种族主义和卑鄙的材料，以及民主公民所必需的关于政治、战争和和平的负面故事。</p>
<p class="translated">无知最终是福，但是互联网被设计来以最快的速度提供最多的信息。这两个目标是直接竞争的，硅谷公司在避免深度内容节制方面正当地拖延时间。</p>
			</div>

			</div>    
</body>
</html>