<html>
<head>
<title>Who is to blame for algorithmic outrage? • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谁该为算法愤怒负责？TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2017/09/17/who-is-to-blame-for-algorithmic-outrage/?ncid=rss">https://web.archive.org/web/https://techcrunch.com/2017/09/17/who-is-to-blame-for-algorithmic-outrage/?ncid=rss</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated"><span class="featured__span-first-words">本周，我们看到了</span>几个高调(但老实说，影响不大)的展示，展示了由主要互联网公司制作或建议的、将广告瞄准不良群体的能力。</p>
<p class="translated">"仇视犹太人"吗？脸书的广告后台说，虽然不多，但还是要努力去做。谷歌建议，尝试添加“烤箱中的犹太人”来扩大你的影响范围。Twitter 表示，“纳粹”可能会吸引 1860 万用户。</p>
<p class="translated">当被告知这些令人困惑的明显的系统滥用时，这些公司的反应都是同样的:“这违反了我们的规则，我们不知道它是如何发生的，现在已经解决了。”</p>
<p class="translated">我不是唯一一个发现这种做作的担忧、单片眼镜爆裂般的震惊和自信的偏转难以令人信服的人。</p>
<p class="translated">有很多关于在各种平台上打击仇恨言论和对抗算法偏见的非常真实的可能性的谈论。这些事情在每一个可能的场合都受到强烈谴责，有时，就像 StormFront 的烫手山芋主持一样，甚至有机会以较小的代价展示一家公司对这一概念的奉献。</p>
<p class="translated">但是，这些公司似乎非常乐意从针对“希特勒没做错什么”等群体的广告中赚钱。</p>
<p>	</p><div class="article-block block--pullout block--right">
		<blockquote class="translated">他们的数千名员工、敬业的工作组和多元化官员怎么没有一个人预见到这一点？</blockquote>
	</div><p class="translated">当然，当有人公开展示它有多简单时，他们会欣然接受，即使是在极端的情况下。他们指出，广告很快就被关闭了——只有少数人看过。这总是违反规则的。它可能不会通过人类的审查。不管怎样，我们修好了。</p><p class="translated">无论是现在还是将来，我们为什么要相信他们？</p>
<p class="translated">这不是什么精心策划的黑客攻击。有人真的把“纳粹”这样的词放进了地球上一些最大的数字平台的普通广告系统中——这些平台反复明确地声明<a target="_blank" href="https://web.archive.org/web/20230130002633/https://techcrunch.com/2017/02/08/facebook-updates-its-ad-policies-and-tools-to-protect-against-discriminatory-practices/" rel="noopener">致力于</a>不允许<em>做同样的事情</em>。他们的数千名员工、敬业的工作组和多元化官员怎么没有一个人预见到这一点？</p>
<p class="translated">在这里，大量的双重思考是必要的，以证明这些公司表面上为打击仇恨言论所做的巨大努力，以及它们在严格控制的货币化系统上明显无力阻止仇恨言论。认为这些公司可能不愿意对赚钱的部分进行限制是不是有点愤世嫉俗？我要问为什么我们一开始就应该假定他们是无辜的。</p>
<p class="translated">反身旋转很简单:但它是用户！我们怎么能预测到这样的事情呢？</p>
<p class="translated">嗯，如果他们不能预测，也许他们不应该做出如此显眼的承诺，防止它。这些事件的责任完全在于公司本身。他们通过制造盲目地从用户那里获取和建议信息的系统创造了这个机会，并且未能提供保护来防止基本的滥用。让我们不要假装这是这些系统唯一的滥用，他们会从中获利——脸书向俄罗斯机器人网络出售了价值 10 万美元(或 500 万卢布)的政治广告。</p>
<p>	</p><div class="article-block block--pullout block--right">
		<blockquote class="translated">如果他们不能预测它，也许他们不应该做出如此显眼的承诺来防止它。</blockquote>
	</div><p class="translated">不过，别担心。那不是</p><em>allowed</em><p class="translated">！他们</p><em>have</em><p class="translated">针对这种事情的保护措施！</p><p class="translated">不要相信这些站不住脚的借口。空谈是廉价的，尤其是在科技领域。</p>
<p class="translated">如果这些平台希望我们相信他们在认真对待这件事，并希望我们相信他们在为此投入真正的资源——不是为了防止像本周进行的概念验证测试这样的琐碎滥用，而是更深层次、更微妙的策略——他们需要展示他们的工作。</p>
<p class="translated">谷歌、脸书、推特和其他公司应该公开进行他们的仇恨言论和言论自由运动，并提供每一个显著的细节。</p>
<p class="translated">首先:防止某些滥用行为的制度是什么？如何创建和维护攻击性术语集？审核算法是在什么数据上训练的？如何整合反馈，如何对决定提出上诉？哪里还需要人为干预？这与平台的言论自由目标相一致吗？</p>
<p class="translated">如果我们要了解这些系统是否工作，它们是否有效，以及它们需要改进的地方，这些和其他问题的答案是必要的。毕竟，它们是为了我们的利益，对吗？</p>
<p class="translated">这些公司说他们正在努力，这还不够好。如果他们要宣扬自己在开放和包容原则上的领导力和奉献精神，他们有责任以最大的透明度来实现这一点。给我们看看数据。<em>然后</em>我们会相信他们关心。</p>
			</div>

			</div>    
</body>
</html>