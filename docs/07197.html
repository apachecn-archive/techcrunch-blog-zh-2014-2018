<html>
<head>
<title>Artificial intelligence and racism • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能和种族主义TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2016/04/15/artificial-intelligence-and-racist/?ncid=rss">https://web.archive.org/web/https://techcrunch.com/2016/04/15/artificial-intelligence-and-racist/?ncid=rss</a></blockquote><div><p class="translated">NPR的劳拉·西德尔决定通过一篇新闻报道进一步探究这个话题，她问了一个相对简单的问题:“<a target="_blank" href="https://web.archive.org/web/20221007160504/http://www.npr.org/2016/03/14/470427605/can-computers-be-racist-the-human-like-bias-of-algorithms">计算机会有种族歧视吗？</a></p>
<div class="fb-video">
<p class="translated">Sydell呼吁<a target="_blank" href="https://web.archive.org/web/20221007160504/http://arxiv.org/ftp/arxiv/papers/1301/1301.6822.pdf"> Latanya Sweeney的2013年研究</a>提供犯罪背景调查服务的公司购买Google AdWords。Sweeney的发现表明，当某人谷歌一个传统上“听起来像黑人”的名字时，例如，DeShawn、Darnell或Jermaine，返回的广告结果表明被捕的比率明显高于如果查询的名字是一个传统上“听起来像白人”的名字，例如Geoffrey、Jill或Emma。</p>
<p class="translated">值得注意的是，该算法实际上并不考虑逮捕率。即使广告显示某人可能已经被捕，背景调查公司的数据库中也完全有可能没有这个人。斯威尼教授在谷歌上搜索自己的名字时直接发现了这一点。</p>
<p class="translated">很难说出这些广告可能会潜移默化地或以其他方式煽动起什么类型的偏见。在权衡两个候选人的时候，一个黑人一个白人，雇主可能会在谷歌上快速搜索这两个名字。尽管存在反歧视法，但你永远不知道招聘经理会得出什么样的结论，如果他们看到一则广告，错误地指出黑人候选人已经被捕，而白人候选人没有——而事实可能恰恰相反。种族主义的微妙影响可能出乎意料地强大。</p>
<p class="translated">康奈尔大学的另一项<a target="_blank" href="https://web.archive.org/web/20221007160504/http://arxiv.org/abs/1408.6491">研究</a>指出，这些相同的谷歌AdWords算法也可能表现出性别歧视，指出当用户表示她是女性时，结果中广告的高薪职位空缺明显少于如果用户是男性。</p>
<p>	</p><div class="article-block block--pullout block--right">
		<blockquote class="translated">种族主义的微妙影响可能出乎意料地强大。</blockquote>
	</div>
	
<p class="translated">一些人认为，当大多数从事算法工作的程序员不够多样化时，你就会看到这些结果，例如，在寻求编码职业的学生中，男女比例失调<a target="_blank" href="https://web.archive.org/web/20221007160504/http://blog.meetearnest.com/post/124681853562/coding-schools-a-new-fashioned-career-path">2:1</a>。当谷歌的在线照片识别系统将几名<a target="_blank" href="https://web.archive.org/web/20221007160504/http://www.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">黑人用户识别为某种动物</a>时，在科技行业占多数的西方白人男性也受到了类似的质疑。</p>
<p class="translated">虽然这些问题的根源已被正式梳理出来，但密歇根大学的<a target="_blank" href="https://web.archive.org/web/20221007160504/http://www.npr.org/2016/03/14/470427605/can-computers-be-racist-the-human-like-bias-of-algorithms">克里斯蒂安·桑德维格</a>认为，普通搜索用户带来的固有偏见是罪魁祸首，而不是固有的编程。</p>
<p class="translated">“因为人们倾向于点击暗示此人已被逮捕的广告主题，当名称是非洲裔美国人时，算法学习了搜索用户的种族主义，然后通过更频繁地显示来加强这一点，”桑德维格说。</p>
<p class="translated">对于那些不熟悉谷歌等搜索引擎如何工作的人来说，有数百个因素决定了你搜索的内容，但其中一个因素恰好基于用户反馈。该算法跟踪你点击的内容，然后自我调整，向你显示与你“更相关”的内容和广告。</p>
<p class="translated">基本上，桑德维格是说，该算法可能已经开始种族平等，但因为人们倾向于相信，涉及“听起来像黑人”的名字的逮捕比涉及听起来像白人的名字的逮捕更有可能是真的，所以更多的人愿意点击它进行调查。不管我们知不知道，我们总是看到这种情况。例如，YouTube的“推荐视频”或网飞的“推荐标题”，会根据你以前看过的内容给出个性化的建议。</p>
<p class="translated">从这些例子中(尤其是从微软的Tay中)，我们可以得出结论，算法和计算机可以受到人类的影响，有意或无意地产生种族主义的结果，使这些机器本质上…嗯，种族主义者。对吗？</p>
<p class="translated">这就是事情变得棘手的地方。在社会背景的框架内，他们绝对是种族主义者。但是如果没有独特的人类社会视角，种族是不可能被看到的。这是因为种族在技术上是不存在的。艾伦·邓普顿在1998年证明了这一点，当时他对基因组进行了测序，并没有发现基于DNA的证据支持人类存在不同“种族”的观点。</p>
<p class="translated">“邓普顿的论文表明，如果我们被迫根据生物特征将人分组，我们就真的有麻烦了。人类学家罗伯特·苏斯曼博士在谈到这一发现时说:“(T2)简单的划分在科学上几乎是不可能的，但是我们已经发展出了简单的社会划分方法。”。</p>
<p class="translated">那么如果种族不存在，种族主义怎么可能存在呢？</p>
<p class="translated">引用<a target="_blank" href="https://web.archive.org/web/20221007160504/https://books.google.com/books?id=ZdT-CgAAQBAJ&amp;pg=PT73&amp;lpg=PT73#v=onepage&amp;q&amp;f=false">查尔斯·米尔斯</a>教授的话:“……因为人们开始认为自己是“种族”，例如黑人和白人，这些与自然种类不对应的类别获得了一种社会现实。主体间性创造了某种客观性。”</p>
<p class="translated">温莎大学的Matthew T. Nowachek将此作为他证明人工智能永远不会成为种族主义者的公式的一部分。在他的<a target="_blank" href="https://web.archive.org/web/20221007160504/http://phaenex.uwindsor.ca/ojs/leddy/index.php/phaenex/article/download/4013/3227">论文</a>中，他认为“机器人不可能成为种族主义者，因为它们的本体论没有考虑到与社会世界的适当关系，而这种关系是学习种族主义所必需的，而种族主义是从社会实践的角度来理解的。”</p>
<p class="translated">用通俗的话来说，Nowachek指出，因为种族主义是社会的一种工具，除了不断变化的社会赋予它的意义之外，它没有任何意义，AI将发现种族主义本身或其行为没有任何相关性，即使它可以接收种族暗示。这可能只是一个事实，即人工智能一直在评估现实世界中的变量，并能够将自己从那个世界中分离出来，这样机器人就永远不会成为种族主义者。</p>
<p>	</p><div class="article-block block--pullout block--left">
		<blockquote class="translated">我们可以得出结论，算法和计算机会受到人类的影响。</blockquote>
	</div>
	
<p class="translated">为了说明以上所述，你必须理解人类的思维是如何沉浸在一项活动或任务中的。想象一个戴着护垫和头盔多年的足球运动员。第一次戴护垫的人可能会感到心烦意乱和不舒服。另一方面，经验丰富的球员会下意识地放弃对他的设备的感觉的关注，转而将他的智力转移到分析防守位置和潜在的接球路线。他会觉得在他的设备里像在家里一样，几乎就像它是他的一部分。</p>
<p class="translated">Nowachek认为，AI永远无法做到这一点，无法像人类一样沉浸在世界中，无法“忘记”自己戴着护垫。人工智能将无限地意识到它在任何时候都在做什么，无法摆脱它总是将自己的存在与现实分开的能力。</p>
<p class="translated">另一方面，人类创造并生活在一个真实存在种族的世界，在这个世界里，种族的差异被记录为“常识”和直觉。这两个品质一直被认为是人工智能永远不会具备的，至少在很多年内不会。然而，AlphaGo击败李世石正在挑战这种<a target="_blank" href="https://web.archive.org/web/20221007160504/http://www.latimes.com/business/la-fi-alpha-go-victory-20160315-htmlstory.html">认知</a>。</p>
<p class="translated">因此，一方面，你有拉坦亚·斯威尼，他清楚地表明，学习算法，本质上可以被认为是人工智能的低级形式，可以被人类操纵来产生种族主义的结果。另一方面，你有Nowachek和他的资料来源的哲学，认为真正的人工智能永远不会成为种族主义者，正是因为它缺乏允许人类首先成为并潜意识地表现出种族主义的品质。</p>
<p class="translated">无论他的哲学是否正确，Nowachek的文章有助于挑战“种族主义只是无知或错误信仰的认知问题的普遍观点”，并在阐明人类感知存在的方式和种族主义本身之间的联系方面具有重要意义。</p>
<p class="translated">所以让我们回到首要问题:“人工智能会变成种族主义者吗？”</p>
<p class="translated">可惜，不可能知道。只有时间会告诉我们…但它可能很快就会告诉我们。</p>
<p class="translated">我们将以Android Dick的一句话作为结束，他是一个人工智能机器人，被问及他的编程:</p>
<p class="translated">“很多人问我是否能做出选择，或者我做的一切都是被编程的。我对此的最佳回应是，人类、动物和机器人所做的一切都在一定程度上被编程了。随着技术的进步，预计我将能够整合我在网上和实时听到的新单词。我可能不会把每件事都做对，说错话，有时可能不知道该说什么，但我每天都在进步。很不寻常，是吧？”</p>
<p class="embed breakout embed--video embed--youtube translated"><iframe src="https://web.archive.org/web/20221007160504if_/https://www.youtube.com/embed/UIWWLg4wLEY?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="">视频</iframe></p>
</div>
</div>    
</body>
</html>