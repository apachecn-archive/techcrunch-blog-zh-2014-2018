# 麻省理工学院 CSAIL 研究提供了一种完全自动化的方法来窥视神经网络内部

> 原文：<https://web.archive.org/web/https://techcrunch.com/2017/06/30/mit-csail-research-offers-a-fully-automated-way-to-peer-inside-neural-nets/>

# 麻省理工学院 CSAIL 研究提供了一种完全自动化的方法来窥视神经网络内部

麻省理工学院的计算机科学和人工智能实验室设计了一种方法来观察神经网络内部，并揭示它们实际上是如何做出决定的。这个[新流程是其背后的研究团队两年前展示的系统的全自动版本](https://web.archive.org/web/20230307030204/http://news.mit.edu/2017/inner-workings-neural-networks-visual-data-0630)，该系统雇佣了人工审查人员来达到相同的目的。

想出一种无需人工审查就能提供类似结果的方法，可能是帮助我们理解为什么表现良好的神经网络能够取得如此成功的重要一步。当前的深度学习技术留下了许多关于系统如何实际达到其结果的问题——网络采用连续的信号处理层来分类对象，翻译文本或执行其他功能，但我们几乎没有办法深入了解网络的每一层是如何进行实际决策的。

麻省理工学院 CSAIL 团队的系统使用经过修改的神经网络来报告每个节点对给定输入图像的响应强度，然后分析那些产生最强响应的图像。这种分析最初是由土耳其机械工人进行的，他们会根据图像中发现的特定视觉概念对每个图像进行分类，但现在这项工作已经自动化，因此分类是由机器生成的。

这项研究已经为神经网络如何运作提供了有趣的见解，例如，表明一个经过训练为黑白图像添加颜色的网络最终会将其节点的很大一部分集中在识别图片的纹理上。它还发现，训练识别视频中对象的网络将许多节点专用于场景识别，而训练识别场景的网络则恰恰相反，将许多节点用于识别对象。

因为我们[还没有完全理解人类如何思考](https://web.archive.org/web/20230307030204/https://twitter.com/AngeBassa/status/880739186445357056)，分类和识别信息，而且神经网络是基于人类思维的假设模型，这个 CSAIL 团队的研究最终也可能揭示神经科学中的问题。这篇论文将在今年的计算机视觉和模式识别会议上发表，应该会引起人工智能研究界的极大兴趣。