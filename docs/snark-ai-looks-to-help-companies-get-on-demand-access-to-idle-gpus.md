# Snark AI 希望帮助公司按需访问闲置的 GPU

> 原文：<https://web.archive.org/web/https://techcrunch.com/2018/07/25/snark-ai-looks-to-help-companies-get-on-demand-access-to-idle-gpus/>

乘着机器学习使用的爆炸浪潮，嗯，几乎所有事情都是 GPU 的出现，作为处理这些操作的所有处理的首选方法之一。

但是对于一些公司或研究团队来说，获得这些 GPU——无论是使用卡本身还是可能通过 AWS 之类的东西——可能仍然太困难或太昂贵。因此，Davit Buniatyan 和他的联合创始人决定启动 Snark AI，帮助公司在公司的分布式网络中租赁不使用的 GPU，而不是通过亚马逊这样的服务。虽然较大的云提供商提供类似的 GPU 接入，但 Buniatyan 希望它对公司和开发人员具有足够的吸引力，如果他们能够降低准入门槛，就可以开发不同的网络。该公司正在推出 Y Combinator 的 2018 年夏季班。

“我们打赌，采矿和 AWS 或谷歌云价格之间总会有差距，”Buniatyan 说。“如果开采将(比运行 GPU 的成本更有利可图)，任何人都可以进入 AWS，进行开采并实现盈利。我们正在为客户构建一个分布式云计算平台，他们可以轻松访问那里的资源，但却没有被使用。”

这家初创公司与拥有大量闲置 GPU 的公司合作，如游戏云公司或加密采矿公司。需要 GPU 来训练机器学习模型的团队可以访问原始硬件，而只需要那些 GPU 来处理推理的团队可以通过一组 API 来访问它们。这两者是有区别的，因为它们是机器学习的两个方面——前者建立模型，后者用来执行一些任务，如图像或语音识别。Buniatyan 说，当 GPU 空闲时，它们会运行挖掘来支付硬件提供商，Snark AI 还提供了在硬件上同时进行挖掘和运行深度学习推理的能力。

Snark AI 将适当数量的 GPU 能力匹配到团队需要的任何东西，然后将其部署到公司在各个数据中心拥有的分布式闲置卡网络中。随着时间的推移，这是一种潜在降低 GPU 成本的方法，这可能是一项巨大的投资，但随着时间的推移，当它不在使用时，会获得回报。如果是这样的话，这也可能会鼓励更多的公司注册这样的网络——Snark AI 或其他——并部署类似的卡。

还有一种新兴的趋势是专注于机器学习或推理的专用芯片，这些芯片旨在降低机器学习任务的成本、功耗或空间要求。这个创业公司生态系统，像 Cerebras Systems、Mythic、Graphcore 或任何其他资金雄厚的创业公司，都有可能取代 GPU 来完成机器学习任务。还有 ASICs 的出现，定制芯片更适合加密挖掘等任务，这可能会破坏这样的生态系统——特别是如果大型云提供商决定建立或部署类似的东西(如谷歌的 TPU)。但这也意味着有可能创建一些新的界面层的空间，这些界面层可以为公司可能需要的任务捕捉所有剩余的东西，但不一定需要那些初创公司的尖端技术。

在 Dropbox 显著专注于企业和协作之前，总会有同样的论点:随着它变得更加商品化，价格会大幅下降。对于亚马逊和谷歌这样的公司来说，情况可能尤其如此，它们已经在运行这种剧本，并可能利用它们在云计算领域的主导地位，对 Snark AI 这样的第三方网络施加巨大压力。谷歌也有能力建立专有硬件，如用于专门操作的 TPU。但 Buniatyan 表示，该公司专注于能够兼顾推理和挖掘，此外还为那些只想部署的公司的闲置 GPU 保持低成本，这应该会使其保持可行性，即使是在专注于机器学习的不断变化的生态系统中。