<html>
<head>
<title>Creepy facial projections, 3D hair capture, digital creepers and more from Eurographics 2017 | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">来自Eurographics 2017 | TechCrunch的令人毛骨悚然的面部投影、3D头发捕捉、数字爬虫等</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2017/04/24/creepy-facial-projections-3d-hair-capture-digital-creepers-and-more-from-eurographics-2017/">https://web.archive.org/web/https://techcrunch.com/2017/04/24/creepy-facial-projections-3d-hair-capture-digital-creepers-and-more-from-eurographics-2017/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">欧洲图形会议正在里昂举行，在计算机图形专家提供的更多技术产品中，有一些足够酷，任何人都可以欣赏。除非你害怕小丑。在这种情况下，你可能不应该向下滚动。</p>
<p class="translated">首先是一个模拟藤蔓和攀缘植物以复杂的交织模式生长的系统。植物是一系列粒子，它们与周围的环境——角度、材料、光照、其他植物——相互作用，并适当地生长。视频展示了没有植物装饰的模拟，它看起来像智能香肠链接。</p>
<p class="translated">再加上流体动力学和其他一些技巧，这些虚拟植物可以实时生长和互动。想象一下，探索(和修剪)一个智能藤蔓像蛇一样蜿蜒爬过风景，追逐你和你的杀人砍刀的世界。颤抖吧。</p>
<p class="embed breakout embed-oembed embed--video embed--vimeo"/>
<p class="translated">它同时支持多达20个工厂和多达25，000个分支。你可以阅读更多关于这个项目的信息或者在这里下载论文<a target="_blank" href="https://web.archive.org/web/20230326054543/http://www.pirk.info/projects/climbing_plants/" rel="noopener noreferrer"/>。</p>
<p class="translated">接下来是迪士尼研究的两个项目，展示了令人印象深刻的能力，既可以将数字世界带入现实世界，也可以将现实世界带入数字世界。在一种情况下，它将图形实时应用到一个人的脸上，在另一种情况下，它通过观察运动中的头发来捕捉他们头发的微妙之处。</p>
<p class="translated"><a target="_blank" href="https://web.archive.org/web/20230326054543/https://www.disneyresearch.com/publication/makeup-lamps-live-augmentation-of-human-faces-via-projection/" rel="noopener noreferrer">面部投影设备</a>使用高速摄像机实时跟踪面部运动和表情，并将其与静态图形相结合，创建一个定制的图像投影到脸上——每秒更新数百次。所以你可以把任何一种很酷的设计、面具、胡须或伤疤放在一起…</p>
<p class="translated"><a target="_blank" href="https://web.archive.org/web/20230326054543/https://techcrunch.com/wp-content/uploads/2017/04/makeup-lamps-live-augmentation-of-human-faces-via-projection-image2.jpg" rel="noopener noreferrer"><img decoding="async" class="aligncenter size-full wp-image-1480774" src="../Images/a325edb7787cc3dd794160c2b792afe7.png" alt="" srcset="https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/makeup-lamps-live-augmentation-of-human-faces-via-projection-image2.jpg 694w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/makeup-lamps-live-augmentation-of-human-faces-via-projection-image2.jpg?resize=150,57 150w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/makeup-lamps-live-augmentation-of-human-faces-via-projection-image2.jpg?resize=300,115 300w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/makeup-lamps-live-augmentation-of-human-faces-via-projection-image2.jpg?resize=680,260 680w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/makeup-lamps-live-augmentation-of-human-faces-via-projection-image2.jpg?resize=50,19 50w" sizes="(max-width: 694px) 100vw, 694px" data-original-src="https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/makeup-lamps-live-augmentation-of-human-faces-via-projection-image2.jpg"/></a>……当然，他们做的第一件事就是给某人戴上一张可怕的小丑脸，然后是《黑暗骑士》中小丑更可怕的脸。它工作得很好，但是为什么不做一些不那么令人毛骨悚然的事情呢？</p>
<p class="translated">(注意，在视频中，你看到的闪烁来自DLP图像和相机滚动快门之间的相互作用——你在现实生活中不会看到它。)</p>
<p class="embed breakout embed-oembed embed--video embed--youtube"/>
<p class="translated">特别是灯光演示，我认为非常酷。这在现实生活中会很有用，比如戏剧表演，或者，现在我想起来了，主题公园。谁会想到呢？</p>
<p class="translated">迪士尼的研究人员还整合了一项技术，通过在体内观察毛发<em>来准确捕捉和模拟毛发。头发运动是一个困难的问题，但目前的模型已经很好地解决了这个问题；首先设置头发使其可以被模拟是一个完全不同的问题。想要手动配置5000股3D头发模型的每一股头发吗？我也没有。</em></p>
<p class="translated">这个团队使用10台摄像机来跟踪头部运动和头发运动的细微细节。只要坐在一个我认为肯定是非常热、明亮的工作室里，来回摇晃一个人的头，系统就可以获得足够的数据，来制作一个非常像样的头发复制品。</p>
<p class="embed breakout embed-oembed embed--video embed--youtube"/>
<p class="translated">这在制作自己的化身时非常有用。现在，他们总是变得令人毛骨悚然的部分原因是头发的糟糕表现。再加上机器人的发音和假眼。</p>
<p class="translated">最后一个我觉得超级酷的是这个人群模拟器。模拟人群很容易做得很差，实际上很难做到，几十个或几百个个体在彼此之间穿行，停下来开始，靠得太近或形成奇怪的模式。如果你想在电影或游戏的背景中放一个虚假的人群，这些问题对观察者来说是非常明显的，而且，正如可能发生在许多读者身上的那样，会立即破坏任何怀疑的暂停。</p>
<p class="translated"><a target="_blank" href="https://web.archive.org/web/20230326054543/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg" rel="noopener noreferrer"> <img decoding="async" loading="lazy" class="aligncenter size-full wp-image-1480789" src="../Images/8e4fd69c7d7ff7292daecef37b9eb2c9.png" alt="" srcset="https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg 1134w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg?resize=150,53 150w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg?resize=300,107 300w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg?resize=768,274 768w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg?resize=680,242 680w, https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg?resize=50,18 50w" sizes="(max-width: 1024px) 100vw, 1024px" data-original-src="https://web.archive.org/web/20230326054543im_/https://techcrunch.com/wp-content/uploads/2017/04/agents_crowd.jpg"/> </a>这种新方法基本上给每个个体一个基本的视觉和对周围环境的基本了解。根据它所看到的，它会做出最佳选择，以绕过障碍物或人群中的另一个人，或多或少会像人类那样做:你会偏离你的路线几英尺，但你不会慢慢转向街道，因为另一个人在你的人行道一侧(尴尬)。</p>
<p class="embed breakout embed-oembed embed--video embed--youtube"/>
<p class="translated">结果真的很好，一小群人熟练地相互导航——但从来没有<em>太</em>熟练。当两个人流交叉时，他们找不到一个完美的功能来在不改变速度或环顾四周的情况下做到这一点。有一点谈判和一些放缓，这就是你看到的这种基于愿景的方法。</p>
<p class="translated">也许他们可以把这个视频给西雅图的人看，他们需要一些关于如何绕着别人走的建议。</p>
<p class="translated">下周还会有几十篇论文发表；查看完整的日程安排，看看有没有其他让你感兴趣的。</p>
			</div>

			</div>    
</body>
</html>