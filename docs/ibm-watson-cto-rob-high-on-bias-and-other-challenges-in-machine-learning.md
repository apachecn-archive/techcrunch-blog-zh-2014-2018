# IBM Watson 首席技术官 Rob High 谈机器学习中的偏见和其他挑战 

> 原文：<https://web.archive.org/web/https://techcrunch.com/2018/02/27/ibm-watson-cto-rob-high-on-bias-and-other-challenges-in-machine-learning/>

对 IBM Watson 的首席技术官罗伯 High 来说，机器学习目前面临的最大技术挑战是弄清楚如何用更少的数据来训练模型。在巴塞罗那举行的年度移动世界大会上，High 接受我采访时表示:“这是一个挑战，也是一个目标，我们当然有理由相信这是可能的。”

与此同时，他呼应了整个行业的类似说法。例如，谷歌的人工智能主管约翰·詹南德里亚最近也将此列为这家搜索巨头的机器学习团队正试图应对的主要挑战之一。通常，机器学习模型需要针对大量数据进行训练，以确保它们的准确性，但对于许多问题来说，这些大数据集根本不存在。

然而，High 认为这是一个可以解决的问题。原因何在？“因为人类确实如此。我们有一个数据点，”他说。需要记住的一点是，即使我们从人类的行为中看到了这一点，我们也必须认识到，人类学习的过程不仅仅是这个阶段，也不仅仅是那个时刻。我们把所有这些背景都提到了桌面上。“对 High 来说，有了这样的背景，就可以用更少的数据建立训练模型，再加上最近在迁移学习方面取得的进展，也就是说，有了这样的能力，可以先获取一个训练好的模型，然后使用这些数据，开始对另一个可能存在更少数据的模型进行训练。

人工智能面临的挑战，尤其是会话式人工智能，远远不止这些。High 说:“另一端则是试图理解如何更好地与人类互动，让人类找到自然的方式，并影响他们的思维。”“人类受到影响的不仅仅是他们交流的文字，还包括我们如何将这些文字用发声、音调、语调、节奏、脾气、面部表情、手臂和手势来体现。”High 认为人工智能不一定需要以某种拟人化的方式来模仿这些，但也可以用某种其他的方式，比如设备上的视觉提示。

与此同时，大多数人工智能系统还需要更好地理解问题的意图，以及这些问题与个人先前就某件事提出的问题有何关联，以及个人当前的精神状态和个性。

不过，这又带来了另一个问题。现在正在使用的许多机器学习模型都存在固有的偏见，因为它们是用数据来训练的。举例来说，这通常意味着，如果你是一名白人男性，某个特定的模式会对你非常适用，但对黑人女性却不适用。“首先，我认为这个等式有两个方面。一个是，这些数据可能存在总体偏差，我们必须对此保持敏感，并迫使自己考虑那些拓宽了其所代表的人群的文化和人口统计方面的数据，”High 说。“然而，另一方面，你实际上希望这类系统中的总体偏差超过个人偏差。”

例如，High 引用了 IBM 与斯隆·凯特林癌症中心的合作。IBM 和医院根据一些最好的癌症外科医生的工作训练了一个模型。“但是斯隆·凯特林对于如何行医有自己独特的哲学。所以哲学体现在他们的偏见中。这是他们的制度偏见，这是他们的品牌。[……]斯隆·凯特琳之外的任何系统都需要将同样的理念发扬光大。”

“确保这些事情以正确的方式偏向很大一部分是确保你有正确的人提交，以及这些人代表着更广泛的文化。”High 说，IBM 的客户现在也经常讨论这个问题，这在一个仍然经常忽视这类话题的行业中是一个积极的迹象。

[![](img/c56334c2395ce3cc0d1d05c6e1184e2c.png)](https://web.archive.org/web/20221025222150/https://techcrunch.com/tag/mobile-world-congress-2018/)