# 在 TechMAKERS 迷你系列 中认识创造未来的女性

> 原文：<https://web.archive.org/web/https://techcrunch.com/2018/03/11/meet-the-women-inventing-the-future-in-the-techmakers-mini-series/?ncid=rss>

# 在 TechMAKERS 迷你系列中认识创造未来的女性

《创客》聚焦五位女性，她们站在重塑我们世界的令人振奋的技术前沿，从人工智能到机器人技术，从心灵感应到深空探索。在女性仅占技术岗位四分之一的行业中，她们是处于行业顶端的工程师和计算机科学家。他们正在打破硅天花板，并激励新一代女性“创客”加入他们的行列，产生影响。

机器人专家艾安娜·霍华德
艾安娜·霍华德博士对机器人技术产生了巨大的影响。她是该领域为数不多的黑人女性之一，她从事的发明着眼于社会影响，而不是科幻小说。

[YouTube https://youtu.be/uVJeI60glTE]

发明家、企业家玛丽·卢·杰普森
如果有人能让瓦肯人的想法成真，那就是科技发明家玛丽·卢·杰普森。每一项新发明，她都让人类更接近于为了健康和交流的目的而解放思想。

[YouTube https://youtu.be/t4okOT5aUFk]

**戴安娜·特鲁希略，航天工程师**
男人可以拥有月球。作为美国宇航局喷气推进实验室的工程师，戴安娜·特鲁希略将带我们去火星。特鲁希略在美国宇航局火星好奇号漫游任务中的工作让我们第一次近距离瞥见了火星，并清楚地证明了这颗红色星球曾经有能力支持生命。

[YouTube https://youtu.be/4yGgsx57LBM]

费-李非，斯坦福大学教授&谷歌云首席技术专家
费-李非 16 岁带着对科学的热爱从中国来到美国，她从未回头。她在普林斯顿和加州理工学院接受教育，她在机器人领域的早期工作彻底改变了机器学习和人工智能。她对科技职业包容性和我们教授机器的多样性的关注表明，未来的机器人将不会是性别歧视的。

[YouTube https://youtu.be/UvauKbNiX7k]

**Limor Fried，Adafruit Industries**
电子公司创始人& CEO。公司。动作。Limor Fried 可以建造任何东西。事实上，这位麻省理工学院的毕业生非常喜欢分享她的想法和创造这些想法的工具，她创建了 Adafruit Industries，这是一家美国排名前 20 的制造公司，也是一个跟踪她的每一个机器制造动作的全球在线社区。

[YouTube https://youtu.be/V4WtPv0yWek]

更多信息，请查看 https://www.makers.com/techmakers.ology-studies-fail-reproducibility-test-1.18248)的一半以上。

这场危机的原因很多。研究人员面临着“发表或灭亡”的局面，他们需要积极的结果，以继续他们的工作。期刊希望引人注目的结果来获得更多的读者，而“p-hacking”允许研究人员通过篡改统计数据来获得更好的结果。

人工智能研究也不能免受这些结构性因素的影响，事实上，鉴于人工智能令人难以置信的兴奋感，情况可能会更糟，这促使研究人员找到最新颖的进展，并尽可能迅速和广泛地分享它们。

现在，人们越来越担心，人工智能研究中最重要的成果很难复制，如果不是不可能复制的话。一个挑战是，许多[人工智能论文缺少运行其底层算法](https://web.archive.org/web/20230316060538/http://www.sciencemag.org/news/2018/02/missing-data-hinder-replication-artificial-intelligence-studies)所需的关键数据，或者更糟的是，甚至不包括正在研究的算法的源代码。机器学习中使用的训练数据是算法结果成功的很大一部分，因此没有这些数据，几乎不可能确定特定算法是否如所描述的那样发挥作用。

更糟糕的是，在急于发表新颖和新结果的过程中，人们越来越少关注重复研究，以显示不同结果的可重复性。从上面链接的 MIT Technology Review 文章来看，“……蒙特利尔麦吉尔大学的计算机科学家彼得·亨德森(Peter Henderson)表明，旨在通过试错法学习的人工智能的性能不仅对所用的确切代码高度敏感，而且对启动训练所生成的随机数和‘超参数’(hyperparameters)高度敏感——这些设置不是算法的核心，但会影响它学习的速度。”非常小的变化可能导致非常不同的结果。

就像营养科学中的一项研究一样，我们应该持保留态度(或者现在是黄油，或者是糖？)，新的人工智能论文和服务应该以类似的怀疑态度来对待。证明单一结果的一篇论文或一项服务并不能证明其准确性。通常，这意味着在非常特定的条件下运行的非常精选的数据集可能会产生很高的精度，而这种精度不适用于更一般的输入集。

## 准确报告准确性

人们对人工智能解决各种问题的潜力明显感到兴奋，从医院的临床评估到文件扫描，再到预防恐怖主义。然而，这种兴奋已经影响了记者甚至研究人员准确报道的能力。

[以最近这篇关于使用人工智能检测结肠直肠癌的文章为例](https://web.archive.org/web/20230316060538/https://www.inverse.com/article/37873-artificial-intelligence-colorectal-cancer-detection)。这篇文章说，“结果令人印象深刻——准确率为 86%——因为这些数字是通过评估已经被诊断患有结肠直肠息肉的患者而获得的。”文章还包括了最初研究的关键结果段落。

[或者拿这篇关于谷歌机器学习服务执行语言翻译的文章](https://web.archive.org/web/20230316060538/https://www.theverge.com/2016/9/27/13078138/google-translate-ai-machine-learning-gnmt)。“在某些情况下，谷歌表示其 GNMT 系统甚至接近人类水平的翻译准确度。这种近似对等仅限于相关语言之间的转换，比如从英语到西班牙语和法语。”

这些是随机选择的文章，但还有数百篇其他文章气喘吁吁地报道最新的人工智能进展，并抛出一个单一的准确性数字，或一个隐喻，如“人类水平”。要是评估人工智能程序也这么简单就好了！

假设你想确定一个人皮肤上的痣是否是癌性的。这就是所谓的二元分类问题——目标是将患者分为两组:癌症患者和非癌症患者。一个具有完美精确度的完美算法会将每个癌症患者识别为患有癌症，并将每个未患癌症的人识别为未患癌症。换句话说，结果不会有假阳性或假阴性。

这很简单，但挑战在于，对于计算机和人类来说，像癌症这样的疾病基本上不可能完全准确地识别。每项医学诊断测试通常都必须在灵敏度(它能正确识别多少阳性)和特异性(它能正确识别多少阴性)之间做出权衡。考虑到错误识别癌症患者的危险(可能导致死亡)，测试通常被设计成通过降低特异性(即增加假阳性以确保尽可能多的阳性被识别)来确保高灵敏度。

产品设计师可以选择如何平衡这些相互竞争的优先级。根据误报和漏报的成本，相同的算法可能以不同的方式实现。如果一篇研究文章或服务没有讨论这些权衡，那么准确性就没有得到公平的体现。

更重要的是，单一精度值有点用词不当。准确性反映了多少阳性患者被阳性识别，多少阴性患者被阴性识别。但是我们可以通过增加一个数字和减少另一个数字来保持相同的精度，反之亦然。换句话说，一项测试可以强调很好地检测出阳性患者，或者它可以强调从结果中排除阴性患者，同时保持相同的准确性。这些是非常不同的最终目标，一些算法可能更适合其中一个而不是另一个。

这就是使用单一数字的复杂性。比喻更不好。“人类水平”并没有说什么——很少有关于人类错误率的好数据，即使有这样的数据，也很难比较人类和机器学习所犯错误的类型。

这只是最简单的分类问题的一些复杂之处。评估人工智能质量的所有细微差别至少需要一本书，事实上，一些研究人员无疑将花费他们的一生来评估这些系统。

不是每个人都可以获得人工智能博士学位，但作为这些新技术的消费者，我们每个人都有责任用批判的眼光看待这些阳光的说法，并严格评估它们。无论是再现性还是惊人的准确性，重要的是要记住，我们依赖的许多人工智能技术仅仅是技术婴儿，仍然需要更多的时间来成熟。