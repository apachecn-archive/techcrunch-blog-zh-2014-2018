<html>
<head>
<title>Facebook chose to fight fake news with AI, not just user reports • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书选择用人工智能来打击假新闻，而不仅仅是用户报告TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2016/11/14/facebook-fake-news/">https://web.archive.org/web/https://techcrunch.com/2016/11/14/facebook-fake-news/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">脸书发言人告诉TechCrunch，脸书今年为clickbait构建了两个版本的修复程序，并决定信任算法机器学习检测，而不仅仅是用户行为。</p>
<p class="translated">今天，脸书受到更多指控，称其散布假新闻帮助唐纳德·特朗普当选。一份新的<a target="_blank" href="https://web.archive.org/web/20221005185201/http://gizmodo.com/facebooks-fight-against-fake-news-was-undercut-by-fear-1788808204"> Gizmodo报告</a>称，脸书搁置了今年早些时候的一项计划更新，该更新可能会识别假新闻，因为它会不成比例地贬低右翼新闻机构。</p>
<p class="translated">脸书直接否认了这一点，告诉TechCrunch“这篇文章的指控是不真实的。我们没有基于对任何一个政党的潜在影响而建立和保留任何新闻源的变化。”</p>
<p class="translated">然而，TechCrunch从脸书获得了更多关于Gizmodo讨论的更新的细节。</p>
<p class="translated"><img loading="lazy" class="alignright wp-image-1415803" src="../Images/234a3917ad4b7a78caf1b99f4325732e.png" alt="news-feed-machine-screengrab" srcset="https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/news-feed-machine-screengrab.png 690w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/news-feed-machine-screengrab.png?resize=150,88 150w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/news-feed-machine-screengrab.png?resize=300,177 300w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/news-feed-machine-screengrab.png?resize=680,401 680w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/news-feed-machine-screengrab.png?resize=50,29 50w" sizes="(max-width: 320px) 100vw, 320px" data-original-src="https://web.archive.org/web/20221005185201im_/https://beta.techcrunch.com/wp-content/uploads/2016/11/news-feed-machine-screengrab.png?w=680"/>早在2015年1月，脸书推出了一项旨在<a target="_blank" href="https://web.archive.org/web/20221005185201/https://newsroom.fb.com/news/2015/01/news-feed-fyi-showing-fewer-hoaxes/">打击虚假新闻</a>的更新，该更新降级了那些被用户严重标记为虚假的链接，这些链接后来经常被发布它们的用户删除。这个系统仍然存在。</p>
<p class="translated">2016年8月，脸书发布了另一个新闻订阅更新<a target="_blank" href="https://web.archive.org/web/20221005185201/https://newsroom.fb.com/news/2016/08/news-feed-fyi-further-reducing-clickbait-in-feed/">，旨在减少点击诱饵故事</a>。脸书通过让人类识别clickbait故事的旧新闻标题中的常用短语，训练了一种机器学习算法。然后，机器学习系统将识别并降级以这些点击诱饵短语为特色的未来故事。</p>
<p class="translated">根据脸书的说法，它为2016年的clickbait更新开发了两种不同的选项。一个是基于用户报告的2015年恶作剧检测器的分类器，另一个是专门为通过计算机算法检测clickbait而构建的机器学习分类器。</p>
<p class="translated">脸书表示，它发现特制的机器学习clickbait探测器表现更好，误报和漏报更少，所以这就是脸书发布的。Gizmodo所指的未发布版本可能就是搁置的更新。脸书告诉我，右翼故事的不平衡clickbait降级并不是它没有发布的原因，但政治倾向仍然是一个问题。</p>
<p class="translated">选择依赖机器学习算法，而不是围绕用户报告进行修复，这与脸书最近努力减少其策展中潜在的人为偏见是一致的，这本身就存在问题。</p>
<p class="translated"><img loading="lazy" class="aligncenter size-large wp-image-1415780" src="../Images/c28f0b94feab1e3135baca18f34df0bf.png" alt="fb-clickbait1" srcset="https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg 2560w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=150,84 150w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=300,169 300w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=768,432 768w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=680,383 680w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=1536,864 1536w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=2048,1152 2048w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=1200,675 1200w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?resize=50,28 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20221005185201im_/https://beta.techcrunch.com/wp-content/uploads/2016/11/fb-clickbait1.jpg?w=680"/></p>
<p class="translated">今年早些时候的一份Gizmodo报告称，脸书的人类趋势策展人利用他们的编辑自由压制保守趋势。脸书否认了这些指控，但解雇了它的策展团队，转向一个更具算法性的系统，没有人类书写的趋势描述。随后，脸书因虚假报道成为潮流而受到批评，《纽约时报》报道称，“潮流话题事件麻痹了脸书对其产品做出任何可能损害其客观性的重大改变的意愿。”</p>
<p class="translated">如果脸书推出了未发布版本的clickbait修复程序，它可能会像对待更多老生常谈的恶作剧一样，依赖审查用户报告的员工的主观意见。与此同时，政治活动家或巨魔可能会滥用报道功能，如果准确的报道与他们的观点相冲突，就会大量标记为虚假。</p>
<p class="translated">这种棘手的情况是在政治两极化的环境下，参与度排名的社交媒体成为大规模流行的新闻发布渠道的必然结果，在这种环境下，竞选目标和广告收入刺激了错误信息。</p>
<p class="translated"><img loading="lazy" class="aligncenter size-full wp-image-1415799" src="../Images/c3e1d4932f016297cc637b76bdf3c065.png" alt="facebook-news-feed-algorithm" srcset="https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-algorithm.png 680w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-algorithm.png?resize=150,85 150w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-algorithm.png?resize=300,171 300w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-algorithm.png?resize=50,28 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20221005185201im_/https://beta.techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-algorithm.png"/></p>
<h2 class="translated">谁是真理的仲裁者？</h2>
<p class="translated">脸书以及Twitter和谷歌等其他新闻分销商面临着挑战。可以用事实来反驳的明显的谎言只是问题的一部分，也许更容易解决。可能被认为是点击诱饵的夸张和严重编造的故事可能更难对付。</p>
<p class="translated">因为脸书和其他一些平台奖励参与，新闻机构被激励尽可能耸人听闻地构建故事。虽然长期运行的党派渠道可能要为夸张负责，但专门利用脸书等网络的病毒式传播而建立的新渠道不会面临同样的反响。他们可以专注于短期流量和广告收入，如果人们厌倦了他们的内容，他们可以简单地用不同的品牌重新启动。</p>
<p class="translated">简化用户对虚假或夸大报道的标记，将事实核查网站附加到可疑文章上，以及阻止尚未证明其准确性但优先考虑货币化的域名的分发，可能是对抗假新闻雪崩的一些方法。显然还需要做更多的工作。</p>
<p class="translated"><img loading="lazy" class="aligncenter size-large wp-image-1415805" src="../Images/c002b780b3b1d581a7aa89ff9f245954.png" alt="facebook-news-feed-equation" srcset="https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png 1280w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png?resize=150,85 150w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png?resize=300,171 300w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png?resize=768,437 768w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png?resize=680,387 680w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png?resize=1200,683 1200w, https://web.archive.org/web/20221005185201im_/https://techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png?resize=50,28 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20221005185201im_/https://beta.techcrunch.com/wp-content/uploads/2016/11/facebook-news-feed-equation.png?w=680"/></p>
<p class="translated">但是要求像脸书这样的网络成为真相警察可能是有风险的。这可能会迫使它就审查什么进行更广泛的呼吁，这将不可避免地招致指责。至少，偏向于参与度排名的技术平台允许用户单独决定他们读到的内容是虚假的还是夸大的。脸书的首席执行官马克·扎克伯格重申了这一观点，他写道:“我认为我们必须非常谨慎，不要成为真理的仲裁者。”</p>
<p class="translated">现在，如果脸书允许假新闻传播是该死的，因为它依靠用户自己思考，但如果它不允许假新闻传播是该死的，因为它决定审查什么，这剥夺了用户的选择权。这家社交网络将不得不谨慎选择下一步行动。</p>
			</div>

			</div>    
</body>
</html>