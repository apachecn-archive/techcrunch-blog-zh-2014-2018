<html>
<head>
<title>Facebook rolls out AI to detect suicidal posts before they're reported | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书推出人工智能，在自杀帖子被报道之前检测它们</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2017/11/27/facebook-ai-suicide-prevention/">https://web.archive.org/web/https://techcrunch.com/2017/11/27/facebook-ai-suicide-prevention/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">这是拯救生命的软件。脸书新的“主动检测”人工智能技术将扫描所有帖子，寻找自杀想法的模式，并在必要时向处于危险中的用户或他们的朋友发送心理健康资源，或联系当地的急救人员。通过使用人工智能将令人担忧的帖子标记给人类版主，而不是等待用户报告，脸书可以减少发送帮助所需的时间。</p>
<p class="translated">脸书<a target="_blank" href="https://web.archive.org/web/20230329095646/https://newsroom.fb.com/news/2017/03/building-a-safer-community-with-new-suicide-prevention-tools/" rel="noopener">之前</a>测试使用人工智能检测令人不安的帖子，<a target="_blank" href="https://web.archive.org/web/20230329095646/https://techcrunch.com/2017/03/01/facebook-brings-suicide-prevention-tools-to-live-and-messenger/" rel="noopener">更突出的是向美国的朋友提供自杀报告选项</a>。现在脸书将使用这种人工智能搜索世界各地<a target="_blank" href="https://web.archive.org/web/20230329095646/https://newsroom.fb.com/news/2017/11/getting-our-community-help-in-real-time/" rel="noopener">的所有类型内容</a>,除了在欧盟，那里的<a target="_blank" href="https://web.archive.org/web/20230329095646/http://privacylawblog.fieldfisher.com/2017/let-s-sort-out-this-profiling-and-consent-debate-once-and-for-all/" rel="noopener">一般数据保护法规</a>基于敏感信息对用户进行侧写的隐私法律使这种技术的使用变得复杂。</p>
<p class="translated"><img decoding="async" class="aligncenter size-large wp-image-1571315" src="../Images/2159348668dcff3dcebe99758ba802af.png" alt="" srcset="https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png 2971w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=150,86 150w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=300,172 300w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=768,439 768w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=680,389 680w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=1536,879 1536w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=2048,1172 2048w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=1200,687 1200w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?resize=50,29 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-suicide-prevention.png?w=680"/></p>
<p class="translated">脸书还将使用人工智能来优先处理特别危险或紧急的用户报告，以便版主更快地处理这些报告，并使用工具来即时显示当地语言资源和第一反应者的联系信息。它也致力于更多的主持人自杀预防，培训他们处理案件的24/7，现在有80个地方合作伙伴，如Save.org，全国自杀预防生命线和前沿，从那里提供资源的高危用户和他们的网络。</p>
<p class="translated">产品管理副总裁盖伊·罗森说:“这是为了缩短流程中每一步的时间，尤其是在脸书现场直播中。”。在过去一个月的测试中，脸书已经启动了100多次“健康检查”,首批响应人员访问了受影响的用户。"有些情况下，第一响应者已经到达，而那个人还在广播."</p>
<p class="translated">脸书主动扫描人们帖子内容的想法可能会引发一些反乌托邦式的担忧，即这项技术还可以如何应用。脸书没有回答如何避免扫描政治异议或轻微犯罪，罗森只是说“我们有机会在这里提供帮助，所以我们要投资。”这项技术肯定有很多有益的方面，但这是另一个我们别无选择的领域，只能希望脸书不要走得太远。</p>
<p class="translated">[更新:脸书首席安全官Alex Stamos用一条振奋人心的推文回应了这些担忧，表明脸书确实非常认真负责地使用人工智能。</p>

<p class="translated">脸书首席执行官马克·扎克伯格今天在一篇帖子中称赞了产品更新，<a target="_blank" href="https://web.archive.org/web/20230329095646/https://www.facebook.com/zuck/posts/10104242660091961" rel="noopener">写道</a>“在未来，人工智能将能够理解更多语言的细微差别，并将能够识别自杀以外的不同问题，包括快速发现更多类型的欺凌和仇恨。”</p>
<p class="translated">不幸的是，在TechCrunch询问用户是否有办法退出帖子后，脸书发言人回应说用户不能退出。他们指出，该功能旨在增强用户安全，如果用户不想看到脸书提供的支持资源，可以很快取消。]</p>
<p class="translated">脸书通过在过去人工报告自杀风险的帖子中使用的词语和图像中寻找模式来训练人工智能。它还会寻找类似“你还好吗？”以及“你需要帮助吗？”</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-1571318" src="../Images/8453e9847e8256a3661899deeb27e4bc.png" alt="" srcset="https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png 1749w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=150,145 150w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=300,291 300w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=768,744 768w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=680,659 680w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=1536,1489 1536w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=1200,1163 1200w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=32,32 32w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=50,48 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?w=680"/></p>
<p class="p1 translated">“我们已经和心理健康专家谈过了，帮助预防自杀的最好方法之一是让有需要的人听到关心他们的朋友或家人的声音，”罗森说。“这使脸书处于一个真正独特的位置。我们可以帮助处于困境的人联系朋友和能够帮助他们的组织。”</p>
<h2 class="translated">自杀报道现在在脸书是如何运作的</h2>
<p class="translated">通过人工智能、人类主持人和众包报道的结合，脸书可以试图防止类似上个月一位父亲在脸书直播自杀的悲剧。特别是直播有错误地美化自杀的力量，因此有必要采取新的预防措施，也影响了大量观众，因为每个人都同时看到内容，不像录制的脸书视频，在很多人观看之前就可以标记并删除。</p>
<p class="translated">现在，如果有人在任何类型的脸书邮报上表达自杀的想法，脸书的人工智能将会主动检测到它，并将其标记给受过预防培训的人类版主，并使观众更容易获得报告选项。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-1571318" src="../Images/8453e9847e8256a3661899deeb27e4bc.png" alt="" srcset="https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png 1749w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=150,145 150w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=300,291 300w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=768,744 768w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=680,659 680w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=1536,1489 1536w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=1200,1163 1200w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=32,32 32w, https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?resize=50,48 50w" sizes="(max-width: 680px) 100vw, 680px" data-original-src="https://web.archive.org/web/20230329095646im_/https://techcrunch.com/wp-content/uploads/2017/11/facebook-live-report-2.png?w=680"/></p>
<p class="translated">当有报告进来时，脸书的技术可以突出显示帖子或视频中与自杀风险模式相匹配的部分，或者收到关注评论的部分。这避免了主持人自己浏览整个视频。AI认为用户报告比其他类型的违反内容政策的行为更紧急，比如描绘暴力或裸体。脸书说，这些加速报告升级到地方当局的速度是非加速报告的两倍。</p>
<p/>
<p class="translated">然后，脸书的工具从其合作伙伴那里调出当地语言资源，包括预防自杀和附近当局的电话热线。然后，主持人可以联系响应者，并尝试将他们发送到处于风险中的用户的位置，向处于风险中的用户本人展示精神健康资源，或者将他们发送给可以与用户交谈的朋友。“我们的目标之一是确保我们的团队可以用我们支持的任何语言在全球范围内做出回应，”Rosen说。</p>
<p class="translated">早在二月份，脸书首席执行官马克·扎克伯格写道:“发生了可怕的悲剧事件——比如自杀，有些是直播——如果有人意识到发生了什么并及时报告，这些事件或许可以避免。。。人工智能可以帮助提供更好的方法。”</p>
<p class="translated">拥有超过20亿用户，很高兴看到脸书在这方面有所进步。脸书不仅为用户创造了一种相互联系和关心的方式。不幸的是，它还在脸书直播中创建了一个非中介的实时分发频道，可以吸引那些希望看到自己或他人遭受暴力的人。</p>
<p class="translated">创建一个无处不在的全球通信设施，所带来的责任超出了大多数科技公司的责任，脸书似乎正在接受这一点。</p>
			</div>

			</div>    
</body>
</html>