# DeepMind 现在有一个人工智能伦理研究部门。我们对此有几个问题...

> 原文：<https://web.archive.org/web/https://techcrunch.com/2017/10/04/deepmind-now-has-an-ai-ethics-research-unit-we-have-a-few-questions-for-it/>

2014 年[被谷歌以 5 亿多美元收购的英国人工智能公司 DeepMind 推出了一个新的道德部门，据称将围绕六个“](https://web.archive.org/web/20230205192629/https://techcrunch.com/2014/01/26/google-deepmind/)[关键主题](https://web.archive.org/web/20230205192629/https://deepmind.com/applied/deepmind-ethics-society/research/)”进行研究，包括“隐私、透明和公平”以及“经济影响:包容和平等”。

这家由字母表所有的 [XXVI](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/09/04/google-parent-alphabet-forms-holding-company-xxvi-to-complete-2015-corporate-reorganization/) 公司，其母公司去年创造了近 900 亿美元的收入，表示这项研究将考虑“开放的问题”，例如:“人工智能技术的日益使用和复杂性将如何与公司权力互动？”

它将在这项重要工作中得到许多“独立顾问”(DeepMind 也称他们为“[研究员](https://web.archive.org/web/20230205192629/https://deepmind.com/applied/deepmind-ethics-society/fellows/)”)的帮助，它说，“帮助为我们的研究战略和工作计划提供监督、关键反馈和指导”；还有一组合作伙伴，也就是现有的研究机构，他们表示将“随着时间的推移，努力纳入尽可能广泛的观点”。

虽然它真的不应该需要一个博学的学者和机构的名册来指出一个商业人工智能巨头在研究自己的技术的社会影响的伦理方面的巨大利益冲突。

(与此同时，精通人工智能的学者尚未以某种咨询形式或其他方式依附于一家或另一家科技巨头的问题是人工智能领域的另一个伦理困境，我们在[之前已经强调过](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/06/17/a-discussion-about-ais-conflicts-and-challenges/)。)

DeepMind 道德研究部门是 DeepMind 在收购谷歌时建立的内部道德委员会的补充，因为创始人自己担心公司权力会染指强大的人工智能。

然而，董事会成员的名字从未公开过——显然，现在也不会公开。尽管 DeepMind 大张旗鼓地表示希望研究人工智能的道德和透明度。因此，你不得不好奇科技巨头们似乎围绕在自己周围的过滤泡沫的内部是如何镜像的。

在人工智能和技术平台力量方面，有一件事变得非常清楚:大规模的算法自动化正在产生各种各样令人不快的社会后果——如果我们仁慈一点，这可以归因于企业为规模和业务增长而优化人工智能的结果。因此:“我们赚钱，而不是社会责任”。

但事实证明，如果人工智能工程师在开始快速移动和破坏东西之前不考虑道德和潜在的负面影响和冲击，那些超可扩展的算法不会自己发现问题并绕过损害。[与此相反](https://web.archive.org/web/20230205192629/https://techcrunch.com/2016/10/28/facebook-ethnic-affinity/)。他们会放大、加速和加剧伤害。

见证[假新闻](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/10/02/how-reports-from-4chan-on-the-las-vegas-shooting-showed-up-on-google-top-stories/)。见证[猖獗的网络谩骂](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/07/20/twitter-claims-its-anti-abuse-measures-are-helping-though-many-still-disagree/)。见证[完全缺乏监督](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/09/20/anticipating-the-dark-side/) [让任何人付费进行有针对性的舆论操纵](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/10/01/facebook-russian-ads/)和社会分裂的后果。

鉴于[曙光](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/09/22/uber-loses-its-license-to-operate-in-london/) [政治](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/09/20/tech-giants-told-to-remove-extremist-content-much-faster/)和[公众意识到人工智能如何会导致各种各样的社会问题，因为它的制造者只是“没有想到这一点”——从而允许他们的平台被意图有针对性伤害的实体武器化，那么科技平台巨头控制围绕人工智能的叙事的需要对他们来说肯定变得非常明显。或者他们面临他们最喜欢的工具以他们不喜欢的方式被监管。](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/09/19/twitter-claims-tech-wins-in-quashing-terror-tweets/)

硬币可能会从“我们只是没有想到这一点”变成“我们真的需要想到这一点——并控制公众和决策者如何看待这一点”。

因此，我们来到了 DeepMind，推出了一个道德研究部门，每年将发布#条人工智能相关的研究——希望在与其商业利益密切相关的领域影响公众舆论和政策制定者，如[治理和问责制](https://web.archive.org/web/20230205192629/https://deepmind.com/applied/deepmind-ethics-society/research/governance-and-accountability/)。

这来自同一家公司，其 2015 年与伦敦 NHS 信托达成的[数据共享协议导致了英国隐私监管机构](https://web.archive.org/web/20230205192629/https://techcrunch.com/2016/05/04/concerns-raised-over-broad-scope-of-deepmind-nhs-health-data-sharing-deal/)的[调查——今年夏天，该公司判定，在 DeepMind 的健康部门在大约 160 万人不知情或未经其同意的情况下，被交给他们完全可识别的医疗记录后，违反了](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/03/16/uk-watchdog-close-to-verdict-in-deepmind-health-data-consent-probe/)[英国隐私法](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/07/03/uk-data-regulator-says-deepminds-initial-deal-with-the-nhs-broke-privacy-law/)。

现在,*deep mind 想要研究治理和责任伦理？马后炮的家伙满分。*

比如说，现在 DeepMind 的内部伦理研究部门可能会发表深思熟虑的论文，质疑将人工智能集中在大型企业手中的全方位社会风险。

但鉴于其在决定人工智能(不可避免地)如何受到监管方面的既得商业利益，一个由 DeepMind 员工组成的完全公正的研究单位似乎很难想象。

DeepMind 在宣布推出该单元的一篇措辞谨慎的博客文章中写道:“我们相信人工智能可以给世界带来非凡的好处，但前提是必须坚持最高的道德标准。”

“技术不是价值中立的，技术专家必须为他们工作的道德和社会影响负责，”它补充道，然后继续说道:“作为开发人工智能技术的科学家，我们有责任开展并支持对我们工作的更广泛影响进行公开研究和调查。”

这里的关键词当然是“公开研究和调查”。关键问题是，DeepMind 本身是否能够现实地向自身提供开放的研究和调查。

没有人相信由某一特定食物的制造商所做的吹捧该食物对健康有惊人益处的调查，这是有原因的。

相关:谷歌最近被美国监管机构指控花费数百万美元资助学术研究，以影响观点和政策制定。(它用一张 GIF 反驳了对[的指控。)](https://web.archive.org/web/20230205192629/https://techcrunch.com/2017/07/17/google-responds-to-academic-funding-controversy-with-a-gif/)

“为了保证我们工作的严谨性、透明度和社会责任，我们与我们的同事、其他学者和公民社会一起制定了一套原则。我们欢迎对这些问题以及我们发现的关键道德挑战的反馈。如果你有任何想法、想法或贡献，请联系我们，”DeepMind 在博客中补充道。

伦理小组的网站列出了[的五个核心原则](https://web.archive.org/web/20230205192629/https://deepmind.com/applied/deepmind-ethics-society/principles/)，称这些原则将支撑其研究。我将原则复制粘贴在下面，这样你就不必在多个链接树中搜寻*来找到它们，因为 DeepMind 在主页上没有将“原则”作为标签，所以你真的需要在 FAQ 链接中挖掘才能找到它们。

(如果你真的找到了，页面底部还写着:“我们欢迎所有关于我们原则的反馈，因此我们可能会在未来几个月在本页添加新的承诺。”)

更新:deep mind 的一位女发言人已经指出，也可以通过向下滚动道德主页上的文件夹来找到这些原则。

**有人真的应该计算一下从 DeepMind 的[伦理&社会网站](https://web.archive.org/web/20230205192629/https://deepmind.com/applied/deepmind-ethics-society/)提取所有信息需要多少点击，根据 [DeepMind 健康](https://web.archive.org/web/20230205192629/https://deepmind.com/applied/deepmind-health/)网站设计(实际上还有[谷歌隐私](https://web.archive.org/web/20230205192629/https://privacy.google.com/)网站)强调将文本剪切成更小的块和片段，并将这些信息分发到每个都必须点击才能打开的框/副标题中，以获得相关信息。透明度？在我看来，这更像是混淆信息……*

以下是 DeepMind 在其道德与社会网站上的多个链接背后提出的原则:

> 社会效益
> 我们认为人工智能的发展应该服务于全球社会和环境利益，帮助建立更公平、更平等的社会。我们的研究将直接关注人工智能可以用来改善人们生活的方式，将他们的权利和福祉置于其核心位置。
> 
> 严谨和循证
> 我们的技术研究长期以来一直符合最高的学术标准，我们致力于在研究人工智能对社会的影响时保持这些标准。我们将进行理性严谨的循证研究，探索这些技术带来的机遇和挑战。同行评议的学术传统将研究向批判性反馈开放，对于这类工作至关重要。
> 
> 透明公开
> 我们将始终公开与谁合作以及我们资助了哪些项目。我们所有的研究资助都是不受限制的，我们永远不会试图影响或预先决定我们委托的研究的结果。当我们与外部研究人员合作或共同发表论文时，我们将披露他们是否获得了我们的资助。伦理学会团队发表的任何学术论文都将通过开放获取计划提供。
> 
> 多元化和跨学科
> 我们将努力让尽可能多的声音参与到我们的工作中，将不同的学科融合在一起，以包含不同的观点。我们认识到，人工智能提出的问题远远超出了技术领域，只有当我们做出审慎的努力，让不同的专业知识和知识来源参与进来，这些问题才能得到解答。
> 
> 协作和包容
> 我们相信，一项有潜力影响全社会的技术必须由全社会塑造并对全社会负责。因此，我们致力于支持一系列关于人工智能的公共和学术对话。通过在我们的研究人员和受这些新技术影响的人们之间建立持续的合作，我们寻求确保人工智能为所有人的利益服务。

鉴于道德研究部门的成立，我们向 DeepMind 提出了一些问题。我们将包括他们回复 **时的回复更新:**现在用斜体显示 DeepMind 的回复:

*   *   DeepMind 现在会公布内部道德委员会成员的名单吗？还是仍然对公众隐瞒这些信息？
        *DeepMind 拒绝就此事发表公开评论*
    *   **如果不会公布姓名，为什么不会？**
        *DeepMind 拒绝就此事发表公开评论*
    *   DeepMind 在资助一项它也在寻求从商业上受益的技术的伦理研究方面，是否发现了任何矛盾？DeepMind 的一位发言人表示:“我们认为开发人工智能的公司有责任进行并支持对其工作的更广泛影响进行公开研究和调查。在 DeepMind，我们的出发点是，所有人工智能应用都应该处于有意义的人类控制之下，并用于有益于社会的目的。要理解这在实践中意味着什么，需要对我们面临的最敏感的挑战进行严格的科学探究。”
    *   鉴于这项研究是由 DeepMind 资助的，如何确保公正性？DeepMind 的一位发言人说:“我们很幸运能得到以专业、正直和独立著称的独立人士的建议。他们、我们的内部员工和其他合作者可以自由探索人工智能在近期和未来的实际影响。如果他们的研究导致他们探索人工智能的潜在负面后果，那是他们作为研究员和独立研究人员的职权范围内的事情。虽然批评可能会让人不舒服，但这种程度的开放是我们确保进步、造福所有人的唯一途径。为了确保我们工作的严谨性、透明度和社会责任，我们与我们的同事、其他学者和民间社会一起制定了一套公共原则，指导我们的一切工作，我们欢迎对这些原则的反馈。”
    *   这个单位有多少人员？DeepMind 是否有现有员工加入该部门，或者该部门是否配备了全新员工？DeepMind 的一位发言人说:“今天伦理协会团队大约有 8 人，明年我们计划增加到 25 人。”
    *   **研究员是如何挑选的？有开放的申请流程吗？DeepMind 的一位发言人说:“我们最初的研究员是根据他们的诚信和学术档案或成就，以及他们提出挑战性问题的声誉而被选中的。通常，他们来自研究社区，专门研究与人工智能及其与社会的交叉相关的各种领域。他们有一个咨询功能，在 T21 社会发展的过程中，帮助塑造和决定 DeepMind 伦理学的工作和方向。未来，我们还将接受希望与我们合作的个人和组织提出的研究和其他合作建议。”**
    *   **道德操守股会公布其开展的所有研究吗？如果没有，它将如何选择发表和不发表的研究？该单位每年打算发表多少项研究？是否打算在六个关键研究主题中平等发表？该部门发表的所有研究都会首先经过同行评审吗？** *deep mind 发言人表示:“就像所有的事情研究一样，这很难说，尤其是在早期。但是我们希望明年早些时候开始发表论文，伦理学会小组发表的任何论文都将通过开放获取计划提供。总的来说，我们非常相信同行评议的学术传统。六个“研究主题”中涵盖的任何主题都在 DMES 研究员和学者的研究范围内，我们也欢迎对我们在此确定的范围之外的项目提出想法和建议。这是一个快速发展的领域，我们意识到我们可能没有预料到现阶段值得研究的一切。”*
    *   这个单位资助研究的预算是多少？这个预算完全来自 Alphabet 吗？还有其他资金支持者吗？DeepMind 的一位发言人说:“我们才刚刚开始，所以现在给出一个数字还为时过早。我们不接受任何外部组织的捐款。”