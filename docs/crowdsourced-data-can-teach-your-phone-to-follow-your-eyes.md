# 众包数据可以教会你的手机跟随你的眼睛

> 原文：<https://web.archive.org/web/https://techcrunch.com/2016/06/16/crowdsourced-data-can-teach-your-phone-to-follow-your-eyes/>

# 众包数据可以教会你的手机跟随你的眼睛

约翰·比格斯是一名作家、顾问、程序员，前东海岸编辑，现任 TechCrunch 特约撰稿人。他主要写技术、加密货币、安全、小工具、齿轮、手表和互联网。在经历了程序员的成长后，他转行成为了一名全职企业家和作家。他的作品出现在纽约时报，笔记本电脑，PC 升级，浪涌，Gizmodo，男性健康，InSync，Linux Journal，科普，Sync，他还写了一本书，名为《黑帽子:互联网时代的不适应者，罪犯和骗子》。

More posts by this contributor

眼球追踪一直是个棘手的问题。存在多摄像头解决方案是为了感知眼睛在 3D 空间中的位置，但总的来说，对于手机来说，观察你的窥视者指向哪里太难了。现在，麻省理工学院和佐治亚大学的研究人员创造了一个依靠众包数据的眼球追踪系统。

该团队创建了一个简单的应用程序，它在屏幕上显示一个点，然后询问它是在左侧还是右侧。受试者在看到圆点的地方点击，手机就会记录下互动的视频和图像。他们使用亚马逊的 Mechanical Turk 雇佣数百名用户进行测试，然后使用图像处理技术来准确评估他们在点击特定停止点时眼睛所指的位置。

麻省理工学院研究生阿迪蒂亚·科斯拉(Aditya Khosla)说:“这个领域陷入了鸡和蛋的循环之中。“由于很少有人拥有外部设备，因此没有太大的动力为他们开发应用程序。由于没有应用程序，人们就没有动力去购买这些设备。我们认为我们应该打破这个循环，尝试只使用你的前置摄像头，制作一款可以在单个移动设备上工作的眼球跟踪器。”

大多数眼球追踪系统使用较小的样本量，在付诸实践时往往会失败。然而，有了 800 个数据点，研究人员能够毫无困难地“看到”眼睛指向的地方。

他们使用机器学习技术从系统为每个用户拍摄的 1600 张照片中感知眼睛的位置。

研究人员的机器学习系统是一个神经网络，它是一个软件抽象，但可以被认为是一个由非常简单的信息处理器组成的巨大网络，这些处理器排列成离散的层。训练修改单个处理器的设置，以便馈送到底层的数据项(在这种情况下，是移动设备用户的静止图像)将由后续层处理。顶层的输出将是一个计算问题的解决方案——在这种情况下，是对用户视线方向的估计。

这意味着应用程序开发人员可以感应智能手机中的眼球运动，并有可能将这一功能添加到他们的设备中。这是对众包数据和机械土耳其人的一种有趣的使用，这可能会对残疾人使用手机产生影响……并使广告更容易瞄准。