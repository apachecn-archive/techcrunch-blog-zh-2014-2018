<html>
<head>
<title>We need to improve the accuracy of AI accuracy discussions | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们需要提高人工智能准确性讨论的准确性|技术危机</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/03/11/accuracy-of-accuracy/?ncid=rss">https://web.archive.org/web/https://techcrunch.com/2018/03/11/accuracy-of-accuracy/?ncid=rss</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">阅读科技媒体，你会被原谅相信人工智能会吃掉几乎每个行业和工作。没有一天没有另一个记者气喘吁吁地报道一些新的机器学习产品，这将击败人类的智能。不过，这种过度热情并不仅仅源于记者——他们只是传达了研究人员和初创公司创始人的疯狂乐观。</p>
<p class="translated">在过去的几年里，随着对深度学习和其他技术的大肆宣传，人们对人工智能和机器学习的兴趣激增。<a href="https://web.archive.org/web/20230316060538/https://www.timeshighereducation.com/data-bites/which-countries-and-universities-are-leading-ai-research">每年有数万篇人工智能研究论文发表</a>，而安吉利斯特的人工智能公司创业指南<a href="https://web.archive.org/web/20230316060538/https://angel.co/artificial-intelligence">包括四千多家初创公司</a>。</p>
<p class="translated">在一个又一个关于人工智能即将占据统治地位的故事——如果你愿意的话，那就是奇点——打击之后，根据东北大学/盖洛普民意测验<a href="https://web.archive.org/web/20230316060538/http://news.gallup.com/poll/228923/seen-greater-job-threat-immigration-offshoring.aspx">最近发布的一项调查，58%的美国人担心会因为自动化和人工智能等“新技术”而失去工作，这并不奇怪。这种恐惧在很大程度上超越了移民和外包。</a></p>
<p class="translated">但事实要复杂得多。专家们越来越认识到人工智能的“准确性”被夸大了。此外，大众媒体报道的准确性数字往往具有误导性，对数据进行更细致的评估后会发现，许多人工智能应用程序的功能比我们想象的要有限得多。人类可能真的会因为人工智能而丢掉工作，但是还有更长的路要走。</p>
<h2 class="translated">又一次复制危机</h2>
<p class="translated">在过去的十多年里，研究界围绕所谓的“复制危机”展开了激烈的争论——即研究人员无法复制诸如<a href="https://web.archive.org/web/20230316060538/https://www.theatlantic.com/science/archive/2016/03/psychologys-replication-crisis-cant-be-wished-away/472272/">心理学</a>和<a href="https://web.archive.org/web/20230316060538/https://www.nature.com/news/cancer-reproducibility-project-releases-first-results-1.21304">肿瘤学</a>等不同领域的关键论文的结果。一些研究甚至将失败重复的次数<a href="https://web.archive.org/web/20230316060538/https://www.nature.com/news/over-half-of-psychology-studies-fail-reproducibility-test-1.18248">置于所有论文</a>的一半以上。</p>
<p class="translated">这场危机的原因很多。研究人员面临着“发表或灭亡”的局面，他们需要积极的结果，以继续他们的工作。期刊希望引人注目的结果来获得更多的读者，而“p-hacking”允许研究人员通过篡改统计数据来获得更好的结果。</p>
<p class="translated">人工智能研究也不能免受这些结构性因素的影响，事实上，鉴于人工智能令人难以置信的兴奋感，情况可能会更糟，这促使研究人员找到最新颖的进展，并尽可能迅速和广泛地分享它们。</p>
<p class="translated">现在，人们越来越担心，人工智能研究中最重要的成果很难复制，如果不是不可能复制的话。一个挑战是，许多<a href="https://web.archive.org/web/20230316060538/http://www.sciencemag.org/news/2018/02/missing-data-hinder-replication-artificial-intelligence-studies">人工智能论文缺少运行其底层算法</a>所需的关键数据，或者更糟的是，甚至不包括正在研究的算法的源代码。机器学习中使用的训练数据是算法结果成功的很大一部分，因此没有这些数据，几乎不可能确定特定算法是否如所描述的那样发挥作用。</p>
<p class="translated">更糟糕的是，在急于发表新颖和新结果的过程中，人们越来越少关注重复研究，以显示不同结果的可重复性。从上面链接的 MIT Technology Review 文章来看，“……蒙特利尔麦吉尔大学的计算机科学家彼得·亨德森(Peter Henderson)表明，旨在通过试错法学习的人工智能的性能不仅对所用的确切代码高度敏感，而且对启动训练所生成的随机数和‘超参数’(hyperparameters)高度敏感——这些设置不是算法的核心，但会影响它学习的速度。”非常小的变化可能导致非常不同的结果。</p>
<p class="translated">就像营养科学中的一项研究一样，我们应该持保留态度(或者现在是黄油，或者是糖？)，新的人工智能论文和服务应该以类似的怀疑态度来对待。证明单一结果的一篇论文或一项服务并不能证明其准确性。通常，这意味着在非常特定的条件下运行的非常精选的数据集可能会产生很高的精度，而这种精度不适用于更一般的输入集。</p>
<h2 class="translated">准确报告准确性</h2>
<p class="translated">人们对人工智能解决各种问题的潜力明显感到兴奋，从医院的临床评估到文件扫描，再到预防恐怖主义。然而，这种兴奋已经影响了记者甚至研究人员准确报道的能力。</p>
<p class="translated"><a href="https://web.archive.org/web/20230316060538/https://www.inverse.com/article/37873-artificial-intelligence-colorectal-cancer-detection">以最近这篇关于使用人工智能检测结肠直肠癌的文章为例</a>。这篇文章说，“结果令人印象深刻——准确率为 86%——因为这些数字是通过评估已经被诊断患有结肠直肠息肉的患者而获得的。”文章还包括了最初研究的关键结果段落。</p>
<p class="translated"><a href="https://web.archive.org/web/20230316060538/https://www.theverge.com/2016/9/27/13078138/google-translate-ai-machine-learning-gnmt">或者拿这篇关于谷歌机器学习服务执行语言翻译的文章</a>。“在某些情况下，谷歌表示其 GNMT 系统甚至接近人类水平的翻译准确度。这种近似对等仅限于相关语言之间的转换，比如从英语到西班牙语和法语。”</p>
<p class="translated">这些是随机选择的文章，但还有数百篇其他文章气喘吁吁地报道最新的人工智能进展，并抛出一个单一的准确性数字，或一个隐喻，如“人类水平”。要是评估人工智能程序也这么简单就好了！</p>
<p class="translated">假设你想确定一个人皮肤上的痣是否是癌性的。这就是所谓的二元分类问题——目标是将患者分为两组:癌症患者和非癌症患者。一个具有完美精确度的完美算法会将每个癌症患者识别为患有癌症，并将每个未患癌症的人识别为未患癌症。换句话说，结果不会有假阳性或假阴性。</p>
<p class="translated">这很简单，但挑战在于，对于计算机和人类来说，像癌症这样的疾病基本上不可能完全准确地识别。每项医学诊断测试通常都必须在灵敏度(它能正确识别多少阳性)和特异性(它能正确识别多少阴性)之间做出权衡。考虑到错误识别癌症患者的危险(可能导致死亡)，测试通常被设计成通过降低特异性(即增加假阳性以确保尽可能多的阳性被识别)来确保高灵敏度。</p>
<p class="translated">产品设计师可以选择如何平衡这些相互竞争的优先级。根据误报和漏报的成本，相同的算法可能以不同的方式实现。如果一篇研究文章或服务没有讨论这些权衡，那么准确性就没有得到公平的体现。</p>
<p class="translated">更重要的是，单一精度值有点用词不当。准确性反映了多少阳性患者被阳性识别，多少阴性患者被阴性识别。但是我们可以通过增加一个数字和减少另一个数字来保持相同的精度，反之亦然。换句话说，一项测试可以强调很好地检测出阳性患者，或者它可以强调从结果中排除阴性患者，同时保持相同的准确性。这些是非常不同的最终目标，一些算法可能更适合其中一个而不是另一个。</p>
<p class="translated">这就是使用单一数字的复杂性。比喻更不好。“人类水平”并没有说什么——很少有关于人类错误率的好数据，即使有这样的数据，也很难比较人类和机器学习所犯错误的类型。</p>
<p class="translated">这只是最简单的分类问题的一些复杂之处。评估人工智能质量的所有细微差别至少需要一本书，事实上，一些研究人员无疑将花费他们的一生来评估这些系统。</p>
<p class="translated">不是每个人都可以获得人工智能博士学位，但作为这些新技术的消费者，我们每个人都有责任用批判的眼光看待这些阳光的说法，并严格评估它们。无论是再现性还是惊人的准确性，重要的是要记住，我们依赖的许多人工智能技术仅仅是技术婴儿，仍然需要更多的时间来成熟。</p>
			</div>

			</div>    
</body>
</html>