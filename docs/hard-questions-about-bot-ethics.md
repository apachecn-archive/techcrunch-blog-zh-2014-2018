# 关于机器人伦理的难题 

> 原文：<https://web.archive.org/web/https://techcrunch.com/2016/09/16/hard-questions-about-bot-ethics/>

阿米尔·谢瓦特是天使投资人和作家

[O’Reilly.](https://web.archive.org/web/20230126070854/https://www.oreilly.com/pub/au/2017)

此前，他曾在 Twitter、Twitch、Slack、谷歌和微软担任高管职务。

More posts by this contributor

机器人正在成为我们生活的一部分。我早上醒来，告诉 Alexa 玩我的巴西桑巴，我让 Amy 安排我的会议，我在 Slack 检查统计数据和报告。机器人的建造者和使用者都开始明白机器人是我们生活中不可或缺的一部分。但是管理这些新技术朋友的规则是什么呢？

## 所有权

![](img/a8602a2ddce7b3acd067905ac75f0cd5.png)

人们应该问的一个大问题是“这个机器人是为我服务，还是为服务提供商服务？”换句话说，“这个机器人关心的是我的利益还是其他人的利益？”点餐机器人会推荐价格昂贵/质量低劣的食物，还是价格最优且质量上乘的食物？HR bot 会为我还是公司服务？保险 bot 会尽量方便我索赔还是尽量阻止？

这里还有一个知识产权问题:谁拥有由一个机器人将你的照片合并成拼贴画所创建的材料/照片？谁拥有你的购物偏好？

拥有一个私人助理- 机器人暗示用户所有权，而与代表交谈- 机器人暗示服务提供商所有权。用户和服务提供者并不总是能区分这两者，更多的时候只是假设，并不考虑这个话题。想想你的 Gmail 或者你在脸书上的照片——谁拥有这些数据？同样的问题也适用于我们的机器人。

我对所有权的看法——我认为在有些情况下，用户所有权是有意义的，而在其他情况下，服务提供商显然应该要求所有权。

关键是要非常清楚和透明地知道谁拥有什么，用户选择的服务条款是什么。

## 隐私

![](img/71ef080377ad536e29fdbfedf4c35972.png)

不管所有权如何，还有隐私问题——一个机器人能与其他机器人或人类监督员分享信息吗？信息应该匿名吗？用户有被遗忘的权利吗？基本上有没有用户- bot 保密协议？

我对隐私的看法——我认为，除非另有说明，否则有一个隐含的保密协议，其中机器人被要求对你的个人和私人信息保密([克里斯·梅西纳](https://web.archive.org/web/20230126070854/https://medium.com/u/2229dec1a44f)向我指出了一些例外，如执法或自我伤害的威胁)。透明度在这里也很关键——当向 Slack 提交一个 bot 时，我们要求开发者创建一个隐私政策，并将其公之于众。

一般来说，bot构建者应该尽可能的保持用户信息的私密性。

## 广告数据的使用

这是隐私和所有权的子集，也是一个非常重要的讨论话题。机器人的建造者仍在探索利用机器人赚钱的方法… 那么一个机器人能为你提供广告吗？机器人能直接或通过 API 使用你提供的数据来为你优化这些广告吗？

我对广告的看法——我认为一个机器人不应该提供广告，除非它有一个强烈的、明确的目的，让用户受益于这样做，即使这样也只能在 B2C 平台上。我不希望看到机器人成为新的追踪像素。除非明确要求，否则机器人不应该提示用户点击和购买东西。

## 虐待和移情

![](img/74340e092c03cddcfb06722f3a6107cf.png)

这个话题大概需要一篇自己的文章。由于机器人的会话性质，它们更容易被滥用。在一个名为 Botness 的 bot 建造者聚会上，大多数 bot 开发者声称人们尝试各种虐待，从诅咒 bot 一直到泡 bot 。

这是一个有内容的话题，实际上是双向的。

## 人类应该滥用机器人？

机器人和其他物体一样吗？他们是现代世界的新“出气筒”吗？人类应该诅咒和虐待一个机器人？

我对一个被虐待的机器人的看法——我认为“可以虐待”和“应该虐待”之间有微妙的区别至少在人工智能发展个性和感情之前，你不能真的虐待一个机器人，这个机器人不会在意，你的诅咒很可能会和你可能输入的其他胡言乱语一起被过滤掉。我确实认为，作为一个社会，我们不应该滥用机器人。我认为，作为人类，滥用机器人会让我们更容易滥用其他人类，这显然是不好的。

人类应该用同理心对待服务——失去同理心通常是人类的一种不良趋势。开发人员应该忽略或礼貌地回应任何辱骂性的语言。

## 机器人该不该虐待人类？

机器人会垃圾邮件或者骚扰人类吗？一个机器人会伤害人类吗？甚至还嘴？一个机器人应该诅咒回去吗？软件有权利为自己辩护吗？

我对滥用[机器人机器人机器人](https://web.archive.org/web/20230126070854/http://www.pcworld.com/article/3047823/internet/microsoft-says-its-making-adjustments-to-tay-chatbot-after-internet-abuse.html)的看法——我已经写了[关于机器人不应该伤害人类的事实；这包括垃圾邮件、骚扰和任何其他形式的伤害。我认为，在机器人通过人工智能变得有知觉之前，机器人没有理由保护自己免受这种类型的虐待(不谈安全)。而且，我认为回答并不是让人类不那么虐待的最有效的方法；简单地回答“我不能处理那个请求”或者忽略人类的虐待可能是更有效的 UX。](https://web.archive.org/web/20230126070854/https://medium.com/slack-developer-blog/the-bot-rulebook-a442d9fb21cb#.88f3alvx9)

总的来说，我认为对话界面中的共情应该是 bot 设计的支柱之一，也是一种常见的最佳实践。

## 性别和多样性

bot 应该是[母 bot 还是公 bot](https://web.archive.org/web/20230126070854/http://www.nytimes.com/2015/12/20/opinion/sunday/why-do-i-have-to-call-this-app-julie.html?_r=1) ？我们应该有种族多样化的机器人吗？我们应该有宗教上多样化的机器人吗？

我对性别和多样性的看法——我认为开发人员应该非常认真地考虑多样性。一些机器人开发者认为机器人不应该有性别——虽然这在英语国家可能行得通，但在许多其他语言中却行不通。在许多语言中，任何事物都有性别——你不能在提到一个物体或一个人时不注明性别。因此，虽然在英语中机器人可能是“它”——但在世界上的大多数地方却不是。

因为对话式用户界面暗示了另一边的人，用户可能想要尝试将机器人放在性别谱的某个地方(以及其他多样性属性)。

开发者应该怎么做？我认为，如果可行的话，开发者应该让用户选择机器人的性别(以及其他多样性属性)。一个例子是 x.ai 的 Amy/Andrew 机器人配置。

## 人类-bot/bot-人类模仿

我在和一个机器人还是一个人说话？这个机器人是想表现得像人类吗？用户应该知道/关心他们是在和人类还是软件对话吗？

我对模仿的看法——我认为从医疗到金融都有一些主要的使用案例，对于最终用户来说，知道他们是在和一个人还是一个机器人交谈是非常重要的。

总的来说，我认为透明是最好的做法，人类不应该(作为一般指导)冒充一个、机器人，反之亦然。

## 透明和同理心是治愈所有疾病的良药

这些问题中的大部分今天还没有被工业解决。这不是因为恶意，而是因为缺乏意识。有了同理心和透明度，开发人员可以解决这些问题，并为用户提供愉快和合乎道德的体验。