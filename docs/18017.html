<html>
<head>
<title>Facebook's new transparency report now includes data on takedowns of 'bad' content, including hate speech • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书新的透明度报告现在包括了对“不良”内容的删除数据，包括仇恨言论 TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/05/15/facebooks-new-transparency-report-now-includes-data-on-takedowns-of-bad-content-including-hate-speech/">https://web.archive.org/web/https://techcrunch.com/2018/05/15/facebooks-new-transparency-report-now-includes-data-on-takedowns-of-bad-content-including-hate-speech/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">脸书今天早上发布了最新的<a href="https://web.archive.org/web/20221205161218/https://newsroom.fb.com/news/2018/05/transparency-report-h2-2017/">透明度报告</a>，该社交网络分享了政府请求用户数据的信息，并指出与 2017 年上半年相比，这些请求在全球范围内增加了约 4%，尽管美国政府发起的请求大致保持不变。此外，该公司在通常的透明度报告中增加了一份新报告，重点是详细说明脸书如何以及为什么采取行动执行其社区标准，特别是在图形暴力、成人裸体和性活动、恐怖主义宣传、仇恨言论、垃圾邮件和虚假账户等领域。</p>
<p class="translated">就政府对用户数据的请求而言，全球增长导致 2017 年下半年的 82，341 次请求，高于上半年的<a href="https://web.archive.org/web/20221205161218/https://techcrunch.com/2017/12/18/government-requests-for-facebook-user-data-continue-to-increase-worldwide/"> 78，890 次。</a>美国的申请数量大致保持不变，为 32，742 份；尽管 62%的调查包含了禁止脸书提醒用户的保密条款——这一比例高于今年早些时候的 57 %,也高于此前报告中的 50%。这表明在执法机构中使用 NDA 变得更加普遍。</p>
<p class="translated">今年下半年，脸书根据当地法律限制的内容数量有所下降，从 28036 条降至 14294 条。但这并不奇怪——由于墨西哥的校园枪击事件，上一份报告中这类请求出现了不同寻常的高峰，导致政府要求删除内容。</p>
<p class="translated">2017 年下半年，12 个国家的脸书服务中断 46 次，而上半年有 9 个国家的服务中断 52 次。</p>
<p class="translated">脸书和 Instagram 根据 373，934 份版权报告删除了 2，776，665 条内容，根据 61，172 份商标报告删除了 222，226 条内容，根据 28，680 份假冒报告删除了 459，176 条内容。</p>
<p class="translated">然而，这一次更有趣的数据来自一份新的报告，脸书将其附加到其透明度报告中，名为<a href="https://web.archive.org/web/20221205161218/https://transparency.facebook.com/community-standards-enforcement">社区标准执行报告</a>，该报告重点关注脸书审查小组的行动。这是脸书第一次发布与执法力度相关的数据，三周前发布了内部指导方针。</p>
<p class="translated">在 25 页的篇幅中，脸书在 4 月份解释了如何对其平台上的内容进行监管，特别是围绕图形暴力、成人裸体和性活动、恐怖主义宣传、仇恨言论、垃圾邮件和虚假账户等领域。这些是脸书搞砸时经常受到批评的领域——比如当<a href="https://web.archive.org/web/20221205161218/https://techcrunch.com/2016/09/09/facensorbook/">在意识到错误并恢复之前，它撤下了</a>有新闻价值的“凝固汽油弹女孩”历史照片，因为它包含儿童裸体。最近，它还因<a href="https://web.archive.org/web/20221205161218/https://www.nytimes.com/2018/04/09/business/facebook-myanmar-zuckerberg.html">助长缅甸暴力</a>而受到批评，因为极端分子充满仇恨言论的帖子煽动了暴力。这也是脸书<a href="https://web.archive.org/web/20221205161218/https://techcrunch.com/2018/05/14/facebook-adds-tools-to-report-conversations-in-messenger/">今天通过更新 Messenger </a>解决的问题，现在允许用户报告违反社区标准的对话。</p>
<p class="translated">今天的《社区标准报告》详细列出了它所实施的各种类别的攻击数量。</p>
<p class="translated">脸书表示，垃圾邮件和虚假账户是最大的类别，Q1 清除了 8.37 亿封垃圾邮件——几乎所有都是在用户举报前主动清除的。脸书还封杀了 5.83 亿个虚假账户，大多数都是在注册后几分钟内完成的。在此期间，网站上大约有 3-4%的脸书账户是假的。</p>
<p class="translated">该公司可能希望这些指标的规模让它看起来做得很好，而事实上，并没有用<a href="https://web.archive.org/web/20221205161218/https://techcrunch.com/2018/04/03/facebook-russia/">那么多俄罗斯账户</a>就让脸书的整个运营陷入混乱，导致<a href="https://web.archive.org/web/20221205161218/https://techcrunch.com/story/zuckerberg-testifies-at-congressional-hearings/">首席执行官马克·扎克伯格在正在考虑监管的国会前作证</a>。</p>
<p class="translated">此外，脸书表示，它在 2018 年 Q1 奥运会上拿下了以下几项:</p>
<ul>
<li class="translated">成人裸体和性活动:2100 万条内容；96%是由技术发现和标记的，而不是人</li>
<li class="translated">图形暴力:350 万条内容被撤下或添加警告标签；86%被技术发现并标记</li>
<li class="translated">仇恨言论:250 万条内容，38%被技术发现并标记</li>
</ul>
<p class="translated">您可能会注意到，其中一个领域在执行和自动化方面落后了。</p>
<p class="translated">事实上，脸书承认其识别仇恨言论的系统“仍然没有很好地发挥作用”，因此需要由审查小组进行检查。</p>
<p class="translated">“……为了防止滥用，我们还有很多工作要做，”产品管理副总裁盖伊·罗森在脸书的博客上写道。“部分原因是，像人工智能这样的技术虽然很有前途，但仍需数年时间才能有效处理大多数不良内容，因为上下文非常重要。”</p>
<p class="translated">换句话说，人工智能在自动标记裸体和暴力等事物方面可能是有用的，但监管仇恨言论需要比机器还能处理的更多的细微差别。问题是，人们可能在讨论敏感话题，但他们这样做是为了分享新闻，或者以尊重的方式，甚至是描述发生在他们身上的事情。这并不总是威胁或仇恨言论，但一个只解析单词而不理解完整讨论的系统不知道这一点。</p>
<p class="translated">要让人工智能系统在这一领域达到标准，需要大量的训练数据。脸书表示，对于一些不太常用的语言，它没有这个功能。</p>
<p class="translated">(这也是对缅甸局势的一种可能的回应，该公司在六个民间社会组织<a href="https://web.archive.org/web/20221205161218/https://www.nytimes.com/2018/04/05/technology/zuckerberg-facebook-myanmar.html">在一封信</a>中批评扎克伯格之后，姗姗来迟地表示，它已经雇佣了“几十个”人类主持人。批评者称这还不够——例如，在德国，对仇恨言论有严格的法律——脸书雇佣了大约 1200 名版主，<a href="https://web.archive.org/web/20221205161218/https://www.nytimes.com/2018/04/09/business/facebook-myanmar-zuckerberg.html">NYT 称</a>。)</p>
<p class="translated">似乎显而易见的解决方案是在各地配备审核团队，直到人工智能技术能够像在内容政策执行的其他方面一样出色。这需要钱，但当人们因为脸书缺乏执行自己政策的能力而死亡时，这显然也是至关重要的。</p>
<p class="translated">脸书声称因此正在招聘，但没有透露具体人数、地点和时间。</p>
<p class="translated">“我们正在大量投资于更多的人和更好的技术，以使脸书对每个人都更安全，”罗森写道。</p>
<p class="translated">但是脸书的主要焦点似乎是在改进技术上。</p>
<p class="translated">“脸书正在大量投资，让更多的人来审查被标记的内容。但正如盖伊·罗森两周前解释的那样，机器学习、计算机视觉和人工智能等新技术帮助我们更快地发现更多不良内容——比人们能够做到的更快，规模更大，”分析副总裁 Alex Schultz 在一篇关于脸书方法论的相关帖子中说。</p>
<p class="translated">他特别吹捧人工智能是一种工具，可以在脸书的内容被报道之前就让它消失。</p>
<p class="translated">但是人工智能还没有准备好监管所有的仇恨言论，所以脸书需要一个权宜之计——即使代价高昂。</p>
			</div>

			</div>    
</body>
</html>