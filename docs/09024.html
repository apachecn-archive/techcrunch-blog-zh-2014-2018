<html>
<head>
<title>A cautionary tale about humans creating biased AI models • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于人类创造有偏见的人工智能模型的警示故事TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2016/09/11/a-cautionary-tale-about-humans-creating-biased-ai-models/">https://web.archive.org/web/https://techcrunch.com/2016/09/11/a-cautionary-tale-about-humans-creating-biased-ai-models/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary">
</p><div class="article__contributor-byline">
	

		<div class="contributor-byline__bio"><p class="translated">马特·本克是</p><a href="https://web.archive.org/web/20221207111842/http://www.spare5.com/">Spare5</a><p class="translated">。此前，他曾在Getty Images、微软和波音公司工作。</p></div>
	
		<div class="contributor-byline__more-articles">
		<span class="more-articles-title">More posts by this contributor</span>
		
	</div>
	</div>

<p dir="ltr" class="translated">大多数人工智能<span class="il">模型</span>是由<span class="il">人类</span>构建和训练的，因此有可能学习、延续和大规模扩展人类训练者的偏见。这是今年早些时候发表在《纽约时报》上的两篇颇具启发性的文章中的警告词，这两篇文章分别由彭博<a target="_blank" href="https://web.archive.org/web/20221207111842/http://www.bloomberg.com/news/articles/2016-06-23/artificial-intelligence-has-a-sea-of-dudes-problem">的Jack Clark和纽约时报</a>的Kate Crawford发表。</p>
<p dir="ltr" class="translated">TL；dr:人工智能领域缺乏多样性——甚至比我们的大多数软件行业都更加引人注目。当一个<span class="il"> AI </span>从业者建立一个数据集来训练他或她的算法时，这个数据集很可能只代表一个世界观:从业者的世界观。由此产生的<span class="il">人工智能</span>模型充其量展示了一种非多样化的“智能”，而在最坏的情况下则展示了一种有偏见的<span class="il">甚至是令人不快的智能。</span></p>
<p class="translated">这些文章集中在两个相关的领域，当谈到构建人工智能时，多样性和人口统计学很重要:数据科学家和数据科学家对训练数据的选择。同样，该理论认为，尽管这是潜意识的，但从业者对训练数据的选择——比如，人们眼睛的图像或英语推特——反映了对象的类型、经历等。从业者最熟悉的(也许是特定人口统计的眼睛图像，或者用英式英语写的推文)。</p>
<p class="translated">不过，人口统计和多样性还有第三个重要的方面。这一点同样重要，而且经常被忽视——注释者。</p>
<h2 class="translated">许多人=许多(不同的)观点</h2>
<p dir="ltr" class="translated">用于训练<span class="il"> AI </span>和机器学习<span class="il">模型</span>的数据必须被标记——或者注释——才能被输入算法。例如，计算机视觉<span class="il">模型</span>需要注释来描述图像所属的类别、其中的对象、对象出现的上下文等等。</p>
<p dir="ltr">	</p><div class="article-block block--pullout block--right">
		<blockquote class="translated">我们需要敏锐地意识到是什么让我们所有人，嗯…成为人类。</blockquote>
	</div>
	
<p dir="ltr" class="translated">自然语言<span class="il">模型</span>需要注释来教导<span class="il">模型</span>例如，一条推文的情感，或者一串单词是关于在线购买状态的问题。在计算机能够自己知道或“看到”这些东西之前，它必须被展示许多自信的正面和负面例子(又名地面真理或黄金标准数据)。您只能从正确的人类注释者那里获得这种确定性。</p>
<p dir="ltr" class="translated">那么，如果不仔细考虑谁在注释数据，会发生什么呢？如果不考虑不同的<span class="il">人</span>的不同偏好、倾向和偏见，会发生什么？我们做了一个有趣的实验来寻找答案。</p>
<h2 class="translated">性别有很大的不同</h2>
<p dir="ltr" class="translated">实际上，我们并没有打算进行实验。我们只是想<span class="il">创造</span>一些我们认为<a target="_blank" href="https://web.archive.org/web/20221207111842/https://spare5.com/platform/">我们令人敬畏的任务社区</a>会喜欢的有趣的东西。想法？让人们有机会在业余时间评价小狗的可爱程度。虽然我们把所有的任务都设计得有趣和吸引人，但它们仍然需要智慧和技能，我们认为加入一些只是为了微笑的任务会很酷。一个可爱的小脑残，如果你愿意的话。</p>
<p class="translated">所以我们设立了一个“给小狗打分”的任务，给用户提供小狗的照片，让他们给每只小狗的可爱程度打分，从1星到5星不等。每个人都喜欢它。包括我们。咄！我们喜欢狗！(也是猫！我们也喜欢猫。还有养猫的人。郑重声明。但是当我们分析这些数据时，有一件事立刻引起了我们的注意:平均而言，女性给出了更高的可爱度评分——在统计上高出0.16颗星。</p>
<p dir="ltr" class="translated"><img decoding="async" loading="lazy" class="CToWUd a6T" src="../Images/54b6964e24016f5df2ecd011455ed6e9.png" alt="RateThePuppies_GenderGap.png" data-original-src="https://web.archive.org/web/20221207111842im_/https://lh5.googleusercontent.com/69gebI2P9kfYVSB32Sg7jvm-2By6H9msg50M3AbTMy9_lquNJRWu0SJFKWNTOXitOEuiaRKxBYEAixKQ1RFvLzNN6-yis9L-a8mxj5h4YD7ic5iPTOWHePqG1o0hMWGTNQXxXLiy"/></p>
<p class="translated">有明显的性别差异——一种非常一致的模式，即女性认为小狗比男性更可爱。对于“不太可爱”的人来说，女性和男性的评分差距更小。)狗，更宽的给更可爱的。令人着迷。</p>
<p class="translated">我甚至不会试图解开这些发现的社会含义，<span class="il">但</span>这里的教训是:如果你正在训练一个人工智能模型——特别是一个你希望能够执行主观任务的模型——有三个领域你必须评估和考虑人口统计和多样性:</p>
<ul>
<li class="translated">你自己</li>
<li class="translated">您的数据</li>
<li class="translated">您的注释者</li>
</ul>
<p class="translated">这是一个简单的例子:二元性别差异解释了一个图像的主观数字度量。然而，这是出乎意料的，意义重大。随着我们的行业部署极其复杂的<span class="il">模型</span>,将芯片组、算法和科学家推向极限，我们面临着强化微妙偏见的风险，其力度之大、规模之大是以前无法想象的。更有害的是，许多人工智能强化了他们自己的学习，所以我们需要仔细考虑随着时间的推移进行“监督的”(也就是人类)再培训。</p>
<p class="translated">人工智能有望改变我们所有人的生活——它已经微妙地指导着我们购物、约会、导航、投资等方式。<span class="il">但是</span>为了确保它变得更好，我们所有的从业者都需要努力做到兼容并蓄。我们需要敏锐地意识到是什么让我们所有人，嗯…成为人类。尤其是微妙的，隐藏的东西。</p>
			</div>

			</div>    
</body>
</html>