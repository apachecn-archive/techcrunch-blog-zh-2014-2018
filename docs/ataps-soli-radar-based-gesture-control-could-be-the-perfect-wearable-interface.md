# ATAP 基于“Soli”雷达的手势控制可能是完美的可穿戴界面 

> 原文：<https://web.archive.org/web/https://techcrunch.com/2015/05/29/ataps-soli-radar-based-gesture-control-could-be-the-perfect-wearable-interface/>

谷歌的 ATAP 项目 Soli 试图利用手和手指操纵的力量，使其更容易与越来越小的设备和屏幕进行交互。它认为，我们应该使用我们的“手部动作词汇”来控制设备，而不是使用工具，即使设备并不存在。

它的作用是让你使用自然的手部动作来控制设备，甚至通过材料(例如，你可以将传感器安装在桌子下面)精确地检测难以置信的细微动作。它使用雷达来实现这一点(我稍后会谈到这一点)，并允许您以相同的精度操纵微型或大型显示器，这要归功于不需要触摸点大小的限制。

触觉反馈也包括在内，因为你的手自然会提供它——当你的指尖接触指尖时，你自己的皮肤会提供摩擦。然后，Soli 被设计成将你的手重新想象成它自己的用户界面。这当然需要传感器来检测运动，但在硬件方面应该没有其他要求。

【图库 ids="1164759，1164760，1164758，1164757，1164755，1164754，1164753，1164752，1164751，1164750，1164748，1164747，1164746，1164745，1164744，1164744

Soli 被设计用于微型设备，如智能手表，并通过表面和远距离工作。ATAP 发现雷达是完成这一任务的合适传感器，除了尺寸之外，它满足了所有的要求。因此，他们开始把它变小。通过反复的硬件设计过程，他们将其从家用游戏机的大小缩小到不到四分之一。

ATAP 也实现了规模化生产，在 10 个月的开发时间内全部完成。他们还发现了如何追踪接收信号的微小变化来确定单个手指的位置。它对非常轻微的运动做出反应，这要归功于将信号转换成许多不同视觉化图像的技术，以获得关于你的手到底在做什么的最终、微妙和多维的信息。

API 将为开发人员提供所有已翻译的信号信息，让他们在所有不同阶段的已解释数据中随心所欲。

Soli 的目标是在今年晚些时候广泛上市，其形式可用于智能手表等可穿戴设备。这可能会大大有助于提高 Android Wear 硬件的性能，所以我们希望它能在今年假期发布大型旗舰设备时及时到来。

[![](img/b4af02481cbe09360fdab033fe0b8b2b.png)](https://web.archive.org/web/20221221003904/https://techcrunch.com/tag/io2015/)