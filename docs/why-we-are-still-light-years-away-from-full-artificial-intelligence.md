# 为什么我们离完全人工智能还有几光年的距离 

> 原文：<https://web.archive.org/web/https://techcrunch.com/2016/12/14/why-we-are-still-light-years-away-from-full-artificial-intelligence/>

克拉拉·卢是

[ViSenze](https://web.archive.org/web/20230104162714/https://www.visenze.com/)

，这是一家人工智能公司，它使通过图像进行搜索成为可能，而无需关键字。

未来就在这里…或者是吗？

有这么多关于人类如何处于完全人工智能(人工智能)尖端的文章充斥着媒体空间，难怪我们相信未来——充满机器人、无人机和自动驾驶汽车，以及人类对这些机器的控制越来越少——就在我们的门口。

但是我们真的像我们想象的那样快地接近奇点吗？

不难看出，埃隆·马斯克(Elon Musk)、斯蒂芬·霍金(Stephen Hawking)等全球领先的大学院系和研究中心，以及更多人高度关注人工智能带来的潜在风险，并立即采取行动，以避免不久的将来出现末日场景。他们预测，到 2030 年，机器将通过应用人类智能来发展意识。

事实上，霍金博士告诉 BBC，“全人工智能的发展可能意味着人类的终结。”这意味着未来就在眼前，可能很快就会超过我们。

然而，事实是，我们远未实现真正的人工智能——像人类智能一样反应迅速、充满活力、自我完善和强大的东西。我说的不是 100 年，而是可能几个世纪，几千年，也许，我们可能永远也不会到达那里。

以下是一些原因。

## 聪明并不等同于超聪明

全人工智能，或者说超级智能，应该拥有人类全部的认知能力。这包括自我意识、感觉和意识，因为这些都是人类认知的特征。

牛津大学哲学家、人工智能领域的主要思想家尼克·博斯特罗姆[将超级智能](https://web.archive.org/web/20230104162714/http://www.nickbostrom.com/superintelligence.html)定义为“在几乎每个领域，包括科学创造力、普遍智慧和社交技能，都比最优秀的人类大脑聪明得多的智力。”

现在人工智能只存在于一个领域。例如，有一个人工智能可以在国际象棋中击败世界象棋冠军，但这是它唯一能做的事情。

即使科学家已经建立了模拟大脑如何理解、分析信息和构建概念的复杂层次的神经网络，他们也不知道那里到底发生了什么，为什么神经网络以某种方式解释事物。

> 全人工智能最极端的承诺是基于一个有缺陷的前提:我们理解人类的智力和意识。

从科学的角度来看，它们只是一堆数学和方程，只是一堆数字。而且我们都知道[人类的智力和人类的大脑远没有那个](https://web.archive.org/web/20230104162714/https://aeon.co/essays/your-brain-does-not-process-information-and-it-is-not-a-computer)。

“我没有看到任何迹象表明我们正接近一个奇点，”[纽约大学计算机科学家 Ernest Davis](https://web.archive.org/web/20230104162714/http://www.livescience.com/29379-intelligent-robots-will-overtake-humans.html) 说。“虽然人工智能可以打败最好的国际象棋或危险游戏选手，并完成其他专门的任务，但在常识、视觉、语言和对物理世界如何运作的直觉方面，它仍然落后于 7 岁的平均水平。”

未能认识到这种智能和完全人工智能之间的区别可能导致霍金和马斯克的存在主义担忧，他们都认为我们已经走在发展完全人工智能的道路上。

## 我们自己对智能和超智能的理解是有限的

“要实现奇点，仅仅运行今天的软件更快是不够的，”微软联合创始人保罗·艾伦[在 2011 年写道](https://web.archive.org/web/20230104162714/https://www.technologyreview.com/s/425733/paul-allen-the-singularity-isnt-near/)。“我们还需要构建更智能、更强大的软件程序。创造这种先进的软件需要对人类认知的基础有一个预先的科学理解，而我们只是触及了表面。”

本质上，最极端的全人工智能承诺是基于一个有缺陷的前提:我们理解人类的智力和意识。

大多数研究大脑和思维的专家普遍同意至少两件事:我们不知道，具体而一致地，智力是什么，我们不知道意识是什么。

神经科学和神经心理学没有给出人类智力的定义——相反，它们有很多定义。不同的领域，甚至不同的研究者，用不同的术语来定义智力。

目前，人工智能专家正在研究智能的具体定义，即学习、识别模式、显示情感行为和解决分析问题的能力。然而，这仅仅是在关于认知本质的拥挤的、模糊形成的想法的海洋中对智力的一个定义。

如果我们人类不理解智能，我们如何创造具有“智能”能力的计算机？

## 人脑太复杂，无法复制

为了复制人脑及其工作方式，科学家们一直在试图克隆大脑，或建立一个受大脑启发的系统。

> 我们对智力、意识、甚至人类思维的概念的了解，仍处于幼稚阶段。

人类大脑大约有 1000 亿个神经元，神经元之间有 1 万亿个连接。迄今为止，人工绘制活体大脑的最佳尝试是由[全球会议项目](https://web.archive.org/web/20230104162714/http://www.ibtimes.co.uk/lego-robot-controlled-by-artificial-worm-brain-developed-by-openworm-project-1485174)完成的。其背后的团队已经成功地将线虫的 302 个神经元映射到计算机模拟中，为简单的乐高机器人的运动提供动力。

虽然这本身就是一个非凡的壮举，但机械地创造一个神经元距离重建一个完整的人脑(一个生物学上无限复杂的结构)还有几光年的距离——更不用说理解如何合成人类的意识和智能了。

自然，我们不需要模仿人类大脑来设计我们的人工智能系统；然而，如果我们的目标是比人类更聪明的人工智能，那么这意味着它至少必须在某一方面超过人脑。也许最重要的是，大脑也是我们现有的最佳基准。

## 计算能力的局限性

科学界有很多谈论，人们希望量子计算能在我们的人工智能之旅中带我们前进。

量子计算机是多年来的梦想，因为目前的计算机功能不够强大或速度不够快，它们没有能力模拟人脑，所以像[谷歌这样的科技巨头已经建立了自己的量子计算机](https://web.archive.org/web/20230104162714/http://www.sciencealert.com/google-s-quantum-computer-is-helping-us-understand-quantum-physics)专门从事这种工作。

然而，量子计算对我们来说仍然是一个谜，并且[是出了名的难以驯服的野兽。与普通计算机(二进制，1 或 0)不同，量子计算机可以是其中之一，也可以同时是两者。这意味着科学家必须处理量子力学的所有古怪特性，才能正确地给量子计算机编程。](https://web.archive.org/web/20230104162714/https://www.washingtonpost.com/news/innovations/wp/2015/12/10/why-googles-new-quantum-computer-could-launch-an-artificial-intelligence-arms-race/)

此外，测试结果并不像谷歌声称的那样令人印象深刻。量子计算机极难编程，并且高度不可预测——这是一个需要相当长时间才能解决的问题。

## 向全人工智能的巨大飞跃

技术有潜力和能力以前所未有的速度向前发展；我们见证了工业革命期间感受到的机械化的快速时期，以及互联网给我们的交流方式带来的巨大变化。

然而，我们对智力、意识、甚至人类思维的概念的了解，仍然停留在幼稚阶段。而这些知识上的空白，必将拖累投射的 AI 时间轴。

到目前为止，我们构建的人工智能距离接收信息和理解信息还有一步之遥——尽管是一大步。这是从先进技术到人工创造意识的巨大飞跃。

正在开发任何接近人工智能技术的公司只能在未来许多许多年里坚持不懈地寻找真正的人工智能。