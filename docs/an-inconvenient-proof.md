# 一个不方便的证明

> 原文：<https://web.archive.org/web/https://techcrunch.com/2015/11/07/an-inconvenient-proof/>

约翰·c·海文斯撰稿人

[*没人料到西班牙会有宗教裁判所！*](https://web.archive.org/web/20230324115615/https://www.youtube.com/watch?v=Tym0MObFpTI)

我仍然记得我第一次在我的地下室看这个 Python 小品的时候，是从 PBS 录制到我的 VCR 上的。作为一名基督徒，我想我可能会被这些家伙嘲笑教会的某些方面所冒犯。但是太有趣了，不能不去欣赏。太真实了。以基督的名义杀人相当于甘地的暴饮暴食。它是假冒的。它不尊重归因于耶稣的话语和行为的教导。在我对《新约圣经》的研究中，我还没有找到《马太福音》28:19 的拉丁文、希腊文或亚拉姆文译本，其中说，“去使万民作我的门徒……或杀他们”。”

我上大学打算成为一名部长，主修历史。我爱上了研究，尤其是对新约圣经的研究。具有讽刺意味的是，最初，这种迷恋源于我缺乏信仰。像许多执着于宗教信仰和诚实内省的人一样，我觉得如果我记住了足够多的考古细节，我可以通过经验事实证明基督是上帝之子。从科学上来说，有大量的证据证明新约中许多书的历史性。但是同样的，我可能想介绍两个好朋友认识，希望他们可以相爱，我意识到我不能强迫一个人相信上帝。

这取决于他们。

## 自由意志是个婊子

*一个不方便的证明*指的是个性化算法通过代码传教的事实。它们被设计来审视我们的生活，同时也被设计来影响我们的行为。由人类创造的每一种算法都充满了制造商的偏见、商业目标和个人议程。这并没有让人工智能变得恶毒。但是除非允许个人控制自己的个人信息，否则算法经济就是数据独裁。当你被秘密跟踪和潜意识操控时，就没有自由意志可言了。

## 我们的 ID 就是他们的 IP

我曾经在一家排名前 10 的公关公司担任执行副总裁，所以我可以根据我的经验说出下面的话:

*没有一个营销漏斗以禁欲告终。*

我从来没有在全球 CMO 的客户会议上，有人指着一张图表说，“在客户旅程的这一点上，我们让他们独处。”没有。我记得我们曾经和一个客户做过一次重大的广告购买，在那里，被介绍了一种新产品的人会通过广告在网上被跟踪，这些广告出现在他们冲浪的任何地方长达六个月，直到他们点击我们的广告。

**事实:**今天，我们个人的个人数据是一种商品。我们被训练放弃我们的数据，无论是为了换取“免费”服务还是仅仅为了方便。但它如此容易利用的事实对人工智能来说是一个巨大的福音。整体研究人类行为从未如此简单。

**事实:**一个组织的数据是他们的知识产权。由于我们的数据可以自由获取，这意味着从我们独特的身份中产生的洞察力正在成为创造我们使用的设备的任何组织的财产。

John Deere 最近开创了这一先例，声称购买装有电脑的拖拉机的农民并不拥有这些车辆，而是获得了一个在车辆寿命内使用车辆的[默示许可](https://web.archive.org/web/20230324115615/http://www.wired.com/2015/04/dmca-ownership-john-deere/)。这意味着农民在拖拉机上采取的任何行动都可以作为 John Deere 改进其车辆的一种自由研发形式。虽然这些数据表面上是用来改进拖拉机供每个人使用，但农民并没有因为他们的见解提供的金钱利益而得到额外的补偿。

> 无论是关于上帝还是谷歌，自由意志都不能被强迫或控制成为现实。

现在将这种模式从拖拉机转移到自动驾驶汽车和陪伴机器人。加入无处不在的公司面部识别身份，[不受任何关于收集个人身份的联邦法律](https://web.archive.org/web/20230324115615/http://www.nbcnews.com/tech/security/privacy-groups-walk-out-talks-facial-recognition-software-n376291)的约束。我们可能知道也可能不知道的组织控制的无数个性化算法随意收获我们的行动，我们的个人数据是我们无法控制甚至无法完全访问的商品。

**事实:**无论人工智能有多么崇高的抱负，[算法经济](https://web.archive.org/web/20230324115615/http://www.theatlantic.com/business/archive/2014/03/the-algorithm-economy-inside-the-formulas-of-facebook-and-amazon/284358/)就是建立在这种数据混淆模型的基础上。

## 我们的主要武器是惊喜

除非为个人提供[个人云](https://web.archive.org/web/20230324115615/https://www.forrester.com/Personal+Identity+And+Data+Management/fulltext/-/E-RES60322)或通过设计提供[隐私的方法，否则是时候认识到阻止人们控制他们的个人数据意味着我们消除了他们控制自己身份的能力。这超越了隐私问题，涉及到一个人的代理感和心理健康。如果我们正在处理一个单一的个性化算法，想知道它如何影响我们的观点和选择感是一回事。当我们面对成千上万的算法时，这是另一回事，看不见却有影响力。很快，我们将冒着失去对我们是谁的主观真实感的风险，因为在这个问题上我们会有太多的外界意见。](https://web.archive.org/web/20230324115615/https://en.wikipedia.org/wiki/Privacy_by_design)

我们需要[算法经济的人工智能伦理标准](https://web.archive.org/web/20230324115615/http://mashable.com/2015/10/03/ethics-artificial-intelligence/#8U6f2G0Y_gqp)。它本质上不是基督教、佛教、无神论、技术或卢德派。是人。我们需要为情感(基于情绪的)和个人数据的交换创建一个技术框架，让每个人都可以决定他们共享什么数据，与谁共享，以及共享多长时间。这相当于一个自由开放的社会对一个独裁的社会。

这不会阻碍人工智能的发展。恰恰相反。故意混淆意味着我们最终不需要人类来分析他们的数据。我们已经知道他们要做什么了。让人类保留对他们数据的控制意味着我们仍然会被跟踪，但我们将保留说出我们真相的能力和基础设施。

我们混乱，辉煌，人性的真相。

无论是关于上帝还是谷歌，自由意志都不能被强迫或控制成为现实。虽然证明人工智能符合人类价值观可能不太方便，但这是真诚前进的唯一方式。