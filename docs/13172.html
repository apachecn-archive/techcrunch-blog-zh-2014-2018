<html>
<head>
<title>Google to ramp up AI efforts to ID extremism on YouTube • TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌将加大人工智能识别YouTube上极端主义的力度TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2017/06/19/google-to-ramp-up-ai-efforts-to-id-extremism-on-youtube/">https://web.archive.org/web/https://techcrunch.com/2017/06/19/google-to-ramp-up-ai-efforts-to-id-extremism-on-youtube/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">上周，脸书就其所谓的“棘手问题”寻求帮助，包括它应该如何解决其平台上恐怖主义宣传的传播。</p>
<p class="translated">昨天，谷歌紧随其后，通过《T2金融时报》的一篇专栏文章发表了自己的公开声明，解释了它是如何采取措施应对极端主义内容的。</p>
<p class="translated">这两家公司在欧洲都面临越来越大的政治压力，尤其是在压制极端主义内容方面——包括英国和德国在内的政界人士指责YouTube等平台托管仇恨言论和极端主义内容。</p>
<p class="translated">近年来，欧洲遭受了一连串的恐怖袭击，自三月份以来，仅在英国就发生了四起。T4、英国和法国的政府目前正在考虑是否对未能及时删除恐怖内容的技术平台引入新的责任——认为恐怖分子正在这些内容的帮助下变得激进。</p>
<p class="translated">本月早些时候，英国首相还呼吁盟国、民主政府之间达成国际协议，以“规范网络空间，防止极端主义和恐怖主义计划的蔓延”。</p>
<p class="translated">而在德国，一项包括对未能删除仇恨言论的社交媒体公司处以巨额罚款的提案已经获得了政府的支持。</p>
<p class="translated">除了罚款的威胁被纳入法律之外，今年早些时候，YouTube面临广告客户的反弹<a target="_blank" href="https://web.archive.org/web/20221202195139/https://beta.techcrunch.com/2017/03/21/after-youtube-boycott-google-pulls-ads-from-more-types-of-offensive-content/" rel="noopener">后，谷歌还有一个额外的商业激励</a>与极端主义内容一起显示的广告有关，几家公司从平台上撤下了他们的广告。</p>
<p class="translated">谷歌随后<a target="_blank" href="https://web.archive.org/web/20221202195139/https://beta.techcrunch.com/2017/06/01/youtube-bans-hateful-videos-from-making-money-via-its-advertising-network/" rel="noopener">更新了该平台的指导方针</a>以停止向有争议的内容提供广告，包括包含“仇恨内容”和“煽动性和贬低性内容”的视频，因此它们的制造商不能再通过谷歌的广告网络将内容货币化。尽管公司仍需要能够识别此类内容，此措施才能成功。</p>
<p class="translated">谷歌没有像脸书上周所做的那样，征求打击极端主义内容传播的想法，而是简单地陈述了它的行动计划——<a target="_blank" href="https://web.archive.org/web/20221202195139/https://blog.google/topics/google-europe/four-steps-were-taking-today-fight-online-terror/" rel="noopener">详细说明了它表示将采取的</a>四个额外步骤，并承认需要采取更多行动来限制暴力极端主义的传播。</p>
<p class="translated">“虽然我们和其他人多年来一直在努力识别和删除违反我们政策的内容，但令人不安的事实是，作为一个行业，我们必须承认还需要做更多的工作。现在，”谷歌总法律顾问肯特·沃克在一篇博客文章中写道。</p>
<p class="translated">沃克列出的四个附加步骤是:</p>
<ol>
<li class="translated"><strong>越来越多地使用机器学习技术</strong>，试图自动识别“极端分子和恐怖主义相关的视频”——尽管该公司警告说这“可能具有挑战性”，例如，指出新闻网络也可以播放恐怖袭击视频。“过去6个月，我们利用视频分析模型，发现并评估了50%以上与恐怖主义相关的内容。沃克写道:“我们现在将投入更多的工程资源，应用我们最先进的机器学习研究来训练新的‘内容分类器’，以帮助我们更快地识别和删除极端主义和恐怖主义相关内容。”</li>
<li class="translated"><strong>更多独立的(人类)专家</strong>在<a target="_blank" href="https://web.archive.org/web/20221202195139/https://support.google.com/youtube/answer/7124236?visit_id=1-636334719875527339-2442308706&amp;rd=1" rel="noopener"> YouTube的可信标记者</a>项目中——也就是YouTube社区中对标记问题内容有很高准确率的人。谷歌表示，它将在已经参与标记内容的63个组织的现有名单上增加50个“专家非政府组织”，涉及仇恨言论、自残和恐怖主义等领域，并将提供“运营拨款”支持它们。它还将与更多的反极端主义团体合作，努力识别可能被用于激进化和招募极端分子的内容。<br/>“机器可以帮助识别有问题的视频，但人类专家仍然在关于暴力宣传和宗教或有新闻价值的言论之间的细微决定中发挥作用。虽然许多用户标记可能不准确，但可信的标记报告在90%以上的情况下都是准确的，并帮助我们扩大工作范围，确定新出现的问题领域，”Walker写道。</li>
<li class="translated">对有争议的视频采取更强硬的立场，这些视频明显违反了YouTube的社区准则——包括在包含煽动性宗教或种族优越内容的视频中添加间隙警告。谷歌指出，这些视频也“不会被货币化，不会被推荐，也没有资格获得评论或用户认可”——这意味着它们的参与度会更低，也更难找到。沃克写道:“我们认为这在自由表达和获取信息之间取得了恰当的平衡，同时没有宣扬极端冒犯性的观点。”。</li>
<li class="translated"><strong>通过与(其他字母部门)Jigsaw合作，在欧洲更广泛地实施“重定向方法”,扩大反激进化努力</strong>。“这种有希望的方法利用定向在线广告的力量来接触潜在的Isis新兵，并将他们重定向到可以改变他们加入想法的反恐视频。沃克说:“在以前部署这一系统时，潜在的被招募者以异常高的比率点击广告，观看了50多万分钟揭露恐怖分子招募信息的视频内容。</li>
</ol>
<p class="translated">尽管对极端主义的政治压力越来越大，随之而来的是糟糕的公关(更不用说高额罚款的威胁)，谷歌显然希望通过继续在其平台上发布有争议的仇恨言论来保持其作为言论自由支持者的火炬姿态，只是这意味着它不会被直接指控为暴力个人提供收入来源。(当然，前提是它能够正确识别所有的问题内容。)</p>
<p class="translated">这一妥协是否会让“消除仇恨言论”与“保留言论自由”辩论中的任何一方满意，仍有待观察。风险在于，这两种人群都不会满意。</p>
<p class="translated">这种方法的成功与否还将取决于谷歌能够多快、多准确地识别出被视为问题的内容——在这样的规模上监管用户生成的内容是一个非常困难的问题。</p>
<p class="translated">目前还不清楚谷歌到底雇佣了多少名内容审查员——我们已经问过了，并将根据任何回复更新这篇文章。</p>
<p class="translated">脸书最近<a target="_blank" href="https://web.archive.org/web/20221202195139/https://beta.techcrunch.com/2017/05/03/facebook-to-hire-3000-to-review-posts-with-hate-speech-crimes-and-other-harming-posts/" rel="noopener">增加了3000名员工</a>，使审查人员总数达到7500人。首席执行官马克·扎克伯格也希望将人工智能应用于内容识别问题，但<a target="_blank" href="https://web.archive.org/web/20221202195139/https://beta.techcrunch.com/2017/02/16/building-the-world-we-all-want/" rel="noopener">此前曾表示</a>在“许多年内”不太可能成功做到这一点。</p>
<p class="translated">在谈到谷歌已经采取了哪些措施来应对极端主义内容时，即在采取这些额外措施之前，沃克写道:“我们在世界各地有成千上万的人来审查和反击对我们平台的滥用。我们的工程师已经开发出技术，利用图像匹配技术来防止已知恐怖分子内容的重新上传。我们投资了使用基于内容的信号来帮助识别要删除的新视频的系统。我们还与专家小组、反极端主义机构和其他技术公司建立了合作伙伴关系，以帮助宣传和加强我们的努力。”</p>
			</div>

			</div>    
</body>
</html>