<html>
<head>
<title>Social media handed “one-hour rule” for terrorist takedowns in Europe – TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">社交媒体为欧洲的恐怖分子提供了“一小时规则”——TechCrunch</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2018/03/02/social-media-handed-one-hour-rule-for-terrorist-takedowns-in-europe/">https://web.archive.org/web/https://techcrunch.com/2018/03/02/social-media-handed-one-hour-rule-for-terrorist-takedowns-in-europe/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">欧盟委员会(European Commission)仍在考虑是否监管社交媒体平台，以确保它们及时删除非法内容——无论是恐怖主义宣传、儿童性剥削还是仇恨言论，也包括商业诈骗甚至侵犯版权。</p>
<p class="translated">昨日它透露了试图统治社交分享平台的下一步措施，同时对科技公司施加了巨大压力，要求它们通过制定所谓的“一小时规则”来删除恐怖内容，该规则要求公司在报告后一小时内删除此类非法内容(或至少“作为一般规则”)。</p>
<p class="translated">它表示，这一时间框架是必要的，因为这种类型的内容构成了“对欧洲安全的特别严重的风险”，因此其传播“必须被视为最紧急的事情”。</p>
<p class="translated">尽管欧盟委员会非正式地使用了“规则”一词，但这(还)不是一项新法律。</p>
<p class="translated">相反，这是在给公司施加压力，让他们遵守一个非正式的——批评者称之为“武断的”——的建议，否则将面临起草实际立法来管理社交媒体的风险，并可能附带处罚(正如<a href="https://web.archive.org/web/20220823105638/https://techcrunch.com/2017/10/02/germanys-social-media-hate-speech-law-is-now-in-effect/">已经在德国</a>发生的那样)。</p>
<p class="translated">委员会将恐怖主义内容定义为“根据欧盟<a href="https://web.archive.org/web/20220823105638/http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32017L0541">反恐指令</a>或国家法律构成恐怖主义罪行的任何材料——包括由欧盟或联合国所列恐怖组织制作或可归因于这些组织的材料”。</p>
<p class="translated">因此，除了ISIS的宣传，它还将包括被禁的英国极右翼仇恨组织“国家行动”(National Action)制作的内容。</p>
<p class="translated">去年秋天，英国政府向科技巨头施压，要求他们大幅缩短从平台上删除极端内容的时间——称希望平均时间从36小时缩短至两小时。因此，它可能为欧盟执行机构更严格的取缔措施——一小时规则——提供了灵感。</p>
<p class="translated">尽管它给予公司和欧盟成员国三个月的宽限期，在此之前，他们需要提交有关恐怖分子内容的相关信息，以便委员会能够监督他们的表现。</p>
<p class="translated">数字单一市场副总裁Andrus Ansip在一份声明中评论说:<em> " </em>在线平台正在成为人们获取信息的主要途径，因此他们有责任为他们的用户提供一个安全的环境。线下违法的，线上也违法。</p>
<p class="translated">“虽然几个平台删除的非法内容比以往任何时候都多，这表明自律可以发挥作用，但我们仍然需要对恐怖宣传和其他非法内容做出更快的反应，这些内容严重威胁着我们公民的安全和基本权利。"</p>
<p class="translated"><a href="https://web.archive.org/web/20220823105638/https://techcrunch.com/2018/02/13/uk-outs-extremism-blocking-tool-and-could-force-tech-firms-to-use-it/">上个月</a>英国政府还透露，它已向一家人工智能公司支付开发一款机器学习工具，据称该工具可以“以极高的准确度”自动检测伊斯兰极端仇恨组织ISIS制作的在线宣传。</p>
<p class="translated">该公司表示，该工具可以集成到平台中，在此类内容上传到互联网之前将其屏蔽。英国内政大臣Amber Rudd表示，她不排除强迫科技公司使用该工具。</p>
<p class="translated">欧盟委员会还在推动各平台实施它所称的“主动措施”，包括“自动检测”，用它的话说，“有效而迅速地删除或禁用恐怖内容，并在删除后阻止其再次出现”。</p>
<p class="translated">它还效仿英国政府的做法，表示也希望社交媒体巨头与较小的平台分享学习和技术，并表示希望科技公司“制定工作安排，以更好地与包括欧洲刑警组织在内的相关当局合作”。</p>
<p class="translated">“快速通道程序应该到位，以尽快处理转介，而成员国需要确保他们有必要的能力和资源来检测，识别和转介恐怖主义内容，”它补充说。</p>
<p class="translated">欧盟成员国被指示定期向欧盟委员会报告科技公司在恐怖主义内容推荐方面的表现，以及“整体合作”。</p>
<p class="translated">该委员会还表示，将在未来几周内发起公众咨询。</p>
<p class="translated">虽然恐怖主义内容在这里是明确的优先事项，但欧盟委员会仍在继续向平台施加压力，以加强对所有“非法内容”的控制，正如它所定义的那样。</p>
<p class="translated">虽然它似乎已经接受了对将如此多不同类型的内容问题捆绑到一个“非法”包中的一些批评，以及所应用的措施不相称的相关风险，因为它的建议还指定了防止不公正和/或不适当的内容删除的保障措施，包括通过提高公民对平台内容决策的透明度。</p>
<p class="translated">“非法内容在网上的传播破坏了公民对互联网的信任，并造成安全威胁，”它写道，解释其合理性。“虽然在保护欧洲人上网方面取得了进展，但平台需要加倍努力，更快、更有效地从网上删除非法内容。欧盟委通过欧盟网上恐怖主义内容论坛、《打击网上非法仇恨言论行为守则》和《销售假冒商品谅解备忘录》鼓励的行业自愿措施取得了成果。然而，采取更有效行动的空间很大，特别是在最紧迫的恐怖主义内容问题上，这带来了严重的安全风险。”</p>
<p class="translated">在科技公司通常被要求采取的措施中，包括围绕非法内容的更明确的“通知和行动”程序，同时，为了避免无意中删除非非法内容的风险，欧盟委员会表示，“内容提供商应该被告知此类决定，并有机会提出异议”。</p>
<p class="translated">虽然它明确表示希望公司拥有“主动工具”来检测和删除非法内容，但它表示，这种方法应该“特别适用于恐怖主义内容和不需要语境化就被视为非法的内容，如儿童性虐待材料或假冒商品”。</p>
<p class="translated">欧盟委员会还补充称，措施“可能因非法内容的性质而异”，并表示其建议“鼓励公司在删除非法内容时遵循比例原则”。</p>
<p class="translated">关于避免自动化工具(尤其是)删除不应该删除的内容的风险的保障措施，报告进一步表示，公司应该“在充分尊重基本权利、言论自由和数据保护规则的情况下，制定有效和适当的保障措施，包括人工监督和验证”。</p>
<p class="translated">因此，这归结为科技公司需要雇用更多的人类主持人，对人工智能驱动的自动化系统进行健全检查，这些系统永远不会在混乱的内容领域做出完美的决策。</p>
<p class="translated">尽管科技公司在这方面有着糟糕的记录，去年脸书和T2谷歌都承诺增加人类版主和内容安全人员，试图在一系列<a href="https://web.archive.org/web/20220823105638/https://techcrunch.com/2017/12/19/youtube-more-ai-can-fix-ai-generated-bubbles-of-hate/">内容审核丑闻</a>后面对公众压力提高他们的整体表现。</p>
<p class="translated">欧盟委员会在这里的目的也是加强科技公司、受信任的旗手(也称为帮助平台识别问题内容的第三方专业组织)和执法机构之间的合作。</p>
<p class="translated">它给公司和成员国整整六个月的时间来提交(非恐怖)非法内容的相关信息，以便监督其建议的效果。</p>
<p class="translated">因此，至少在一年内，宣布任何EU-范围的立法来普遍统治社交媒体内容的威胁似乎不太可能。</p>
<p class="translated">不过，如果欧盟委员会认为确实需要采取行动，针对恐怖主义的措施可能会更快宣布，因为各平台做得还不够。</p>
<p class="translated">欧洲贸易协会EdiMA ，其成员包括脸书、谷歌和推特，<a href="https://web.archive.org/web/20220823105638/http://edima-eu.org/news/edimas-reaction-ec-recommendation-tackling-illegal-content-online/">对委员会的建议表示失望和沮丧，称其为“错过了一个循证决策的机会”，并声称“在这种情况下，一个小时的周转时间可能会损害服务提供商记录系统的有效性，而不是帮助”。</a></p>
<p class="translated">这是它的完整声明:</p>
<blockquote><p class="translated">EDiMA对欧盟委员会决定在今天发布关于处理在线非法内容的建议之前不与利益攸关方进行重要对话和事实调查讨论感到失望，并对错过宝贵的循证决策机会感到遗憾。</p>
<p class="translated">EDiMA承认这些问题的重要性，但认为有必要强调一个事实，即该行业一直在迎接挑战。在线和离线打击恐怖主义的总体成功取决于伙伴关系和协作，我们的部门通过全球互联网反恐论坛在这方面发挥了领导作用，并希望强调正在通过哈希共享数据库开展宝贵的协作。我们的行业接受这种紧迫性，但需要在保护用户的责任和维护基本权利之间取得平衡——在这种情况下，一个小时的周转时间可能会损害服务提供商关闭系统的有效性，而不是有所帮助。</p>
<p class="translated">虽然欧盟一级关于通知和行动程序的协调方法将受到欢迎，但EDiMA看不到欧盟委员会在没有适当考虑内容类型的情况下发表的武断建议；该义务的背景和对其他监管问题的影响；此外，由不同类型的服务提供商应用这种广泛建议的可行性可以被视为向前迈出的积极一步。</p>
<p class="translated">EDiMA将在未来几个月继续与利益主体群体进行接触，以寻求一种务实可行的方法来解决在线非法内容。</p></blockquote>
<p class="translated">一位脸书发言人也告诉我们:“我们与欧盟委员会的目标一致，即打击一切形式的非法内容。在脸书没有煽动暴力或恐怖主义的仇恨言论或内容的容身之地。</p>
<p class="translated">「最新数字显示，我们在清除各种形式的非法内容方面已取得良好进展。我们继续努力消除仇恨言论和恐怖主义内容，同时确保脸书仍然是所有思想的平台。”</p>
			</div>

			</div>    
</body>
</html>