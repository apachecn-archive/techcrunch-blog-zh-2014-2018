# 基于人工智能的智能手机的光明与黑暗

> 原文：<https://web.archive.org/web/https://techcrunch.com/2018/01/06/the-light-and-dark-of-ai-powered-smartphones/>

分析师高德纳(Gartner)本周发布了一份 10 人名单，确定了智能手机人工智能功能的“高影响力”用途，并表示这将使设备供应商通过“更先进”的用户体验为客户提供“更多价值”。

它还预测，到 2022 年，全部 80%的智能手机将具备设备上的人工智能功能，高于 2017 年的 10%。

在它看来，更多的设备上人工智能可以带来更好的数据保护和更好的电池性能——这是数据在本地处理和存储的结果。至少这是顶级外卖。

它的全部明显诱人的人工智能使用列表如下所示(逐字)。

但是，为了围绕自动化驱动的 UXes 呈现一个更加平衡的叙述，我们在每一个列出的项目后都加入了一些替代性的想法，这些想法考虑了智能手机用户利用这些被吹捧的“人工智能”所需要的价值交换的性质，因此也考虑了一些潜在的缺点。

## **设备上人工智能的使用和滥用**

> **1)** **坐在设备上的“数字我”**
> 
> “智能手机将是用户的延伸，能够识别他们并预测他们的下一步行动。他们会理解你是谁，你想要什么，你什么时候想要，你想怎么做，并根据你的权力执行任务。”
> 
> 高德纳(Gartner)首席研究分析师王安琪(Angie Wang)表示:“你的智能手机会全天跟踪你，为你学习、计划和解决问题。”。“它将利用自己的传感器、摄像机和数据自动完成这些任务。例如，在联网家庭中，它可以在房子空着的时候命令一个真空机器人来清洁，或者在你到达之前 20 分钟打开电饭煲。”

**您好，跟踪即服务。这个“数字我”会不会也甜蜜地低语说它是我的“头号粉丝”，因为它会无所不在地监视我的一举一动，以塑造一个数字身体——将我的自由意志困在它的算法黑箱里的替身……**

***还是因为，你知道，我是一个人，不是一个数字回形针(不，我他妈的没有写信)，所以在试图准确预测任何特定时刻我想要什么的时候，它真的会变得非常糟糕。***

***哦，当人工智能的选择不仅不符合我的喜好而且糟糕得多时，谁该受责备呢？说*当孩子们不在学校的时候，人工智能派机器人吸尘器去他们的蚂蚁农场…人工智能也会向他们解释他们的宠物死亡的原因吗？或者 w**** ****帽子如果它打开了我的空电饭煲(在我忘记加满电之后)——充其量是毫无意义的消耗能量，最坏的情况是热情地烧毁房子。****

 *很长一段时间以来，我们一直被告知人工智能助手将很快变得非常擅长了解和帮助我们。但是，除非你想做一些简单事情，比如播放一些音乐，或者一些狭隘的事情，比如找一首新的类似的音乐来听，或者一些基本的事情，比如从网上订购一个主食，他们仍然是[比学者更白痴](https://web.archive.org/web/20221209102957/https://twitter.com/chris_beaumont/status/943286460853161984)。

> **2)**用户认证
> 
> “基于密码的简单身份认证正变得过于复杂和低效，导致安全性差、用户体验差和拥有成本高。结合机器学习、生物识别和用户行为的安全技术将提高可用性和自助服务能力。例如，智能手机可以捕捉和学习用户的行为，如他们走路、滑动、对手机施压、滚动和打字时的模式，而无需密码或主动认证。”

***更多盯梢即服务。没有完全的隐私放弃就没有安全，嗯？但是，如果我感到恐慌，表现得不像我“正常”时那样，我会被锁在自己的设备之外吗——比如说，因为人工智能在我不在的时候打开了电饭煲，而我回到家发现厨房着火了。我会不会因为我的设备碰巧被我拿在手中而无法阻止它被解锁——即使我可能希望它在任何特定的时刻保持锁定，因为设备是个人的，情况并不总是可以预测的。***

***如果我想与家人共享对移动设备的访问权限，该怎么办？他们是否也必须在无所不在的数码眼睛前脱光衣服才能获准进入？或者这种人工智能增强的多层生物识别系统最终会使亲人之间更难共享设备吗？正如苹果在 iPhone X 上从指纹生物识别(允许注册多个指纹)转向[面部生物识别认证系统](https://web.archive.org/web/20221209102957/https://beta.techcrunch.com/2017/09/13/iphone-xs-face-id-raises-security-and-privacy-questions/)的情况一样(不支持注册多个面部)？*** ***难道我们就应该把设备通用性的逐渐告别记为“进步的代价”的又一个等级吗？***

> **3)**情感识别
> 
> “情绪传感系统和情感计算允许智能手机检测、分析、处理和响应人们的情绪状态和心情。虚拟个人助理和其他基于人工智能的对话系统技术的激增，推动了为更好的环境和增强的服务体验添加情绪智能的需求。例如，汽车制造商可以使用智能手机的前置摄像头来了解司机的身体状况或评估疲劳程度，以提高安全性。

如果不考虑如果广告商获得了这种高度敏感的情绪数据，他们会做些什么，就不可能对情绪传感系统进行诚实的讨论。在这个话题上，脸书为我们提供了潜在风险的清晰指引——去年[泄露的内部文件](https://web.archive.org/web/20221209102957/https://www.theguardian.com/technology/2017/may/01/facebook-advertising-data-insecure-teens)表明，这家社交媒体巨头正在吹嘘其处理使用数据的能力，以识别青少年的不安全感，作为其广告销售的卖点。因此，尽管感知情感背景可能暗示了智能手机用户可能欢迎和喜欢的一些实用功能，但它也可能具有很高的可利用性，并且很容易让人感觉具有可怕的侵犯性——比如说，为青少年的智能手机打开了大门，因为他们知道准确地在他们情绪低落的时候给他们打广告。

如果设备上的人工智能确实意味着本地处理的情绪传感系统能够保证它们永远不会泄露情绪数据，那么人们的担忧可能会减少。但是，通过将情绪跟踪烘焙到智能手机用户界面来使其正常化，肯定会推动其他地方更广泛地推动类似的“增强”服务——然后这将取决于个人应用程序开发人员(以及他们对隐私和安全的态度)来决定如何使用你的情绪。

至于汽车，我们不是也被告知人工智能将不再需要人类司机吗？为什么我们需要人工智能看门狗来监视我们在车内的情绪状态(在那种情况下，车真的只是小睡和娱乐舱，很像飞机)。一个主要的以消费者为中心的情感传感系统的安全争论似乎没有说服力。 ***然而，政府机构和企业肯定会因为各种原因而喜欢获得我们的情绪数据……***

> **4)**自然语言理解
> 
> “智能手机上的持续训练和深度学习将提高语音识别的准确性，同时更好地理解用户的具体意图。例如，当用户说“天气冷”时，根据上下文，他或她的真实意图可能是“请在线订购一件夹克”或“请打开暖气”。“例如，在国外旅行时，自然语言理解可以用作智能手机上的近实时语音翻译。”

虽然我们肯定仍然会梦想拥有自己的巴别鱼——即使这个概念暗指的圣经寓言中有对人类傲慢的警告——但我 ***t 将是一个非常令人印象深刻的人工智能助手，它可以在主人不经意地说“天气冷了”后自动选择完美的夹克给它的主人买。***

我的意思是，没有人会介意一件惊喜的外套。但是，很明显，人工智能与你的信用卡有着不可分割的深度联系，这意味着你将不得不购买并穿着那件亮红色的哥伦比亚羽绒服，该羽绒服是在你观察气候后的几个小时内(通过亚马逊 Prime)到达的，人工智能已经通过算法确定它足以抵御一些“寒冷”，同时还对你以前购买的外套进行了数据挖掘，以减少其款式选择。哦，你 s ***到现在都不喜欢它的样子？太糟糕了。***

向完美的人工智能个人助理的消费者推出的营销“梦想”涉及到对该技术将提供多少实际效用的大量怀疑——即除非你是那种希望每年重新订购同一品牌夹克的人，并且发现手动在网上寻找一件新外套并自己点击“购买”按钮非常不方便。 ***或者谁会觉得直接要求一个联网的机器人助手“请打开暖气”与让一个机器人助手 24/7 监视你以便它可以在无意中听到你谈论寒冷天气时自动应用计算好的代理选择打开暖气之间有着令人振奋的区别——即使你实际上只是在谈论天气，而不是偷偷要求房子变得神奇地温暖。也许当你的人工智能在附近时(即，在任何地方，任何时候)，你必须开始对你大声说的事情更加小心。***

***人类相互理解已经够麻烦了；期望我们的机器在这方面比我们自己做得更好似乎是异想天开——至少除非你认为这些受数据限制的不完美系统的制造商希望通过重组和减少我们的行为选择，以使我们的生活更可预测(从而更容易系统化)，在社交上重新设计他们设备的不稳定生物用户，从而修补人工智能的限制和理解缺陷。称之为人工智能增强的生活更普通，更少活。***

> **5)** **增强现实(AR)和 AI 视觉**
> 
> “随着 iOS 11 的发布，苹果公司加入了 ARKit 功能，为开发者提供了新的工具，使向应用程序添加 AR 变得更容易。同样，谷歌宣布了其用于 Android 的 ARCore AR 开发者工具，并计划到明年年底在大约 1 亿台 Android 设备上启用 AR。谷歌预计，明年几乎所有新的安卓手机都将开箱即用。AR 如何使用的一个例子是在帮助收集用户数据和检测皮肤癌或胰腺癌等疾病的应用程序中。”

虽然大多数 AR 应用不可避免地会比这里引用的癌症检测例子更加轻浮，但没有人会否认“可能会抵御严重疾病”这张牌。尽管如此，一个为医疗诊断目的收集个人数据的系统加剧了智能手机供应商将如何安全存储、管理和保护敏感健康数据的问题。苹果在健康数据方面一直很积极[——但是，与谷歌不同，它的商业模式并不依赖于对用户进行描述来销售有针对性的广告，因此存在各种竞争的商业利益。](https://web.archive.org/web/20221209102957/https://beta.techcrunch.com/2015/09/29/apple-blows-up-the-concept-of-a-privacy-policy/)

**与此同时，强大的人工智能应用可以突然诊断出非常严重的疾病，这也引发了更广泛的问题，即一个应用如何负责任地、敏感地通知一个它认为自己有重大健康问题的人当顾问是机器人时,“不伤害”开始看起来复杂得多。**

> **6)设备管理**
> 
> “机器学习将提高设备性能和待机时间。例如，通过许多传感器，智能手机可以更好地理解和学习用户的行为，例如何时使用哪个应用程序。智能手机将能够让经常使用的应用程序在后台运行，以便快速重启，或者关闭不用的应用程序，以节省内存和电池。”

另一个人工智能承诺是基于无处不在的监控和减少的用户代理——如果我真的想让一个我通常直接关闭的应用程序保持打开，或者反之亦然；人工智能的模板不会总是完美地预测动态使用。 ***在[之后，苹果受到了批评](https://web.archive.org/web/20221209102957/https://beta.techcrunch.com/2017/12/28/apple-apologizes-for-not-being-clearer-about-slowing-down-iphones-with-older-batteries/)最近有消息称，iOS 将降低老款 iPhones 的性能，作为一种试图利用旧电池提高性能的技术，这应该是一个警告信号，消费者可能会以意想不到的方式对制造实体对其设备的失控做出反应。***

> **7)个人档案**
> 
> “智能手机能够收集行为和个人资料。用户可以动态地获得保护和帮助，这取决于正在进行的活动和他们所处的环境(例如，家庭、车辆、办公室或休闲活动)。保险公司等服务提供商现在可以专注于用户，而不是资产。例如，他们将能够根据驾驶行为调整汽车保险费率。”

***基于普遍行为分析的保险费——在这种情况下，由智能手机传感器数据(位置、速度、移动等)提供支持——当然也可以以最终惩罚设备所有者的方式进行调整。比方说，如果一个人的手机显示他们经常紧急刹车。或者经常在某些区域超速行驶。再说一次，人工智能不是应该取代方向盘后面的司机吗？自动驾驶汽车会要求它的骑手有驾驶保险吗？或者说，传统汽车保险的保费不是已经接近于零了吗——那么，消费者到底能从无处不在的个人信息中获得什么好处呢？***

与此同时，歧视性定价是特征分析的另一个明显风险。 ***智能手机还可以用于其他什么目的来对其主人进行行为分析？花在敲办公室电脑键盘上的时间？在电视机前消磨几个小时？作为永远在线的人工智能的结果，量化几乎每一件日常事物可能成为可能——并且考虑到智能手机的无处不在(也称为“不可穿戴的可穿戴设备”)——但这实际上是可取的吗？难道它不会让“用户”(即人们)感到他们正在被仔细地、持续地仅仅因为他们的生活方式而被评判，从而引发不适、压力和消极情绪吗？***

***当你看到[中国计划](https://web.archive.org/web/20221209102957/https://www.newscientist.com/article/dn28314-inside-chinas-plan-to-give-every-citizen-a-character-score/)给每个公民一个“性格分数”——并考虑由我们口袋里的传感器包装设备供电的国家级控制基础设施可能产生的各种有意(和无意)后果时，围绕普遍侧写的风险似乎更加疯狂地反乌托邦。***

> **8)** **内容审查/检测**
> 
> “可以自动检测受限制的内容。可以标记不良图像、视频或文本，并启用各种通知警报。计算机识别软件可以检测任何违反法律或政策的内容。例如，在高度安全的设施中拍照或在公司支付的智能手机上存储高度机密的数据都会通知它。”

举报用户违反公司 IT 政策的个人智能手机听起来就像是科幻反乌托邦小说中的情节。人工智能驱动的内容审查也是如此。人工智能未能正确识别或完全错误分类的例子不胜枚举， 图片——包括被[故意掺假的图片](https://web.archive.org/web/20221209102957/https://beta.techcrunch.com/2018/01/02/these-psychedelic-stickers-blow-ai-minds/)愚弄——以及长期以来科技公司滥用自己的政策从视图中消失(或以其他方式)某些片段和类别的内容(包括[真正标志性的](https://web.archive.org/web/20221209102957/https://beta.techcrunch.com/2016/09/12/facebook-employees-say-deleting-napalm-girl-photo-was-a-mistake/)和[真正自然的](https://web.archive.org/web/20221209102957/https://www.snopes.com/facebook-lifts-nipple-ban/)东西)——因此，自由地将我们自己的设备在用户界面层面上能看到和不能看到(或做什么)的控制权交给一个最终由商业实体控制的机器机构，至少可以说是不明智的。 这也将代表用户和连接设备之间的力量动态的巨大转变。

> **9)个人摄影**
> 
> “个人摄影包括能够根据用户的个人审美偏好自动生成美化照片的智能手机。例如，东方和西方有不同的审美偏好——大多数中国人喜欢苍白的肤色，而西方消费者倾向于喜欢古铜色的肤色。”

谈到种族攻击性的“美化”滤镜，人工智能已经有了一段不完整的历史。因此，任何自动调整肤色的方式似乎都同样是不明智的。 ***缩小来看，这种主观自动化也是可怕的还原——通过侵蚀用户的代理来发现替代的视角和美学，从而将用户更牢固地固定在人工智能生成的过滤器泡沫中。如果人类的眼睛在算法上被无意地渲染成色盲，那么“情人眼里出西施”会发生什么？***

> **10)**音频解析
> 
> “智能手机的麦克风能够持续聆听真实世界的声音。设备上的人工智能功能能够辨别这些声音，并指示用户或触发事件。例如，智能手机听到用户打鼾，然后触发用户的腕带，鼓励改变睡眠姿势。”

持续监听你的卧室、浴室、客厅、厨房、汽车、工作场所、车库、酒店房间等地方的声音的智能手机麦克风还能辨别和推断你和你的生活吗？你真的想让一个外部商业机构来决定如何最好地将你的存在系统化到如此亲密的程度，以至于它有能力扰乱你的睡眠吗？ ***这里提出的“问题”(打鼾)和侵入性的“修复”(窃听加上产生电击的可穿戴设备)之间的差异非常坚定地强调了人工智能中缺乏“自动控制”。相反，我们目前能够构建的人工智能系统需要接近极权水平的数据和/或对数据的访问，而消费者的主张实际上只能提供狭隘、琐碎或附带的效用。***

这种差异并没有困扰大数据挖掘企业，这些企业已经将积累海量数据集作为自己的使命，以便在幕后推动业务关键的人工智能工作。例如，对于被要求睡在主动窃听卧室活动的个人设备旁边的智能手机用户来说，这个等式开始变得更加不平衡。即使你个人不介意，你周围的其他人的“真实世界的声音”也会被你的手机监听，不管他们喜不喜欢。你问过他们是否想要一个人工智能来量化他们发出的噪音吗？你会告诉你遇到的每个人你带了窃听器吗？*