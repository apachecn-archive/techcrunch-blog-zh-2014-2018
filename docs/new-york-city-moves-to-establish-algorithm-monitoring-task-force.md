# 纽约市着手建立算法监控工作组

> 原文：<https://web.archive.org/web/https://techcrunch.com/2017/12/12/new-york-city-moves-to-establish-algorithm-monitoring-task-force/>

# 纽约市着手建立算法监控工作组

纽约市可能很快就会有一个特别工作组，专门监督市政机构使用的算法的公平性。该委员会由自动化系统专家和受这些系统影响的群体代表组成，将负责密切检查该市正在使用的算法，并就如何改善问责制和避免偏见提出建议。

这个没有花哨名字的法案已经得到市议会的批准，并放在市长的办公桌上等待签署。美国公民自由联盟纽约分部[已经表示支持。](https://web.archive.org/web/20230403205645/https://www.aclu.org/blog/privacy-technology/surveillance-technologies/new-york-city-takes-algorithmic-discrimination)

比方说，一个“自动决定系统”(法律上这样称呼他们)在一定程度上决定了谁有资格获得保释。这可能是产生这个系统的训练数据固有的偏见，倾向于导致一个群体在保释听证会上不公正地优于另一个群体。

将要求工作队编写一份报告，列出处理上述情况的程序。具体而言，该报告将就以下方面提出建议:

*   人们如何知道他们或他们的环境是否被算法评估，以及他们应该如何被告知这个过程？
*   一个给定的系统是否对某些群体，如老年人、移民、残疾人、少数民族等产生了不成比例的影响？
*   如果是，代表受影响的群体应该做些什么？
*   一个给定的系统在技术细节和城市应用方面是如何运作的？
*   应该如何记录和归档这些系统及其培训数据？

该工作组需要在法案签署后的三个月内成立，重要的是，它必须包括“在与自动决策系统相关的公平性、问责制和透明度领域具有专业知识的人员，以及与代表受机构自动决策系统影响的城市中的人员的慈善公司有关联的人员。”

所以这不仅仅是一群机器学习专家和几个律师。你还需要社会工作者和人权倡导者，这也是我过去一直主张的。

这份报告本身(它将是公开的)在 18 个月后才到期，但这不是你想仓促完成的事情。评估这些系统是一项数据密集型任务，创建平行的市政系统以确保人们不会被遗漏，这在民事方面非常重要。