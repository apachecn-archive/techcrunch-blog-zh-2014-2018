# 脸书用技术解决复仇色情问题，防止人们重新分享亲密图像

> 原文：<https://web.archive.org/web/https://techcrunch.com/2017/04/05/facebook-addresses-revenge-porn-with-tech-to-prevent-people-from-re-sharing-intimate-images/?_ga=2.2252407.696106435.1552311000-65650910.1541640065>

# 脸书用技术解决复仇色情问题，防止人们重新分享亲密图像

脸书实施了一种新的照片匹配技术，以确保人们不能再分享以前被报道和标记为复仇色情的图像——未经他们同意分享的亲密照片。这意味着如果有人试图分享脸书之前拍摄的照片，这个人会看到一个弹出窗口，说这张照片违反了脸书的政策，脸书不会允许这个人在脸书、Messenger 或 Instagram 上分享这张照片。

“我们之所以关注这个问题，是因为这种分享对受害者造成了独特的伤害，”脸书全球安全主管 Antigone Davis 告诉我。“在新闻编辑室的帖子中，我们提到了一项关于这种行为对受害者造成的独特伤害的具体研究。我认为这是我们前进的重点。”

戴维斯提到的数字是，根据美国非自愿亲密图像受害者的说法，93%受非自愿亲密图像共享影响的人报告说“严重的情绪困扰”，82%的人报告说他们生活的其他方面存在严重困难。

戴维斯说，尽管脸书使人们能够报告图像已经有一段时间了，但围绕复仇色情的语言现在更加清晰，“非常具体地针对这些类型的亲密图像”。在“很多”情况下，脸书也会关闭发布复仇色情的人的账户。

脸书还与一些组织合作，如[网络公民权利倡议](https://web.archive.org/web/20230130101824/https://www.cybercivilrights.org/)和[复仇色情热线](https://web.archive.org/web/20230130101824/https://revengepornhelpline.org.uk/)，为复仇色情的受害者提供支持。

报复色情是互联网上一个普遍存在的问题，根据数据&社会研究所和创新公共健康研究中心 2016 年的一份报告，[每 25 个人中就有一个是未经同意的图片分享的受害者。在脸书和 Instagram 上发生针对私人团体中女性海军陆战队队员的丑闻后不久，脸书推出了应对报复色情的新工具。](https://web.archive.org/web/20230130101824/https://datasociety.net/pubs/oh/Nonconsensual_Image_Sharing_2016.pdf)

去年，[脸书应用机器学习工程总监华金·坎德拉告诉 TechCrunch](https://web.archive.org/web/20230130101824/https://techcrunch.com/2016/05/31/terminating-abuse/) 该平台正在使用人工智能来检测和报告攻击性照片，但似乎在复仇色情的情况下，仍然需要人类。

“目前，我们没有使用人工智能来浏览这个特定的内容，”戴维斯说。“审查非自愿分享需要有重要的背景。”