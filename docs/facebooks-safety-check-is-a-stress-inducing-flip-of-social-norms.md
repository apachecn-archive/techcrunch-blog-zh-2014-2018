# 脸书的安全检查是对社会规范的压力诱导翻转

> 原文：<https://web.archive.org/web/https://techcrunch.com/2017/06/14/facebooks-safety-check-is-a-stress-inducing-flip-of-social-norms/>

继伦敦西部一座 24 层公寓楼被大火吞噬的消息后，脸书的安全检查功能于今天启动。据报道，至少有六人在大火中丧生，警方预计死亡人数还会上升。格伦费尔大厦有 120 套公寓。

显然这是一场悲剧。但是，脸书应该通过发送推送警报来对悲剧做出反应吗——包括向距离发生问题的大楼数英里之外的用户？

这有帮助吗？或者，它是否有可能产生比表面上应该缓解的压力更大的压力…

【T2![](img/f8fe5df7d06320c144307ec97912ba59.png)

在一个拥有约 850 万人口的城市，距离着火的建筑 6 英里远不应该成为担忧的原因——但脸书正在积极鼓励用户担忧，使用情绪化的语言(“你的朋友”)来推动个人安全的公开声明。

如果有人不采取行动“标记自己是安全的”，正如脸书所说，他们可能会让他们的朋友认为他们在某种程度上——违背所有理性的可能性——陷入了这场悲剧事件。

在脸书功能出现之前，这些朋友可能根本不会想到会有任何风险。

这就是‘安全检查’的悖论性恐慌。

(脸书自己已经默认了一个悖论，甚至延伸到那些标记自己“安全”的人，然后，通过这样做，让他们的朋友担心他们仍然以某种方式被卷入事件中——然而，脸书没有撤回安全检查，而是现在正在紧缩；增加更多的功能，鼓励用户在他们的复选标记中加入“个人注释”,以说明他们实际上没有发生什么事情……是的，我们真的目睹了一些被宣传为提供被动保证的功能悄悄出现

底线是:伦敦是一个非常大的城市。塔楼失火是非常非常糟糕的消息。它也非常，非常不可能涉及任何不住在大楼里的人。然而，脸书的安全检查算法显然无法对相对风险做出任何接近理智的评估。

更复杂的是，该公司依赖其自身明显不可靠的地理定位技术来确定谁会得到安全检查提示，这导致它向居住在数百英里以外的用户发送垃圾邮件——在完全不同的城镇和城市(甚至显然在[不同的国家](https://web.archive.org/web/20230326175838/https://twitter.com/robmanuel/status/874951091351408640))——毫无意义地推动他们按下安全检查按钮。

正如一名脸书用户在推特上所说，这确实是“极其不负责任的”。

[![](img/6c6eb9224d08a835bf955f23f634a390.png)](https://web.archive.org/web/20230326175838/https://techcrunch.com/2017/06/14/facebooks-safety-check-is-a-stress-inducing-flip-of-social-norms/screen-shot-2017-06-14-at-4-02-50-pm/)

正如 Tausif Noor 在一篇出色的文章中所写的那样，通过“明确地、制度化地介入生死攸关的问题，脸书承担起了适当应对这些问题的新责任”，一个控制我们认为我们的朋友是否安全的平台会带来附带的社会损害。

而且，很明显，脸书没有很好地履行这些责任——尤其是在是否启动安全检查的问题上，没有根据具体情况做出基于证据的决定。

这项功能确实是由脸书手动开启的。但是脸书很快就放弃了这个决策角色([听起来很熟悉吧？](https://web.archive.org/web/20230326175838/https://techcrunch.com/2016/08/29/facebooks-trending-topics-algorithm-mistake/))——包括在面对西方对恐怖事件评估的偏见的批评之后。

自去年夏天以来，这项功能被称为“社区激活”。

那是什么意思？这意味着脸书依赖于以下激活安全检查的公式:首先，全球危机报告机构 NC4 和 iJET International 必须提醒它发生了事故，并给事故起一个标题(在这种情况下，大概是“伦敦的火灾”)；其次，在事件发生地附近的未指定区域，必须有未指定数量的关于该事件的脸书帖子。

目前还不清楚脸书用户必须离事故区域多近才能触发安全检查提示，也不清楚他们必须亲自发布多少与事故有关的帖子。我们已经要求脸书对其算法标准做出更多澄清——但是(到目前为止)没有得到任何回应。

NC4 和 iJET International 也拒绝提供他们如何与脸书合作开发该功能的具体细节，后者告诉我们:“这是专有信息。”

将安全检查激活放在这种保护性的半算法襁褓中意味着，当该功能被激活(或未被激活)时，该公司可以免受指责——因为它自己并没有逐案做出决定——但也(显然)回避了其技术导致广泛算法压力的责任。就像这里的例子一样，它在伦敦和其他地方都被激活了。

人们谈论脸书的悲剧似乎是一个非常嘈杂的信号，实际上是为了发送推送通知，敦促用户做出个人安全声明。

此外，正如我们从伦敦火灾相关提示的命中率可以看出的那样，脸书的地理定位智能远非完美。如果你的定位误差范围扩大到触发数百英里以外的其他城市的警报(更不用说其他国家了！你的技术显然不符合目的。

在一个大约 850 万人口的城市中，即使只有 6 英里也表明这里正在使用一种可笑的钝器。然而这也有情感上的影响。

更广泛的问题是，脸书是否应该通过制造一个有特色的“公共安全”预期来寻求控制用户行为。

完全不需要安全检查功能。人们仍然可以使用脸书发布状态更新，说他们很好，如果他们觉得有必要的话——或者实际上，使用脸书(或 WhatsApp 或电子邮件等)直接联系朋友，询问他们是否还好——如果他们觉得有必要的话再次*。*

 *> 通过将安全检查作为默认期望，脸书颠覆了社会行为规范，突然之间，除非每个人都手动勾选了标有“安全”的脸书框，否则没有人会感到安全。

但通过将安全检查作为默认期望，脸书颠覆了社会行为规范，突然之间，除非每个人都手动勾选了标有“安全”的脸书框，否则没有人会感到安全。

这太荒谬了。

脸书自己表示，安全检查在两年内被激活了 600 多次——在此期间，用户触发了超过 10 亿次“安全”通知。然而，这些通知中有多少是真正应得的？又有多少人消除了比他们造成的更多的忧虑？

很明显，算法触发的安全检查比手动版本更加歇斯底里。去年 11 月 [CNET](https://web.archive.org/web/20230326175838/https://www.cnet.com/news/facebook-safety-check-users-activate/) 报道称，脸书在过去两年中只开启了 39 次安全检查，而自 6 月开始测试以来，该工具的社区版本标记了 335 次事件。

问题是社交媒体被设计成一个公共论坛。新闻事件显然会在这些平台上掀起公共传播的浪潮。这些喋喋不休的声音不应该被误解为风险的证据。但这看起来确实是脸书的安全检查在做的事情。

虽然该公司开发这一功能的意图可能是最好的，毕竟这是 2011 年日本地震和海啸后有机网站的使用，但此时的结果看起来像是一触即发，鼓励人们对悲剧事件做出过度反应，而理智和理性的反应实际上恰恰相反:保持冷静，不要担心，除非你听到相反的消息。

又名:保持冷静，继续前进。

安全检查还迫使每个人，无论是否愿意，每次发生某种重大(或相对较小)的公共安全事件时，都要与单一的商业平台接触——否则会担心给朋友和家人带来不必要的担忧。

当你考虑到脸书的商业模式受益于其平台参与度的提高时，这一点尤其成问题。此外，它最近还进入了个人筹款领域。今天，机缘巧合，脸书宣布[安全检查将整合这些个人筹款](https://web.archive.org/web/20230326175838/https://techcrunch.com/2017/06/14/facebooks-safety-check-will-integrate-fundraisers-among-other-upgrades/)(从美国开始)。

一份针对脸书筹款人的[常见问题解答](https://web.archive.org/web/20230326175838/https://www.facebook.com/fundraisers)指出，该公司对个人捐款征收 6.9%+. 30 美元的费用，而对非营利捐款的收费从 5%到 5.75%不等。(该公司声称，这些费用用于支付信用卡处理费用，以及资助内部团队对筹资者进行欺诈审查。)

尚不清楚脸书是否会对那些与安全检查也被触发的事件相关的筹款人征收相同的费用结构——我们已经问过了，但在撰写本文时，该公司尚未回应。

如果是这样的话，脸书通过安全检查直接将其对用户的行为提示与创收功能联系起来，这将使其能够从筹集的资金中抽取一部分，以帮助相同悲剧的受害者。这使得其明显鼓励公众担忧的不负责任行为看起来更像是玩世不恭的机会主义。

在查看我自己的伦敦朋友时，脸书的安全检查告诉我，有三个人在塔楼火灾中是“安全的”。

然而，令人担忧的是，有 97 种被贴上了“还没有被标记为安全”的标签。

对此唯一理智的回应是:脸书安全检查，关闭你的账户。

*这篇文章更新了 iJET International 的评论，并增加了关于脸书募捐活动的更多细节**