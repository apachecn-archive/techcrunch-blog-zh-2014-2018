# DeepMind 表示，验证健康数据访问没有快速解决方案

> 原文：<https://web.archive.org/web/https://techcrunch.com/2017/03/09/deepmind-says-no-quick-fix-for-verifying-health-data-access/>

你为什么要相信一个掌握着你最敏感的个人数据(也就是你的医疗记录)的广告巨头呢？这是谷歌旗下的 DeepMind 在寻求嵌入英国医疗保健领域时面临的巨大棘手问题——这是去年 2 月公开宣布的一项重大举措。

DeepMind 现在正在通过一篇博客文章，在去年 11 月首次讨论的技术审计基础设施计划的基础上增加一点内容，从而在[更加详细地描述](https://web.archive.org/web/20230315204856/https://deepmind.com/blog/trust-confidence-verifiable-data-audit/)它希望如何在未来提高患者对商业访问和他们健康数据货币化的信任度——当时 DeepMind 还确认它正在为国家医疗服务系统(NHS)的患者病历建立访问基础设施。世界著名的人工智能公司听起来对能够建立一个可验证的健康数据审计系统信心不足——超越 [Alpha Go](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/03/17/google-defeating-go-champion-shows-ai-can-find-solutions-humans-dont-see/) ！DeepMind 要运用集体智慧应对新的挑战。

DeepMind 的 NHS 访问基础设施计划的最终目的是让该公司拥有一个标准接口，该接口可以推广到其他 NHS 信托，使 DeepMind 和第三方开发者能够更容易地将应用程序交付到英国的医疗保健系统中(例如，DeepMind 的定位是能够向其他应用程序制造商收取访问其正在构建的 access API 的费用)。

根据它自己的说法，它已经表示，在人工智能和健康交叉的地方，它未来的雄心是能够按结果收费。但与此同时，它需要病人数据来训练它的人工智能。正是对数据争夺让 DeepMind 在去年陷入了早期的困境。

自 2015 年以来，该公司与英国 NHS 信托基金会签署了多项协议，以获得用于各种目的的患者数据，其中一些用于人工智能研究，但[并非所有用于人工智能研究。DeepMind 迄今为止最广泛的 NHS 数据共享安排——与皇家免费 NHS 信托基金合作——为 NHS 算法建立一个应用包装器以识别急性肾损伤——引起了](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/11/21/deepmind-health-inks-new-deal-with-uks-nhs-to-deploy-streams-app-in-early-2017/)[的重大争议](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/05/04/concerns-raised-over-broad-scope-of-deepmind-nhs-health-data-sharing-deal/)，当时 FOI 的一项请求披露了该公司正在接收的可识别患者数据的范围。DeepMind 和该信托公司尚未公开详细说明有多少数据被共享。

在这种情况下，假设患者同意(意味着没有要求患者同意)，这是基于 NHS 医疗保健数据共享指南对所谓“直接患者护理”的解释，该解释受到了[数据保护专家](https://web.archive.org/web/20230315204856/https://www.ft.com/content/f6bcce6e-b099-11e6-9c37-5787335499a0)的[质疑](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/11/22/patient-data-api-pivotal-to-deepminds-push-into-uks-nhs/)和健康数据隐私倡导组织 [MedConfidential](https://web.archive.org/web/20230315204856/https://medconfidential.org/) 的批评。

最初的 DeepMind-Royal 免费数据共享协议(已经[被重新签署](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/11/21/deepmind-health-inks-new-deal-with-uks-nhs-to-deploy-streams-app-in-early-2017/))也仍在接受英国国家数据保护机构 ICO 的调查。在国家数据监护人的审查下，政府任命的任务是确保公民的健康数据得到保护和正确使用。

尽管正在进行调查，但与伦敦皇家免费 NHS 信托基金合作开发的应用程序 DeepMind 已经在后者的三家医院部署。因此，你可以说，人工智能公司在诉讼的这一点上考虑健康数据访问审计基础设施，类似于一个长途汽车司机谈论将一辆尚未建造的大车放在一匹已经被释放出来绕场奔跑的马上，同时要求那些被装上马鞍的人信任它。(另见:DeepMind 没有浪费时间[在获得皇家免费患者医疗记录的自由访问权后，Streams 应用程序创造了明显的好处](https://web.archive.org/web/20230315204856/http://www.wired.co.uk/article/deepmind-nhs-ai-kidney-royal-free)。)

这里最重要的问题是信任——信任患者的敏感医疗保健数据不会在没有适当授权和/或患者同意的情况下被共享。并且患者不会被蒙在鼓里，不知道谁被允许访问他们的个人信息以及出于什么目的。

DeepMind 对信任问题的回答——以及最初因其如何获取 NHS 患者数据而引发的争议——似乎主要是一个技术问题。尽管在已经获得数据访问权之后构建审计基础设施并不能满足法律或隐私专家的要求。这种颠倒的信任轨迹也不太可能打动病人。(尽管 DeepMind 也已经[开始与患者团体](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/09/20/deepmind-wants-its-healthcare-ai-to-charge-by-results-but-first-it-needs-your-data/)接触，即使只是在争议出现之后。)

在一篇名为“信任、信心和可验证的数据审计”的[博客文章](https://web.archive.org/web/20230315204856/https://deepmind.com/blog/trust-confidence-verifiable-data-audit/)中，DeepMind 描绘了一幅技术审计基础设施的画面，该基础设施使用“数学保证”和开源尊重来提供“可验证的”数据访问审计，它大概希望这将使信任问题安乐死。在更近的时间框架内，它的希望看起来是试图将审查从它目前如何利用患者数据的“信任我们”现实中踢出来(即没有可验证的技术基础设施来证明其说法，同时仍在接受英国数据保护机构的审查)。

谷歌旗下的人工智能公司写道:

> 想象一下这样一种服务，它可以对每一个人的个人数据提供数学保证，没有伪造或遗漏的可能性。想象一下实时检查该系统内部工作情况的能力，以确保数据只用于它应该使用的地方。想象一下，支持这一点的基础设施可以作为开源免费获得，因此世界上任何组织都可以实现他们自己的版本，如果他们愿意的话。

当然，那只是介绍性的[心情音乐](https://web.archive.org/web/20230315204856/https://www.youtube.com/watch?v=DVg2EJvvlF8)。帖子的内容几乎没有具体的保证，只是反复强调 DeepMind 建立“DeepMind 健康的可验证数据审计”有多困难，因为它描述了计划中的审计基础设施。

它写道，这“真的很难，最艰难的挑战绝不是技术上的挑战”——这可能是间接提到了这样一个事实，即它需要获得所有医疗保健和监管利益相关者的认可。因此，它需要获得他们对其方法的信任。(这反过来解释了情绪音乐和紧张的公关游戏。)

技术审计基础设施的时机和可行性也仍然模糊不清。因此，尽管如上所述，DeepMind 构建的 Streams 应用程序再次在伦敦的三家医院使用，但其预定的建立信任审计系统甚至尚未开始构建。

这篇博文充满了对建设所希望的基础设施的挑战/困难的警告，潜台词听起来很像:“注意，这实际上可能是不可能的。”

“在今年的过程中，我们将开始为 DeepMind Health 建立可验证的数据审计，”它在开头写道。但是在这篇博文的结尾，它谈到了“希望能够在今年晚些时候实现第一部分”——所以在同一篇博文中，它从“开始”转变为“希望”。

我们已经联系了 DeepMind，要求澄清其建立审计基础设施的时间表，并将根据任何回应更新这篇文章。

至于审计基础设施可能如何工作的其他细节，DeepMind 表示，其目标是建立在现有的数据日志基础上，当其系统通过仅附加的“特殊数字分类帐”与健康数据进行交互时——这不是分散的区块链(它声称这将浪费资源)，而是由 DeepMind 控制的具有树状结构的分类帐，这意味着新条目会生成一个总结最新条目和所有先前值的加密哈希——其想法是随着分类帐的增长，使条目防篡改。它表示，一个条目将记录:“某一特定数据被使用的事实，以及使用的原因——例如，血液测试数据与 NHS 国家算法进行了核对，以检测可能的急性肾损伤。”

值得注意的是，它没有指定当患者数据被用于训练任何人工智能模型时，分类账条目是否会记录下来 DeepMind 和 Royal Free 之前曾[表示他们的目标是](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/06/08/nhs-memo-details-googledeepminds-five-year-plan-to-bring-ai-to-healthcare/)——也没有指定是否会创建关于患者数据如何改变人工智能模型的审计线索，即，使数据输入能够与患者结果进行比较，并允许未来进行一些算法问责。(在这个话题上，可能是世界上最著名的人工智能公司 DeepMind 保持着明显的沉默。)

“我们将建立一个专用的在线界面，我们合作医院的授权人员可以使用它来实时检查 DeepMind Health 数据使用的审计线索，”它写道。“这将允许持续验证我们的系统是否正常工作，并使我们的合作伙伴能够轻松查询分类账，以检查特定类型的数据使用。我们还希望我们的合作伙伴能够运行自动查询，有效地设置警报，如果发生任何异常情况，就会触发警报。而且，随着时间的推移，我们甚至可以让我们的合作伙伴选择允许其他人检查我们的数据处理，例如单个患者或患者群体。”

将患者循环到审计中听起来可能很好，也很包容，但 DeepMind 继续警告说，实际上为患者群体/个体患者提供任何访问的困难是建立系统的主要技术挑战之一——所以在这个新生点上，这最好放在“情绪音乐”下。

在讨论“重大技术挑战”时，DeepMind 指出的第一个问题是能够确保所有数据访问都被记录在账本中。因为，很明显，如果系统不能捕获任何数据交互，整个审计就会失败。因此，这与其说是一个“挑战”，不如说是对整个努力的可行性的一个巨大的问号。

然而在这个深处，我只是试探性地写道(重点是我的):

> 除了设计日志来记录任何与数据交互的时间、性质和目的，我们还希望**能够证明**没有其他软件在后台偷偷与数据交互。除了在我们的分类帐中记录每一次数据交互之外，我们还需要使用正式的方法以及专家对代码和数据中心的审计，来证明数据中心中每一个软件的每一次数据访问都被这些日志所捕获。我们还对保证运行这些系统的硬件的可信性的努力感兴趣——这是计算机科学研究的一个活跃课题！

坦率地说，我认为“秘密软件”秘密获取人们敏感医疗记录的可能性为零，这必须成为一项要求，而不是一项可选的额外要求，以使拟议的审计系统具有一丝可信度。

值得注意的是，DeepMind 也没有说明它在这里设想的审计其数据中心/基础设施所需的“专家”是否独立于公司本身。但是很明显，他们需要这样做——否则，系统提供的任何审计都不会有价值。

我们已经联系了 DeepMind，询问其关于开源技术审计基础设施的意图，并将再次更新此贴的任何回应。

例如，与端到端加密协议一样，很明显，要使任何技术审计解决方案可信，DeepMind 都需要完全开放它——发布详细的白皮书，完全开源所有组件，并让外部专家对其操作进行彻底审计(可能会持续进行，因为基础设施会随着时间的推移而更新/升级)。

除了完全开放源代码之外，什么都不需要。记住:这是一个数据处理器*本身*提议为数据控制器授予访问权限的健康数据构建一个审计系统。所以冲突很明显。

当然，DeepMind 并没有指出这一点；更确切地说，它在结束自己的博客时，隐约希望能从任何普遍感兴趣的人那里获得帮助，实现自己的愿景。“我们希望通过公开分享我们的流程和记录我们的缺陷，我们将能够与尽可能多的人合作并获得他们的反馈，并增加这种基础设施有朝一日在医疗保健甚至其他领域得到更广泛应用的机会。”

但是，如果该公司真的想在其彻底改革医疗服务的愿景中灌输信任，它将需要使自己和它的过程比他们[迄今为止](https://web.archive.org/web/20230315204856/https://techcrunch.com/2016/07/20/deepminds-first-nhs-health-app-faces-more-regulatory-bumps/)更加透明和负责。

例如，它可以从回答一些问题开始，例如 DeepMind 处理健康患者的敏感数据的法律依据是什么，这些患者永远不会发展成 AKI？

为什么它和 Royal Free 没有为 Streams 应用程序寻求一种数字集成解决方案，这种解决方案只能获取可能容易受到攻击的患者的子集数据，而不是根据数据共享协议传递给 DeepMind 的更广泛的医疗记录？

当被问及对 DeepMind 的审计基础设施计划的评论时，MedConfidential 的协调员菲尔·布斯(Phil Booth)提出了关于原始数据共享安排的此类未回答的问题——他指出，目前的问题是该公司最初是如何以及为什么获得如此多的患者可识别数据，而不是在事后如何管理数据访问。

在讨论拟议的审计基础设施时，布斯说:“在谷歌与皇家免费服务的欺诈交易中，这最终将向患者证明，当他们当时不在医院附近时，数据被复制到谷歌‘用于直接护理’。它应该不可逆转地记录谷歌获得了他们无权访问的数据，现在拒绝回答有关问题。”

“这就像是飞行中的黑匣子记录器，”他在谈到审计基础设施时补充道。“你总是希望这不是必要的，但如果出了什么问题，知道有人能弄清楚你的飞机撞到山上后发生了什么，这令人放心。”

**更新:** DeepMind 已经证实，它打算完全开源审计基础设施的所有元素，并且审计与审计基础设施相关的代码和数据中心所需的“专家”将在公司外部。

它还证实，当患者数据被用于训练人工智能模型时，审计账本将会记录下来——尽管尚不清楚该账本是否也会记录数据如何改变 DeepMind 的人工智能模型，即通过解释人工智能应用/服务如何做出医疗决策来支持未来的算法问责。

在“最好的情况下”，它说它的目标是今年建立并运行审计系统。