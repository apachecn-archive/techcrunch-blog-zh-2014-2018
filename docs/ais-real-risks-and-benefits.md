# 不仅仅是另一场关于人工智能是否会毁灭我们的讨论

> 原文：<https://web.archive.org/web/https://techcrunch.com/2015/09/06/ais-real-risks-and-benefits/>

人工智能圆桌讨论是科技新闻马戏团的一个主要内容——通常以“超级智能机器”不可阻挡的崛起对人类生存的威胁为序言。只需添加一张来自《终结者》的电影剧照。

这种设置的典型结果是观点和轶事的来回纠缠，其中人工智能的一致定义未能成为聚集的有学问的头脑的涌现属性。对于人工智能对人类的未来意味着什么，也没有明确的共识。毕竟，即使是最善意的群体思维又怎么能预测一个未知的未知的结果呢？

考虑到我们人类甚至不知道什么是人类智能，这一点都不奇怪。在“机器意识”的金属外壳中思考我们自己——不管这意味着什么——就像试图想象如果我们自己的智慧体现在梨的果肉中，而不是我们居住的肉质形式中，我们的思想会是什么一样富有成效。或者，如果我们的意识在艺术家的意图下在动画的瞬间短暂地存在于液体颜料中。哲学家可以对人工智能的含义进行哲学思考，当然([，他们当然会这么做](https://web.archive.org/web/20230313153123/https://www.youtube.com/watch?v=pywF6ZzsghI))。但是只有白痴才会声称知道。

本周，我在伦敦超时尚的初创公司合作中心[的第二故乡](https://web.archive.org/web/20230313153123/http://secondhome.io/)参加了一场小组讨论，讨论了很多这种熟悉的话题。所以我不会老调重弹。相反，正如一些人可能会争论的那样，让人工智能更像一台机器——在某种意义上，就像一个被训练来从混合数据转储中发掘新奇事物的算法一样——我编制了一个列表(如下)，列出了一些在小组成员被要求考虑人工智能是否是“一种好的力量”(或不是)时出现的更有趣的观点。

我还列出了一些参与者提到的(狭义)人工智能的有前途的途径。因此，他们看到了学习算法解决人类可能会发现难以解决的问题的潜力，以及这些用例可以被广泛认为对社会有益的地方，以努力引导人工智能叙事远离嗜血机器人。

最后一个列表是对更有根据的感知威胁/风险的总结，即那些不关注未来“超级智能机器”判断人类浪费地球空间的刻板末日场景，而是再次关注与我们已经拥有的那种狭窄但不断增加的“人工智能”相关的风险。

在切换到子弹和片段之前，还有一点:在长达一小时的讨论中出现的对(狭义)人工智能的最简洁描述来自 Tractable 创始人亚历山大·达利亚克，他总结道:“与人类相比，算法通常能够解决规模、速度或准确性问题。”

所以你知道了:人工智能，它是关于规模、速度和准确性的。不会把人类变成液体肥皂。但是，如果你真的想关心机器智能的发展方向，那么思考一下*算法的规模、速度和准确性——应用于人类生活的越来越多的方面——*将如何影响和塑造我们生活的社会，肯定是一个值得思考的问题。**

 ***小组成员**

*   《幸存的人工智能》的作者卡卢姆·刘升
*   丹·克罗，首席技术官
*   Alexandre Dalyac，Tractable 创始人
*   圣玛丽大学哲学讲师/项目主任 Yasemin J Erden 博士
*   Martina King，Featurespace 首席执行官
*   Ben Medlock，SwiftKey 创始人
*   马丁·米尼奥，指数投资公司负责人
*   王军，读者，计算机科学，UCL & media gamma 联合创始人，首席技术官

**平均兴趣以上的讨论点:**

*   AI 研究应该默认开源吗？当深度学习等人工智能领域的最大实体是谷歌等不透露其专有算法的商业公司时，我们怎么能指望控制和监管日益智能的计算的社会影响？

“如果人类的未来岌岌可危，他们应该被迫开源吗？或者我们如何控制那里正在发生的事情？”米尼奥问道。“我认为没有人知道谷歌在做什么。这是问题之一，也是我们应该担心的问题之一。”

Jun 补充说，开源机器学习相关研究的运动也可能是减少公众对人工智能技术未来影响的担忧的一种方式。

*   我们的机器变得越通用，完成某项特定任务的能力和/或可靠性就会越低——因此，可以说，整体上就越不安全，会是这样吗？当你试图让机器跳出(狭窄的)框框思考时，这也许是一种交换吗？

“一个有趣的哲学问题是，你完全专注地完成特定任务的能力——减少假阳性，增加安全性——是否真的需要一种狭义的智能。“当我们的机器开始变得更通用，本质上更像人类时，这是否必然会降低安全性，”梅德洛克假设道。

“我可以想象，人类大脑的灵活性，对如此多不同场景做出反应的可塑性，需要减少完成特定任务的特定能力。我认为，随着我们开始开发 AGI(人工通用智能)，这将成为有趣的事情之一——它是否真的会因为一系列非常不同的原因而变得有用，以缩小人工智能的范围。”

“我不认为人工智能本身是我所关心的，它更像是人工的愚蠢。这种愚蠢要么来自狭隘的关注，要么来自对更广泛问题的误解，”额尔登补充道。“试图确定构成个体特定任务发生背景的所有小细节的困难。

“一旦你试图要求单个程序做非常大的事情，因此它们需要考虑许多问题，那么事情就变得困难得多。”

*   随着学习算法的激增，安全的核心问题或对机器决策篡夺人类判断的更广泛的伦理担忧应该成为社会最大的担忧吗？在那个模糊的关头，你能把安全和道德分开吗？

“建立网站的人把它放在那里，根本没有真正考虑过道德问题。我没有想过把这些工具交到那些消极而不是积极使用这些工具的人手中。我认为我们可以把这些经验应用到新技术中，”金说。

“网络的一个很好的例子是人们相信加利福尼亚的法律适用于世界各地。他们没有，他们没有，实际上这些网络公司花了大量的时间——这是同行团体的压力，游说团体等等——为了让这些组织的行为实际上符合他们运营所在国家的法律。”

> 他们不在乎我们，他们什么都不在乎。他们不知道自己的存在。但是它们可以给我们带来伤害，也可以给我们带来好处，我们需要考虑如何让它们变得安全。

“我对人们谈论人工智能伦理有点困惑，”刘升补充道。“在某些时候，机器很可能是有道德的存在，但目前这不是道德问题，而是安全问题。这是为了确保随着人工智能变得越来越强大，它们对人类是安全的。他们不在乎我们，他们什么都不在乎。他们不知道自己的存在。但它们可能会对我们造成伤害，也可能会带来好处，我们需要考虑如何让它们变得安全。”

*   社会将从学习算法的效率提高中受益，还是财富将越来越多地集中在(越来越多的)少数个人手中？

“我认为……无论何时人工智能出现，甚至有可能取代劳动力，这确实是因为它提高了效率——因此创造了更多。但是，或许可以这样想，这种效率收益是如何分配的。因此，如果它集中在所有者手中，可能对社会没有什么好处。但如果社会普遍受益，那可能会更好，”Dalyac 说。

“例如，我们正在进行的一项工作是自动化保险索赔的视觉评估任务。这样做的好处是降低汽车保险的保险费……所以这是一个通常被雇佣来做这件事的人会发现自己失业的情况，所以这个国家可能有 400 人失业。但结果是有 5000 万人从中受益。”

*   类似于“人工智能哲学”的东西应该在学校里教授吗？假设我们鼓励孩子们学习编码，那么通过教他们思考越来越聪明和强大的决策机器的社会影响，将这些知识放在上下文中怎么样？

"它应该是学校里的一门学科，让学生学习人工智能吗？"米尼奥问道。“再往前一步上课会不会有意思。一旦你知道如何用二进制语言编写计算机代码，那么创造一个智能设备意味着什么？

“我认为这将对讨论有很大帮助，因为今天的编码人员并不真正了解技术的局限性和潜力。成为一台可以自我学习和决策的机器意味着什么？作为一个概念，它是如此抽象，以至于我认为对于不在这个领域工作的人来说，它要么太不透明，甚至无法考虑，要么真的很可怕。”

*   “人工智能”这个总括术语是否真的阻碍了公众对无数发展和(潜在)利益的认识和理解，这些发展和利益与能够根据数据输入进行调整的算法有关？

“我们要求人们理解一些我们自己还没有真正理解的东西，或者至少还没有归类的东西。因此，当我们谈论智能手机时，我们并没有真正谈论人工智能，我们谈论的是一些智能计算。我们正在谈论一些非常有趣的编程，以及这种编程可以学习和适应的可能性，但以非常非常简单的方式，”Erden 说。

“当你这样向人们描述它时，我认为他们不是被它吓到了，就是没有理解它。但是，如果你用人工智能这个总括术语来描述这一点，你会承诺太多，你会失望很多，你也会让人们困惑……说‘智能计算’有什么错？说‘聪明编程’有什么错？说‘计算智能’有什么错？”

*   IBM 的“认知计算”技术，沃森——据称从玩 Jeopardy 扩展到将其算法印章应用到非常不同的领域，如[预测医学](https://web.archive.org/web/20230313153123/https://techcrunch.com/2015/07/30/cvs-health-taps-ibms-watson-to-help-predict-patients-health-decline-before-it-happens/)——更像是一个聪明的营销案例，而不是一个日益广泛的人工智能的例子？

“我想说，如果你看一看报纸，你就会意识到沃森可能只是纯粹的品牌推广。它是一个非常大的研究人员团队，他们在一项任务上做得非常好，并说'嘿，让我们称它为沃森'，让我们让它成为'超级智能生物'，所以下次他们要求我们做一些智能的事情时，我们会让相同的研究人员或类似的研究人员从事其他工作，”Dalyac 说。

“我们正在研究自动评估汽车的损坏，IBM Watson 在 2012 年发表了一篇论文，老实说，它使用了非常非常古老的人工智能——我可以肯定地说，人工智能与在 Jeopardy 中获胜无关，”他补充道。

**圆桌会议期间引用的学习算法的有前途的应用:**

*   帮助网站剔除算法生成的广告点击(讽刺的是！)
*   分析赌徒的游戏模式，以确定有问题的临界点
*   通过使用变点检测更有效地监测皮肤损伤
*   创造可以与自闭症儿童互动的社交人工智能，以减少孤独感
*   通过使用统计方法改进机器翻译来解决语言翻译的复杂性
*   将传感器放在手术工具上来模拟(和复制)完美的手术
*   通过分析行为模式，使用来自运动传感器的数据来预测身体虚弱的老年人何时可能有跌倒的风险

**对机器学习和大数据激增的一些近期担忧:**

*   如何监管和控制可能适用不同法律的日益强大和复杂的跨境数据处理？
*   如何保护用户隐私免受预测算法侵害，确保数据处理的知情同意？

“在过去十年左右的时间里，数据的使用在很大程度上是发生在表面之下的事情。用户的数据被传递给目标网络，我认为，从某种程度上说，我希望，在未来十年左右的时间里会发生变化，部分人会意识到收集的数据，这些数据描述了他们做的事情，他们的喜欢和兴趣，这是他们实际上拥有和控制的资产，”Medlock 说。

“向消费者转变，他们将数据视为一种货币，就像他们使用和拥有自己的钱一样，他们能够决定在哪里共享这些数据……将数据的处理、操作和存储从黑暗的深渊转移到人们至少意识到并能够有意识地做出决定的地方。”

*   如何应对越来越强大的少数科技公司手中积累的海量数据以及数据可以产生的预测性见解？

“对政府、行业和学术界来说，这将继续是一个挑战。我们不会很快解决这个问题，但很多人都在努力思考，”克罗说。“如果你看看正在发生的一些监管事情，当然是在欧盟，也开始在美国发生，我认为你会看到人们至少理解现在存在的担忧。

“这是一个政府需要发挥有效作用的领域。我不认为我们确切地知道那看起来像什么——我不认为我们已经完成了那个讨论。但至少现在讨论正在进行，我认为这真的很重要。”

*   如何避免算法效率破坏就业，将越来越多的财富集中在越来越少的个人手中？

在小组讨论之前，SwiftKey 对英国用户进行了一项调查，发现大多数受访者(52%)担心人工智能的进步会导致工作岗位冗余。而只有三分之一(36%)的人表示，他们希望看到人工智能在社会中发挥更大的作用——这意味着三分之二的人更喜欢对机器学习技术的扩散进行制衡。

底线是，如果提高算法效率破坏的工作比创造的多，那么大规模的社会重组是不可避免的。因此，人类大脑试图询问谁从这种加速变化中受益，以及人们希望生活在什么样的社会中，肯定只是谨慎的尽职调查——更不用说(生物)智能的定义了。*