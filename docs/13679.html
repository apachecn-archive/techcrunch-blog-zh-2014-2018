<html>
<head>
<title>Artificial intelligence is not as smart as you (or Elon Musk) think | TechCrunch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能没有你(或埃隆·马斯克)想象的那么聪明</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://techcrunch.com/2017/07/25/artificial-intelligence-is-not-as-smart-as-you-or-elon-musk-think/">https://web.archive.org/web/https://techcrunch.com/2017/07/25/artificial-intelligence-is-not-as-smart-as-you-or-elon-musk-think/</a></blockquote><div><div class="article-content">
				<p id="speakable-summary" class="translated">2016 年 3 月，DeepMind 的 AlphaGo <a target="_blank" href="https://web.archive.org/web/20230325195204/https://techcrunch.com/2017/05/24/alphago-beats-planets-best-human-go-player-ke-jie/" rel="noopener">击败了当时世界上最好的人类围棋选手</a>Lee Sedol。它代表了那些定义性的技术时刻之一，比如 IBM 的<a target="_blank" href="https://web.archive.org/web/20230325195204/http://www.nytimes.com/1997/05/12/nyregion/swift-and-slashing-computer-topples-kasparov.html" rel="noopener">深蓝击败了国际象棋冠军</a>加里·卡斯帕罗夫，甚至是<a target="_blank" href="https://web.archive.org/web/20230325195204/https://www.theguardian.com/technology/2011/feb/17/ibm-computer-watson-wins-jeopardy" rel="noopener"> IBM 沃森击败了</a>世界上最伟大的<em> Jeopardy！</em>2011 年冠军。</p>
<p class="translated">然而，这些胜利虽然看起来令人振奋，但更多的是关于训练算法和使用蛮力计算能力，而不是任何真正的智能。前麻省理工学院机器人学教授罗德尼·布鲁克斯是 iRobot 和后来的 Rethink Robotics 的创始人之一，他上周在麻省理工学院举行的 TechCrunch 机器人会议上提醒我们，训练一个算法来玩一个困难的策略游戏不是智能，至少在我们对人类的思考中不是智能。</p>
<p class="translated">他解释说，尽管 AlphaGo 在给定的任务方面很强，但它实际上除了在标准的 19 x 19 棋盘上下棋之外，不会做任何其他事情。他转述了一个故事，最近在伦敦与 DeepMind 团队交谈时，他问他们如果将棋盘的大小改为 29 x 29 会发生什么，AlphaGo 团队向他承认，如果棋盘的大小哪怕有一点点变化，“我们都会死。”</p>
<p class="translated">“我认为人们看到[一个算法]在一项任务中的表现有多好，他们认为它可以做所有的事情，但它不能，”布鲁克斯解释道。</p>
<h2 class="translated">蛮力智能</h2>
<p class="translated">正如卡斯帕罗夫 5 月份在 TechCrunch Disrupt 接受 Devin Coldewey 采访时指出的那样，设计一台能在大师级别下棋的计算机是一回事，但称之为纯粹意义上的智能是另一回事。它只是将计算机的能力投入到一个问题中，让机器做它最擅长的事情。</p>
<p class="translated">“在国际象棋中，由于计算的强力，机器主宰了游戏，一旦数据库足够大、硬件足够快、算法足够智能，它们(可以)处理国际象棋，但仍有许多事情人类可以理解。机器没有理解力。他们不知道战略模式。机器没有目的，”卡斯帕罗夫解释道。</p>
<p class="translated">丰田研究所(Toyota Institute)的首席执行官吉尔·普拉特(Gil Pratt)在 TechCrunch Robotics 会议上接受了采访，他说，我们从许多人那里听到的恐惧，包括埃隆·马斯克(Elon Musk)，他最近<a target="_blank" href="https://web.archive.org/web/20230325195204/https://techcrunch.com/2017/07/19/elon-musk-clarifies-that-ai-regulation-should-follow-observation-and-insight/" rel="noopener">称人工智能是“对人类的存在性威胁</a>”，这可能源于对人工智能失控的科幻反面乌托邦式的描述。</p>
<p>	</p><div class="article-block block--pullout block--center">
		<blockquote class="translated">我认为，重要的是要了解这些系统有多好，实际上它们也有多差，以及我们需要走多长时间，直到这些系统真正构成那种威胁【埃隆·马斯克和其他人谈到】<cite>吉尔·普拉特，丰田研究所首席执行官</cite></blockquote>
	</div>
	
<p class="translated">“我们拥有的深度学习系统，也就是刺激所有这些东西的东西，在我们给定的特定任务中表现出色，但它们实际上在范围上非常狭窄和脆弱。因此，我认为重要的是要了解这些系统有多好，实际上它们也有多坏，以及我们还要走多长时间，直到这些系统真正构成埃隆·马斯克和其他人所说的那种威胁。”</p>
<p class="translated">Brooks 在他的 TechCrunch 会议上说:机器人技术谈论到，我们有一种倾向，认为如果算法可以做<em> x </em>，它一定和人类一样聪明。“这是人们——包括埃隆——犯这个错误的原因。当我们看到一个人很好地完成一项任务时，我们就理解了他的能力。我认为他们将相同的模型应用于机器学习，”他说。</p>
<p class="translated">脸书的马克·扎克伯格在周日的脸书直播中也批评了马斯克的评论，称其“非常不负责任”。扎克伯格相信人工智能最终会改善我们的生活。<a target="_blank" href="https://web.archive.org/web/20230325195204/https://techcrunch.com/2017/07/25/elon-musk-mark-zuckerberg-artificial-intelligence/" rel="noopener">马斯克随后回击道，扎克伯格对人工智能“了解有限”。(如此循环往复。)</a></p>
<p class="translated">然而，值得注意的是，马斯克并不是唯一有这种想法的人。物理学家斯蒂芬·霍金和哲学家尼克·博斯特罗姆也对人工智能对人类的潜在影响持保留态度——但他们谈论的可能是脸书人工智能研究所、DeepMind 和 Maluuba 等实验室正在研究的更广义的人工智能，而不是我们今天看到的更狭义的人工智能。</p>
<p class="translated">布鲁克斯指出，许多批评者实际上并不在人工智能领域工作，并暗示他们不明白解决每个问题有多困难。“有相当多的人说人工智能是一个存在的威胁——斯蒂芬·霍金，(马丁·里斯)，英国皇家天文学家……还有其他一些人——他们有一个共同点，那就是他们自己并不从事人工智能研究。”布鲁克斯接着说，“对于我们这些在人工智能领域工作的人来说，我们知道让任何东西在产品层面上真正发挥作用有多难。”</p>
<h2 class="translated">人工智能可能是用词不当</h2>
<p class="translated">部分问题源于我们称它为“<a target="_blank" href="https://web.archive.org/web/20230325195204/https://techcrunch.com/2016/12/04/wtf-is-ai/" rel="noopener">人工智能</a>”这一点也不像人类的智力，韦氏词典将人类的智力定义为“学习、理解或处理新的或棘手情况的能力”</p>
<p>	</p><div class="article-block block--pullout block--center">
		<blockquote class="translated">大脑像电脑的类比是危险的，阻碍了人工智能的进步。<cite>star mind 首席执行官帕斯卡尔·考夫曼</cite></blockquote>
	</div>
	
<p class="translated">Starmind 的创始人帕斯卡尔·考夫曼(Pascal Kaufmann)在过去的 15 年里一直在研究神经科学。star mind 是一家初创公司，旨在帮助公司利用集体人类智慧来寻找商业问题的解决方案。他说人脑和电脑的运作方式不同，比较这两者是错误的。“大脑就像一台计算机的类比是危险的，它阻碍了人工智能的进步，”他说。</p>
<p class="translated">此外，考夫曼认为，如果我们从技术的角度来看待人类智能，我们就不会推进对人类智能的理解。“认为(算法)像人脑一样工作是一种误解。人们爱上了算法，认为你可以用算法来描述大脑，我认为这是错误的，”他说。</p>
<p class="translated"><span>当事情出错时</span></p>
<p class="translated">事实上，有很多情况下，人工智能算法并不像我们想象的那么聪明。人工智能失控的一个臭名昭著的例子是微软人工智能团队去年创造的<a target="_blank" href="https://web.archive.org/web/20230325195204/https://techcrunch.com/2016/03/23/microsofts-new-ai-powered-bot-tay-answers-your-tweets-and-chats-on-groupme-and-kik/" rel="noopener">微软聊天机器人</a>。不到一天<a target="_blank" href="https://web.archive.org/web/20230325195204/https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist" rel="noopener">机器人就学会了种族主义</a>。专家说，当糟糕的例子出现在任何人工智能系统面前时，它都可能发生。在泰的案例中，它被种族主义和其他攻击性语言操纵，由于它被教会“学习”和模仿这种行为，它很快就脱离了研究人员的控制。</p>
<p class="translated">康奈尔大学和怀俄明大学的研究人员进行的一项被广泛报道的研究发现，欺骗训练有素的识别图片的算法相当容易。研究人员发现，当呈现给人类看起来像“杂乱无章”的东西时，算法会将其识别为像“校车”一样的日常物体。</p>
<p class="translated">根据《麻省理工科技评论》关于同一研究项目的一篇文章<a target="_blank" href="https://web.archive.org/web/20230325195204/http://www.evolvingai.org/files/MIT_Tech_Review_Fooling_paper.pdf" rel="noopener">所述，人们还不太理解的是，为什么算法会以研究人员发现的方式被愚弄。我们知道的是，人类已经学会识别某个东西是图片还是废话，分析像素的算法显然可以受到一些操纵。</a></p>
<p class="translated">自动驾驶汽车甚至更加复杂，因为有些事情人类在接近某些情况时可以理解，而这些事情很难教给机器。在罗德尼·布鲁克斯 1 月份写的一篇关于自动驾驶汽车的长文中，他提到了很多这样的情况，包括一辆自动驾驶汽车可能会在一个城市街区的十字路口靠近一个停车标志，一个大人和一个孩子站在角落里聊天。</p>
<p class="translated">该算法可能会调整为等待行人过马路，但如果他们因为在等校车而无意过马路呢？他写道，人类司机可以向行人发出前进的信号，他们也可以挥手示意汽车前进，但无人驾驶汽车可能会被困在那里，无休止地等待这两个人过马路，因为他们不理解这些独特的人类信号。</p>
<p class="translated">这些例子中的每一个都显示了我们离人工智能算法还有多远。如果研究人员在开发广义人工智能方面变得更加成功，这种情况可能会发生变化，但就目前而言，有些事情人类可以轻松完成，但要教会一种算法要困难得多，这正是因为我们在学习中并不局限于一组定义好的任务。</p>
			</div>

			</div>    
</body>
</html>